{"pages":[{"title":"关于","text":"船舶专业大学生，喜欢计算机、摄影…… Email: zyanglin@outlook.com","link":"/about/index.html"}],"posts":[{"title":"2021电赛F题:送药小车-基于OpenCV和汉明距离识别数字思路","text":"这个题目挺好玩的，不过我并没有参赛，所以只尝试了我感兴趣的识别数字的部分。 需求分析这个识别需求非常简单，一句话就能说完：识别摄像头拍摄到的数字，数字的样式如图所示，数字可能单独出现，也可能两个一组地出现，画面中最多并排出现两组数字，当有多个数字时，数字的顺序不能乱。 也就是说画面可能会有若干个带框的数字并排出现，我要做的就是识别出它们，而且顺序不能乱。 我注意到很多人立马想到用目标检测的方法来寻找画面中的数字和它的位置。但是我之前查阅过一些资料，目前很火热的目标检测算法 yolo 其实不擅长在画面中寻找文字符号（我想过用 yolo 来做 OCR 来着），所以我并没有和他们一样从目标检测这个方向来考虑。 我以前做过类似的工作 —— 识别图中的多边形（三角形、四边形）并找到它们的位置。而这次要识别的数字刚好也带一个四边形的框，所以我以前做过的工作直接就能用了。 最终我采用的是传统的计算机视觉方案。 OpenCV 识别矩形并纠正透视变形识别矩形边框其实更准确的说法是识别画面中的四边形，因为画面是带有畸变（镜头影响）和透视变形（拍摄角度影响）的，所以矩形的边框被摄像头拍下来后就是一个不太整齐的四边形了。 我把我以前做过的多边形识别改成了四边形识别，结果如下图。 可以看到问题还是挺多的。 比如数字的边框识别出了嵌套的两个边框而不是一个边框。这是因为数字边框的内边缘和外边缘被认为是两个四边形了。这个问题我的解决方法是找到所有两两嵌套的边框，然后删除外面那个边框。 还有一个问题就是把没有数字内容的四边形也识别出来了，我的思路是暂时不管它，等到识别数字的阶段，如果没找到数字就舍弃这个边框。 我这里就不贴代码了，因为我也是网上抄的，对其中的原理不是很了解。等我日后研究清楚了另发一篇博客分享。（挖坑） 纠正透视变形带有透视变形的数字可能不利于 OCR，所以最好是进行纠正。 这个纠正其实很常用，比如现在的手机拍照都有所谓的“文档模式”，它能自动搜索图片中的投影仪画面或者纸张，确定投影仪画面或者纸张的四个顶点，然后把图片裁剪成只有投影仪画面或者只有纸张的图片。 这部分代码也是抄的，就先不贴出来了，纠正后的效果如图所示，效果非常好。 识别数字识别数字我并没有用什么神经网络，用的还是简单的方法。首先是这个数字是很标准的字体，又不是什么手写字体，杀鸡何须牛刀？其次我这个程序是用 C++ 写的，而平时玩神经网络都是用的 dotnet(ML.NET) 或者 python，C++ 程序调用它们不太方便。 我以前做过类似的识别工作，为了识别教务系统的验证码。那个验证码是很简单的：位置固定、标准字体、没有干扰线，所以我用的是最简单的汉明距离。 这次的数字识别和那个验证码识别非常类似，所以这次我也用的汉明距离。 在计算汉明距离之前，需要对图片进行预处理比如缩放为固定大小、转化为灰度图、二值化处理。预处理中尤其是要进行二值化，这样才方便计算汉明距离。 灰度与二值化预处理效果如图所示。 提取特征我之前做验证码识别的时候并没有提取特征。我从 A-Z 0-9 里各挑选一张照片，组成一个 36 张照片的数据库。然后拿新的照片和那 36 张图片算汉明距离，汉明距离最小的就认为是答案。 这次我打算用新的思路，这个思路是我以前看到的，忘了出处是哪里了，当时觉得很有意思所以一直记得。 这个思路就是从图片中提取一定的特征，然后算新图片特征和旧图片特征的汉明距离，这其中的关键是提取特征的算法。 我记到的特征提取算法简单来说就是数有几个像素点： 首先横着走，数图片每一列有多少像素点； 然后竖着走，数图片每一行有多少像素点； 对于 32x32 的图片，第一步和第二步分别得到 32 个数字，这两组数字称为一张图片的特征。 当时实现的提取特征的代码如下（注意！实现的代码有误！）： 12345678910111213141516171819202122232425262728293031vector&lt;float&gt; calcIdX(const Mat&amp; image_binary){ vector&lt;float&gt; result; for (int i = 0; i &lt; image_binary.cols; i++) { int tmp = 0; for (int j = 0; j &lt; image_binary.rows; j++) { int value = 255 - (int)image_binary.at&lt;uchar&gt;(j, i); tmp += value; // !我没有除以 255，但是影响不大，下同 } result.push_back((tmp / (float)image_binary.rows)); // !我不知道为什么我当时要除以 rows，但是影响不大，下同 } return result;}vector&lt;float&gt; calcIdY(const Mat&amp; image_binary){ vector&lt;float&gt; result; for (int i = 0; i &lt; image_binary.rows; i++) { int tmp = 0; for (int j = 0; j &lt; image_binary.cols; j++) { int value = 255 - (int)image_binary.at&lt;uchar&gt;(i, j); tmp += value; } result.push_back((tmp / (float)image_binary.cols)); } return result;} 我对 1~8 每个数字都挑选了十几个图片，计算了它们的平均特征值。 汉明距离算汉明距离就是算新的图片的特征值和平均特征值，有多少位置不一样。 虽然我知道是这样的，但是当时迷迷糊糊的状态写的代码求的根本不是汉明距离，真的不知道我当时在想什么。 前面求了 平均特征值，而且求的特征代码写错了，所以下面算的“汉明距离”也就不是“汉明距离了”，而是“相似度”的概念了。 我算“汉明距离”的代码如下： 123456789float distance(const vector&lt;float&gt;&amp; id1, const vector&lt;float&gt;&amp; id2){ double result = 0; for (size_t i = 0; i &lt; id1.size(); i++) { result += fabs(id1[i] - id2[i]); // 这求的可不是汉明距离啊 } return result / id1.size(); // 为什么我又除了个常数？} 连错两次，代码居然能按照预想的结果来…… 实际应用效果朋友的小车用 esp32-cam 来实时录像并推流。我的程序只需要部署到一台和 esp32-cam 相同局域网的设备上就可以工作。 OpenCV 处理 esp32 推流这里有个小坑，就是 esp32 的推流不是视频流，而是 jpg 图片流，所以 opencv 无法直接处理。我用 libcurl 库手动处理了下 esp32 的推流，并让 opencv 解析其中的 jpg 图片。 因为细节还挺多的，所以这部分的代码将在另一篇博文里分享。 影响因素实际的工作结果还是比较好的，光线条件的影响不是很大，但是受视角的影响比较大。如果画面中数字的边框不完整，那么即使数字在画面中占比很大，我的程序也完全无法工作 —— 识别到矩形框是一切的前提，然后才能识别出数字。 但是 esp32-cam 的画面视角比较窄（朋友给换了个素质更好的镜头），实际测试中，两个数字同时出现在画面中，总有一个数字的边框贴近画面边缘，这就很危险了，说明这个方案稳定性可能不如预期。还好朋友调整了云台，让框尽量完整出现在画面中。 另一个问题就是 6 和 8 分不出来。8 可能会识别成 6，而 6 可能会识别成8，虽然错误率不是很高，但是这个问题说得上很致命了。我朋友的解决方案是对我提交的识别结果进行“滤波”，把出现提交最多的一次作为最终结果。 除了 6 和 8，其他数字的识别率还是比较高的，能有 90%。 再分析赛后我重点分析了下为什么我的方法分不清 6 和 8。 我怀疑是 6 和 8 的特征值太过相似，所以分不清。 我把它们的特征值做成曲线后，发现它们的特征曲线确实很像。 如果不能对整体思路进行大改，应该可以通过修改求特征的算法来修补。毕竟我的求特征算法搞错了，说不定该对之后就可以工作了（懒得试）。 也可以增加新的特征，比如把 32x32 的图像横竖两刀切割为 4 份，对每一份都求两组特征值，再加上原来的两组特征值。总共 10 组特征值。 虽然运算量大了很多，但是应该应该对提升准确率有帮助（懒得试）。 考虑改用 BP 神经网络如果能写一个小型的 BP 神经网络，引入几个文件就能用的那种，用来做这种简单的分类任务应该会很好用。这次传统方法好用还是因为字体比较标准，如果是手写字体，我想还是机器学习那一套更好用，应该能节约很多工作量。","link":"/2021/11/09/2021%E7%94%B5%E8%B5%9BF%E9%A2%98-%E9%80%81%E8%8D%AF%E5%B0%8F%E8%BD%A6-%E5%9F%BA%E4%BA%8EOpenCV%E5%92%8C%E6%B1%89%E6%98%8E%E8%B7%9D%E7%A6%BB%E8%AF%86%E5%88%AB%E6%95%B0%E5%AD%97%E6%80%9D%E8%B7%AF/"},{"title":"2020深圳杯数模C题简析:无线可充电传感器网络充电路线规划","text":"好像没啥好写的，就是个旅行商问题+多人旅行商问题。 完。","link":"/2020/09/29/2020%E6%B7%B1%E5%9C%B3%E6%9D%AF%E6%95%B0%E6%A8%A1C%E9%A2%98%E7%AE%80%E6%9E%90-%E6%97%A0%E7%BA%BF%E5%8F%AF%E5%85%85%E7%94%B5%E4%BC%A0%E6%84%9F%E5%99%A8%E7%BD%91%E7%BB%9C%E5%85%85%E7%94%B5%E8%B7%AF%E7%BA%BF%E8%A7%84%E5%88%92/"},{"title":"2048 游戏AI的实现思路","text":"2048 游戏AI的实现思路&emsp;&emsp;最近玩2048玩上瘾了，一玩就停不下来。&emsp;&emsp;觉得这样玩个不停太浪费时间了，于是就想做个AI帮我玩2048。&emsp;&emsp;首先要做一个2048游戏，这个游戏的规则和玩法很简单，所以实现起来不复杂。(要注意的是，2 和 4 的出现概率分别是 0.1 和 0.9。)&emsp;&emsp;关键是如何实现AI！ 游戏规律&emsp;&emsp;这个游戏想要通关(合成出2048)还是很简单的，只要让最大的那些数字按照从大到小的顺序始终呆在一个角落就可以了。&emsp;&emsp;比如 图1 中的这种情况，我只需要在现在这个 32 旁边再合成出一个 32，这两个 32 就能合并成一个 64。然后新合成的 64 和原来就有的 64 将会是挨在一起的，所以让这两个 64 合并就很轻松。合并之后得到一个 128，所以剩下的主要数字就是 2048、512、256、128。而且它们还都是挨在一起，按照从大到小的顺序排列的。游戏的下一步就是我再合成一个 128，这样就能一口气把 512、256、128 合成为一个 1024。 &emsp;&emsp;那么，要如何让 AI 按照这样的规律来游戏呢？ &emsp;&emsp;这个游戏的操作很简单，只有上移、下移、左移、右移这四种操作。而我的思路是让 AI 在当前局面的基础上，对这四种操作移动后的结果打分，返回分数最高的一种操作。 &emsp;&emsp;现在，问题的关键在于如何评分。 位置加权评分方案&emsp;&emsp;一种思路是把棋盘的每个位置都设置一定的权重 \\( w{xy} \\)，那么评分 \\( S \\) 为各位置数值 \\( v{xy} \\) 的加权求和: S = \\sum_{x,y=1}^{x,y=4} w_{xy} \\cdot v_{xy}&emsp;&emsp;可以预知 AI 会让大权重位置上的数值尽可能地大。实际的运行结果也是符合预想。 &emsp;&emsp;接下来谈谈权重的值要怎么取。为了方便说明，我先给出经过测试效果比较好的一种权重取值。 \\begin{bmatrix} 255 & 127 & 63 & 63 \\\\\\\\ 11 & 17 & 15 & 19 \\\\\\\\ 0 & 0 & 0 & 0 \\\\\\\\ -3 & -5 & -7 & -9 \\end{bmatrix}&emsp;&emsp;第一行的权重给的最高，而且从左往右递减。为了让数值大的值尽量呆在这一行，所以这一行各个位置的权重都远远大于其他位置的权重。而又为了让数值最大的那个数字固定于角落不移动，所以这一行最左边位置的权重又远大于所有其他位置的权重。 &emsp;&emsp;第二行的权重比第一行小得多，而且不呈递增或递减。这是因为这一行的数字最终要和上一行合并，如果权重呈现递增或者递减，会导致这一行的数字不常移动。如果这一行的数字不常移动，就难以保证相同的数字处于同一列，因此会出现如 图3 这样的效果。(注意：图片中展示程序的行和列与本文权重的行和列相反。上文给出的权重应当会让数值大的数字在第一行，而图中数值最大的数字正好在第一列。) &emsp;&emsp;可以看出各行数值最大的数字堆积于各行权重最大的位置，迟迟无法合并导致游戏失败。 &emsp;&emsp;剩下两行的权值则是随意设置，只要各行之间的权值相差不要太小即可。 &emsp;&emsp;但是如果只有这样的权值设置，会发现 AI 的运行效果不佳。从 图4 可以看出，数字的出现很有规律，AI 确实在按照权重来运行。 &emsp;&emsp;进一步观察 图4 可以发现，权值最大的那两行位置上的数字，似乎差了一格就能把数字合并在一起。 &emsp;&emsp;设置权重可以让数值大的数字尽量靠近一个角落，也可以让第二行的数字往第一行合并。但是合并的前提是，两行相同数值的数字要在同一列，而光靠设置权重则很难保证相邻两行的同数值数字能够并列。因此需要设置算法鼓励能够让相同数值的数字并列的操作。 让数值相同的数字在同一列&emsp;&emsp;这个思路实现起来不难，针对棋盘上每一列，统计其相邻且相同的数字的数目，折算后加入评分即可。这里给出一个算法： 123456789101112for (int y = 0; y &lt; 4; y++){ int maxt = 0, t = 0, i = 0; for (int x = 0; x &lt; 4 - 1; x++) { i = x + 1; while (board[i++][y] == board[x][y]) ++t; maxt = max(maxt, t); x += t; } result += 1.0e2 * t; // 1.0e2为折算因子，数值越大则该项评分的“影响力”越大} 鼓励增加棋盘上的空位&emsp;&emsp;如果本次操作能够增加棋盘上的空位，有助于游戏的继续，则加一点点优势分。&emsp;&emsp;经过测试，这个评分项目似乎能让 AI 的发挥更稳定。统计棋盘上空位的数目，折算后加入评分即可。 测试代码以及结果&emsp;&emsp;测试代码已经上传到 GitHub : https://github.com/cyanray/Game_2048_AI &emsp;&emsp;这个 AI 能够稳定地合成出 512 这个数字，偶尔运气好能合成出 1024，但是更好的成绩就没能做到了。 &emsp;&emsp;反复修改权重也没能显著改善 AI 的发挥，可能还需要新的评分项目或者需要引入新的方案才能让 AI 有所提升。","link":"/2020/01/21/2048-%E6%B8%B8%E6%88%8FAI%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%80%9D%E8%B7%AF/"},{"title":"C++ Concepts 的两个技巧","text":"其实是 C++ 模板的技巧，本文包含两个方面：实现模板函数的“偏特化”的效果，以及阻止字符串字面量隐式转换成 bool。 模板函数“偏特化”模板函数是不能偏特化的，模板类偏特化的语法用到模板函数上编译器是不认识的。但是可以用一些模板技巧来实现偏特化的效果，当然本质还是函数的重载。这里用 C++ Concepts 来实现，其实用 SFINAE 也可以。 12345678910111213141516// 默认模板函数，返回类型的默认值（默认构造函数）template &lt;typename T&gt;T GetValue(){ return {};}// 该函数相当于 GetValue 对于 bool 的偏特化// 对于 bool 类型，需要返回 true，而不是其默认值（false）// 使用 C++ Concepts 添加约束，只有当类型 T == bool 时才实例化这个函数template &lt;typename T&gt; requires std::same_as&lt;T, bool&gt; bool GetValue(){ return true;} 字符串字面量隐式转换成bool考虑下面代码所实现的 print 函数，它有两个重载，一个用来打印 bool 值，一个用来打印任意字符串。下面的代码看起来没什么问题，但当 print 函数遇到字符串字面量（string literal）时，编译器会选择调用打印 bool 值的那个重载，而不是打印字符串的那个重载。 12345678910111213141516void print(bool v){ cout &lt;&lt; std::boolalpha &lt;&lt; v &lt;&lt; endl;}void print(string_view v){ cout &lt;&lt; std::format(&quot;\\&quot;{}\\&quot;&quot;, v) &lt;&lt; endl;}int main(){ print(false); // false print(string(&quot;Hello&quot;)); // &quot;Hello&quot; print(&quot;Hello&quot;); // true (not &quot;Hello&quot;)} 这是因为字符串字面量的本质是个数组（const char[]），编译器首先把它退化成了指针（const char*），然后隐式地将它转换为了 bool 值。 这个“从指针到 bool”的隐式转换通常用来判断一个指针是否等于 NULL。 12345int* p = static_cast&lt;int*&gt;(malloc(sizeof(int[4])));if(p){ // do sth...} 如果要阻止这种隐式转换，可以考虑的一种方案是让打印 bool 值的重载变成模板函数，然后用 C++ concepts 限制它只能接受 bool 值。 123456template&lt;typename T&gt; requires std::same_as&lt;T, bool&gt;void print(T v){ cout &lt;&lt; std::boolalpha &lt;&lt; v &lt;&lt; endl;} 其他的重载不需要修改，然后代码就可以正常工作了。","link":"/2023/04/29/C-Concepts-%E7%9A%84%E4%B8%A4%E4%B8%AA%E6%8A%80%E5%B7%A7/"},{"title":"C++17 特性:使用 std::string_view 时小心踩坑","text":"C++17 特性:使用 std::string_view 时小心踩坑 关于 std::string_view使用 std::string_view 的原因是为了避免无意义的 std::string 临时对象。 比如说，有某个函数，需要支持 C++-Style 的字符串，即 std::string 和 C-Style 的字符串，即 const char* 两种风格的字符串。最省事的写法就是只写一个 C++-Style 的版本，当传入 C-Style 字符串时，编译器会调用 std::string 的构造函数，自动创建一个 std::string 的临时对象。 12345void func(const string&amp; str);string text { &quot;Hello&quot; };func(text); // works!func(&quot;Hello&quot;); // works! 相当于: func(std::string(&quot;Hello&quot;)); 那么，如果这个函数会被经常调用，而你很在意这个临时对象，最好的方法是再写一个 C-Style 版本。 12345678// C++-Style version:void func(const std::string&amp; str);// C-Style version:template&lt;size_t N&gt;void func(const char str[N]);func(&quot;Hello&quot;); // 将会调用 C-Style version 写两个版本，临时对象的问题是解决了，但是这种解决方案并不那么优雅，这样做带来了更多的问题。 比如说，现在你需要维护两个版本的代码，它们的代码几乎一样。这个一般可以通过再实现一个 func_impl 函数来解决，也就是把具体实现挪到另一个函数。 又比如说，因为 func 的 C-Style 版本是模板函数，所以它的具体实现只能放到头文件里了。 那么 std::string_view 要如何“优雅地”解决问题呢？下面的代码使用 std::string_view 将 func 函数重写。 12345// string_view versionvoid func(std::string_view str);func(text); // works!func(&quot;Hello&quot;); // works! 而且没有临时的 std::string 对象产生！ 很多教程或者书籍都会推荐这样一个做法，一个函数有 std::string 类型的参数，如果这个参数它不会被修改，那么应该以 const-reference 的方式传递。这也就是前面 C++-Style version 的写法: 使用 const string&amp; str 而不是 string str。这样做是因为以值类型传参比以引用类型传参会多一次复制，这种复制的成本可能是高昂的，需要尽量避免。 但是也有例外，如果复制的成本很小，比如 int、double 这种简单的类型，复制的成本极低，使用引用传参甚至可能拖慢速度（比如可能阻止编译器做优化）。 这里的 std::string_view 就是这种复制成本很小的对象。所以虽然我们已经习惯了使用 const string&amp;，但是对于 std::string_view，最好不要使用引用传参，因为 std::string_view 的本质就是一个引用，使用引用的引用并不会带来更多的好处。 容易踩坑的地方标准库生态不佳虽然 std::string_view 有着那么好的优点，但是想用 std::string_view 完全替代 const string&amp; 和 const char[N] 是不会顺利的。并不是简单地把 const string&amp; 替换成 std::string_view 就可以了。 比如说，标准库的正则表达式库 std::regex 对 std::string_view 的支持就不够好。 12345678910111213141516171819202122// https://gist.github.com/WojciechMula/78f7b579abe77ebcfe38beae8d037e88std::vector&lt;std::string_view&gt; correct(){ std::vector&lt;std::string_view&gt; result; // 没有 std::svmatch 这种东西，所以必须写全类型名称 std::match_results&lt;std::string_view::const_iterator&gt; match; if (std::regex_match(input.cbegin(), input.cend(), match, re)) { for (size_t i=1; i &lt; match.size(); i++) { const char* first = match[i].first; const char* last = match[i].second; // 必须根据长度自己构建 string_view 对象 result.push_back({first, static_cast&lt;std::size_t&gt;(last - first)}); // *不要*写成：result.push_back(match[i].str()); // match[i].str() 生成了临时的 string 对象 // 而 string_view 的本质是引用 // 一个指向临时对象的引用会导致程序出错崩溃的！ } } return result;} 又比如说常用的 string to int/long long 函数，std::stoi 和 std::stoll，它们并没有提供 string_view 版本。如果你一定要将字符串转换成数字，那么只能做出修改，使用 std::from_chars 替换 std::stoi/std::stoll。 由字符串的本质引起的问题我有一个踩坑的案例可以分享。我有一个 string_view 对象，它的内容是一个 URL，我打算使用 std::regex 从中取出 hostname 和 port，这个过程没有什么问题，而且前面也分享了如何正确地对 string_view 对象使用 std::regex。 问题在于，我得到的两个对象：std::string_view hostname; 和 std::string_view port; 它们实际储存的并不是字符串片段！ 字符串的本质就是以 ‘\\0’ 结尾的 char 数组（或者宽字节 wchar 数组）。string_view 在内部也就是储存了这么一条数组的指针和一个长度。 2023-01-08 Update。 我看到一种说法，觉得挺合适的：可以把 std::string_view 理解为不以 ‘\\0’ 结尾的字符串，但所有的 C-Style API 都需要以 ‘\\0’ 为结尾的字符串，这就是我出错的原因。 那么当你调用某些需要 C-Style 字符串的 API 时，你可以没有任何开销的将 string_view 转换成 const char*，这么做的时候你不会有任何多余的想法，因为这确实是可行的，而且没有代价。 那么如果使用 C 语言的 printf 来打印 hostname 和 port，得到的结果将会是： 123456std::string url { &quot;ws://localhost:8080/chat&quot; };std::string_view hostname = getHostname(url);printf(&quot;%s&quot;, hostname.data());// 实际运行结果: localhost:8080/chat// 我期待的结果：localhost 这就导致了我调用的 C API 一直出错，我还一头雾水，一时间反应不过来为什么出错。","link":"/2022/02/16/C-17-%E7%89%B9%E6%80%A7-%E4%BD%BF%E7%94%A8-std-string-view-%E6%97%B6%E5%B0%8F%E5%BF%83%E8%B8%A9%E5%9D%91/"},{"title":"C++和C#的值类型与引用类型","text":"最近在看 《CLR Via C#》，看到这本书讨论值类型和引用类型时，我觉得很有必要做点笔记。我常常在 C++ 项目和 C# 项目之间切换，这两个语言虽然名字很像，但有很大的不同。我曾用着 C++ 的习惯来写 C# 代码，现在发现我当时对 C# 产生了很多误会。 比如两个语言常见的顺序容器。C++ 中的 vector&lt;T&gt; v; 和 C# 中的 List&lt;T&gt; l;。往容器里加入一个对象，C++ 会把这个对象完整地复制一份到 vector 里。我原以为 C# 也是这样，但其实并不是。 所以下面的代码在当时让我很困惑。 1234567var m = new MyClass();m.MemberA = 123;var list = new List&lt;MyClass&gt;();list.Add(m); // 将 m 加入 容器list[0].MemberA = 456; // 修改容器中对象的值Console.WriteLine(m.MemberA); // print 456，m 竟然被修改了！我以为会输出 123 ！ 我当时会有这样的困惑，是因为我完全不了解 C# 的类型系统。 C# 的引用类型和值类型C# 支持两种类型：引用类型和值类型。引用类型的变量存储对其数据（对象）的引用，而值类型的变量直接包含其数据。 对于引用类型，两种变量可引用同一对象；因此，对一个变量执行的操作会影响另一个变量所引用的对象。 对于值类型，每个变量都具有其自己的数据副本，对一个变量执行的操作不会影响另一个变量。[1] 微软文档给出的定义解释了我开头的困惑。MyClass 是引用类型，它的对象 m 只是储存了对数据的引用。而 List&lt;MyClass&gt;.Add 方法创造了另一个引用，所引用的数据与 m 相同。 简单来说，可以用 C++ 中指针的概念来理解引用。 C++ 应该是没有值类型和引用类型的说法的（或者说不存在与 C# 的引用类型和值类型相对应的概念）。但是 C++ 类型的行为默认是 C# 中值类型的行为。 比如函数传递参数时，C++ 和 C# 的值类型都会把参数完整复制一份。C++ 往往用传递 const 引用的方式来省去复制的开销。而 C# 可以用 ref 关键词来传递值类型的引用。 1234// C++ 每次调用 Print 都会将 string 复制一份void print(string words);// C++ 传递 const 引用节省一次复制void print(const string&amp; words); 1234// C# struct MyStringValue 是值类型，每次调用 print 都会将 string 复制一份void print(MyStringValue words);// C#void print(ref MyStringValue words); 传递引用来节省复制是 C++ 引用的常见用法。 写到这里我不知道怎么写下去了，所以就不写了。 // 未完待续。。。 C#的可空值类型本质是 Nullable 类 + 一些语法糖。c++ 也有类似的东西，也就是 std::optional。 C#的装箱与拆箱这是 C++ 没有的概念。这概念我也刚认识，下面是笔记，可能有错，建议不看。 C# 里所有类型都基于 object 类型。因此将某个值类型转换为 object 这个基类型是行得通的。 但这其中都发生了什么。要知道 object 可是引用类型，object 储存的是什么呢，是值类型变量的引用吗？ 12var p = new Point(3,4); // 假设 Point 是值类型object obj = p; // 这一步究竟发生了什么，是我们想知道的。 实际上， object 储存的是值类型变量副本的引用。将值类型转化成引用类型的机制称为装箱。 装箱做了以下的工作，来实现将值类型转化为引用类型： 在托管堆中分配足够容纳值类型的内存； 将值类型各个字段复制到托管堆申请的内存中； 返回对象的地址，也就是引用。 装箱的逆操作是拆箱。比如下面的代码，将引用类型 object 转化为值类型 int： 1int v = (int)object; 拆箱做了下面的工作[2]： 检查类型，确保可以进行转换 将值从引用的内存中复制到值类型变量 值得一提的是，在《CLR via C#》这本书里对拆箱的定义是获取值类型各个字段的地址，不包括复制的过程。 CLR分两步完成复制。第一步获取已装箱Point对象中的各个Point字段的地址。这个过程称为拆箱(unboxing)。第二步将字段包含的值从堆复制到基于栈的值类型实例中。 两个定义对我来说都是权威的，我不知道该采用哪个。 不过不管是哪个定义，应该要知道将值类型与引用类型的转换是需要复制的，是有较大成本的，应该在编写代码时避免不必要的装箱和拆箱。 参考文献[1] https://docs.microsoft.com/zh-cn/dotnet/csharp/language-reference/keywords/reference-types [2]https://docs.microsoft.com/zh-cn/dotnet/csharp/programming-guide/types/boxing-and-unboxing","link":"/2021/05/08/C-%E5%92%8CC-%E7%9A%84%E5%80%BC%E7%B1%BB%E5%9E%8B%E4%B8%8E%E5%BC%95%E7%94%A8%E7%B1%BB%E5%9E%8B/"},{"title":"C++20新特性之concept","text":"C++20的concept特性极大增强了C++的模板功能。本文简单介绍了为什么要使用concept以及concept的基本用法。 Concepts 是 C++ 模板功能的一种扩展。他被设计成编译期的一种检查措施，用于约束和限制传入模板的类型。 为什么需要 concept有的时候会有类似这样的需求，即希望传入模板的类型不是任意类型，而是包含某个特定成员的类型。 比如下面这个 GetLength 函数，它希望传入的参数的类型(即类型T)包含 iterator 类型。 进一步考虑这个函数的实现，这个函数还会期待类型T包含begin成员函数和end成员函数。 1234567891011121314template&lt;typename T&gt;size_t GetLength(const T&amp; v){ // 这里用到了类型T中的iterator类型 // 如果T类型中不包含iterator类型，会生成一大堆编译错误 typedef T::iterator iterator; // 这里用到了T类型中的begin函数 iterator it = v.begin(); // 这里用到了T类型中的end函数 iterator end = v.end(); size_t result = 0; for (; it != end; ++it, ++result); return result;} 这个 GetLength 函数的正确使用方法是： 123vector&lt;int&gt; test({1,2,3});cout &lt;&lt; GetLength(test) &lt;&lt; endl; // 输出 3cout &lt;&lt; GetLength(&quot;Hello&quot;s) &lt;&lt; endl; // 输出 5 vector&lt;int&gt; 类和 string 类中都包含 iterator 类型，而且包含 begin 和 end 成员函数，所以上面的代码可以通过编译。 由于GetLength这个模板函数没有做出限制，所以你还可以传入其他类型的参数： 1cout &lt;&lt; GetLength(123) &lt;&lt; endl; // 错误！而且是一大堆错误！ 上面的这个例子是无法通过编译的，因为字面量123的类型是int。int类型没有成员类型iterator，也没有成员函数begin和end。 你会得到类似下面这些错误： 12345678910error C2825: 'T': 当后面跟“::”时必须为类或命名空间message : 查看对正在编译的函数 模板 实例化“size_t GetLength&lt;int&gt;(T)”的引用with[ T=int]error C2510: “T”:“::”的左边必须是类/结构/联合error C4430: 缺少类型说明符 - 假定为 int。注意: C++ 不支持默认 interror C2146: 语法错误: 缺少“;”(在标识符“iterator”的前面)warning C4091: “”: 没有声明变量时忽略“int”的左侧 这些错误实在是不友好，令人摸不着头脑。 出现这些错误的原因是编译器会根据模板生成一个GetLength&lt;int&gt;(int v)函数。很显然，不存在int::iterator，也不存在v.begin()和v.end()，编译这个函数的时候肯定会报错。 这就是需要 concept 的原因之一。 使用 concept 可以约束传入模板的类型，对于不满足条件的类型，就不进行模板实例化，可以避免复杂的报错，从而方便定位错误。在介绍 concept 之前，先介绍一种不使用 concept，但是可以达到同样目的的编程技巧。(这个部分可以跳过，不影响理解 concept) 利用SFINAE原则的技巧SFINAE 是 Substitution Failure Is Not An Error 的缩写，是C++编译模板时的一个原则。这个原则的意思是：在解析模板重载时，如果无法替换模板的参数，则寻找下一个重载，而不是抛出编译错误。 123456789101112131415struct Test { typedef int foo;};template &lt;typename T&gt;void f(typename T::foo) {} // Definition #1template &lt;typename T&gt;void f(T) {} // Definition #2int main() { f&lt;Test&gt;(10); // Call #1. f&lt;int&gt;(10); // Call #2. Without error (even though there is no int::foo) // thanks to SFINAE.} 虽然 Definition #1 和 Call #2 不匹配(因为没有int::foo)，但是编译器没有就此抛出错误，而是继续尝试另一个模板重载，即 Definition #2。 SFINAE 原则最初是应用于上述的模板编译过程。后来被C++开发者发现可以用于做编译期的决策，配合sizeof可以进行一些判断：类是否定义了某个内嵌类型、类是否包含某个成员函数等。 考虑下面这个例子： 123456789101112131415161718192021222324252627282930313233#include &lt;iostream&gt;#include &lt;vector&gt;template &lt;typename T&gt;struct has_typedef_iterator { // Types &quot;yes&quot; and &quot;no&quot; are guaranteed to have different sizes, // specifically sizeof(yes) == 1 and sizeof(no) == 2. typedef char yes[1]; typedef char no[2]; template &lt;typename C&gt; static yes&amp; test(typename C::iterator*); // Definition #1 template &lt;typename&gt; static no&amp; test(...); // Definition #2 // If the &quot;sizeof&quot; of the result of calling test&lt;T&gt;(nullptr) is equal to sizeof(yes), // the first overload worked and T has a nested type named iterator. static const bool value = sizeof(test&lt;T&gt;(nullptr)) == sizeof(yes);};struct foo { typedef float iterator;};int main() { std::cout &lt;&lt; std::boolalpha; std::cout &lt;&lt; has_typedef_iterator&lt;foo&gt;::value &lt;&lt; std::endl;//true std::cout &lt;&lt; has_typedef_iterator&lt;int&gt;::value &lt;&lt; std::endl;//false std::cout &lt;&lt; has_typedef_iterator&lt;std::vector&lt;int&gt; &gt;::value &lt;&lt; std::endl;//true return 0;} 类型 foo 定义了内嵌类型 iterator，与Definition #1匹配。而Definition #1 的返回值类型为yes，因此value的值为sizeof(yes) == sizeof(yes)，即 true。 类型int没有定义内嵌类型 iterator，与Definition #1 不匹配。根据 SFINAE 原则，此时不会抛出编译错误，而是尝试另一个模板重载，即Definition #2。因为Definition #2的返回值类型为 no, value的值为sizeof(no) == sizeof(yes)，即 false。 现代C++可以用更少的代码实现上文提到的 has_typedef_iterator，参考资料[2]这篇文章提到了这一点。 enable_ifenable_if 是标准库中定义的一个模板。实际上 enable_if 的原理也是 SFINAE 原则。通过 enable_if 可以按条件约束、限制模板类型T。 下面使用 enable_if 和 has_typedef_iterator 改进前文提到的 GetLength 函数。 1234567891011template&lt;typename T, typename = std::enable_if&lt;has_typedef_iterator&lt;T&gt;::value&gt;::type&gt; // 这一行是关键size_t GetLength(T v){ typedef T::iterator iterator; iterator it = v.begin(); iterator end = v.end(); size_t result = 0; for (; it != end; ++it, ++result); return result;} 使用方法也没有任何变化： 1234vector&lt;int&gt; test({1,2,3});cout &lt;&lt; GetLength(test) &lt;&lt; endl; // 输出 3cout &lt;&lt; GetLength(&quot;Hello&quot;s) &lt;&lt; endl; // 输出 5cout &lt;&lt; GetLength(1234) &lt;&lt; endl; // 这一行是错误的! 唯一的区别是错误使用时，编译器的错误变成了： 123error C2672: “GetLength”: 未找到匹配的重载函数error C2783: “size_t GetLength(T)”: 未能为“&lt;unnamed-symbol&gt;”推导 模板 参数message : 参见“GetLength”的声明 改进之前，如果错误使用GetLength函数,编译器仍然会实例化模板，然后进行编译，从而导致一连串错误。 改进之后，错误使用GetLength函数，编译器将停止实例化模板，然后提示 未找到匹配的重载函数。 从报错的友好程度来看，这个改进简直进步巨大！ 那么这是如何做到的呢？ enable_if 的定义非常简单。标准库的代码往往都是晦涩难懂的代码，但 enable_if 的代码却很简单，下面是VC++标准库中 enable_if 的实现： 12345678// STRUCT TEMPLATE enable_iftemplate &lt;bool _Test, class _Ty = void&gt;struct enable_if {}; // no member &quot;type&quot; when !_Testtemplate &lt;class _Ty&gt;struct enable_if&lt;true, _Ty&gt; { // type is _Ty for _Test using type = _Ty;}; 如果 _Test 的值为 false，那么enable_if是一个空的struct。反之，如果 _Test 为 true，enable_if 中会定义一个成员type，默认值为void，或等于传入的_Ty。 考虑改进后的GetLength中关键的一行： 1typename = std::enable_if&lt;has_typedef_iterator&lt;T&gt;::value&gt;::type 当 has_typedef_iterator&lt;T&gt;::value 为 true 时，enable_if 包含 type 成员，因此这一句代码可以被编译器实例化。 而当 has_typedef_iterator&lt;T&gt;::value 为 false 时，enable_if 不包含任何成员，但是这里又调用了 enable_if::type，出现了不匹配，无法继续实例化。 下面的内容尚未完成… \\可能含有错误 concept如何使用前面介绍了利用 SFINAE 原则的编程技巧，下面开始介绍C++20引入的concept特性。 concept可以完全取代SFINAE技巧，而且写出来的代码更加简洁、易读。concept在编译期被计算、对模板进行约束。 定义一个concept定义 concept 的标准语法是： 12template &lt; template-parameter-list &gt;concept concept-name = constraint-expression; 比如约束类型T是类型U的派生类： 12template &lt;class T, class U&gt;concept Derived = std::is_base_of&lt;U, T&gt;::value; 将前文提到的has_typedef_iterator用concept的形式改写： 1234567template&lt;typename T&gt;concept has_iterator = requires(T v){ T::iterator; v.begin(); v.end();}; has_iterator是concept的名称。requires(T v) { /*...*/ };这部分可以看作是一个函数。这个函数包含对模板的约束。 在本例中，对模板的约束为： 类型T包含一个内嵌的类型 iterator 类型T的对象v包含名称为begin()的成员函数 类型T的对象v包含名称为end()的成员函数 使用conceptconcept有下面这三类使用方式： 方式1，将 requires 写在函数后面： 1234567891011// 方式1template&lt;typename T&gt;size_t GetLength(T v) requires has_iterator&lt;T&gt;{ typedef T::iterator iterator; iterator it = v.begin(); iterator end = v.end(); size_t result = 0; for (; it != end; ++it, ++result); return result;} 方式2，将 requires 写在 template 下方： 123456789101112// 方式2template&lt;typename T&gt;requires has_iterator&lt;T&gt;size_t GetLength(T v) { typedef T::iterator iterator; iterator it = v.begin(); iterator end = v.end(); size_t result = 0; for (; it != end; ++it, ++result); return result;} 方式3，使用concept名称取代模板关键词typename/class： 1234567891011// 方式3template&lt;has_iterator T&gt;size_t GetLength(T v){ typedef T::iterator iterator; iterator it = v.begin(); iterator end = v.end(); size_t result = 0; for (; it != end; ++it, ++result); return result;} 此外，concept还可以使用逻辑运算符 &amp;&amp; 和 ||。例如： 12345678template &lt;class T&gt;concept Integral = std::is_integral&lt;T&gt;::value;template &lt;class T&gt;concept SignedIntegral = Integral&lt;T&gt; &amp;&amp; std::is_signed&lt;T&gt;::value;template &lt;class T&gt;concept UnsignedIntegral = Integral&lt;T&gt; &amp;&amp; !SignedIntegral&lt;T&gt;; 使用concept对模板进行约束后，如果错误使用模板，会出现类似下面的错误： 123error C2672: “GetLength”: 未找到匹配的重载函数error C7602: “GetLength”: 未满足关联约束message : 参见“GetLength”的声明 模板的报错更加友好了。 requires 关键词requires 关键词总共有两个作用，一个是定义requires-expressions，用来描述和模板参数有关的约束条件;另一个是引入模板需要的约束。 123456template&lt;typename T&gt;concept has_iterator = requires(T v){/*...*/}; // 定义 requires-expressionstemplate&lt;typename T&gt;requires has_iterator&lt;T&gt; // 引入约束条件size_t GetLength(T v) {} 特别的，上面的 GetLength 函数可以写成这样： 12345678910111213141516template&lt;typename T&gt;requires requires(T v) // 注意，这里有两个 requires{ T::iterator; v.begin(); v.end();}size_t GetLength2(T v) { typedef T::iterator iterator; iterator it = v.begin(); iterator end = v.end(); size_t result = 0; for (; it != end; ++it, ++result); return result;} 标准库的concepts标准库中已经提供了一些常用的concept，位于concepts头文件中，如derived_from、integral等。 总结略 参考资料 Concepts (C++), https://en.wikipedia.org/wiki/Concepts_(C%2B%2B) C++模板技术之SFINAE与enable_if的使用 - Ying’s Blog, https://izualzhy.cn/SFINAE-and-enable_if std::enable_if - cppreference.com, https://en.cppreference.com/w/cpp/types/enable_if Templated check for the existence of a class member function? - Stack Overflow, https://stackoverflow.com/questions/257288/templated-check-for-the-existence-of-a-class-member-function","link":"/2020/11/20/C-20%E6%96%B0%E7%89%B9%E6%80%A7%E4%B9%8Bconcept/"},{"title":"Hello 2020","text":"你好20202020年的第一天，送给自己一个域名，希望能保持写博客的习惯。 123456/* 结束2019年 */delete &amp;_2019;/* 希望2020年能轻松点 */auto _2020 = &amp;new year( with::happy | with::easy );/* 启动2020年 */_2020.StartUp();","link":"/2020/01/01/Hello-2020/"},{"title":"CPU并发编程学习小结","text":"在之前接触 C++ Coroutine 的时候，看到了开源代码中关于内存序(memory order)的使用，于是想要了解一下这个内存序到底是个什么东西。结果发现相关的知识体系非常庞大，想要真正搞懂内存序是怎么来的、有什么用和什么时候用，需要搞清楚的东西根本不是一两天能学会的。本来只是想了解下内存序是什么，结果一不小心从《计算机体系结构》、《操作系统导论》一路学到了并发编程…… 这篇文章梳理一下我在探索“内存序是个什么东西”时，学到的与 CPU 并发编程相关的知识，把我以前粗略了解的很多概念全部串起来了。 并发与并行的区别并发与并行这两个概念很相似，但其实是有区别的。并行的两个任务在某个时间点同时运行，而并发则是在某一段时间内同时运行，在这段时间里两个任务可能是交替进行的。 结合一些例子说明会更好理解：一边打游戏一边喝可乐，如果暂停游戏拿起可乐喝一口再继续游戏，这就是并发；如果打游戏的同时用吸管喝可乐，这就是并行。 并发在一段时间内造成了同时进行多项任务的假象，而并行是真正的同时进行多项任务。 CPU 的并行技术通常在讨论并发和并行的时候，都是在讨论多线程编程。其实在 CPU 内部也有一些并行技术，它们旨在提高 CPU 性能。在 CPU 设计里，提升 CPU 并行性的方法有两类：一类是允许 CPU 同时执行多条指令的指令级并行技术；另一类是运行 CPU 同时执行多个任务的线程级并行技术。 指令级并行指令流水线技术可以让 CPU 同时执行多条指令，实现指令级并行。下面简单地说明他的原理，要详细地了解它可以参考《计算机组成与设计：硬件/软件接口》这本书。 对于 MIPS 指令集的 CPU 来说，一条指令的执行可以分为五个步骤：读取指令、指令解码与读取寄存器、执行指令、存储器访问和写回寄存器； MIPS 指令的格式使得它可以同时进行指令解码与读取寄存器的值。对于其他指令集的处理器，可能不止五个步骤。 在没有流水线的处理器上，上一条指令的这五个步骤要全部执行完，才可以执行下一条指令。在处理器进行指令解码和读取寄存器这个步骤时，读取指令等其他部分的电路是闲置着的。流水线技术就是让其他部分的电路也运转起来，用来执行其他的指令。 用《计算机组成与设计：硬件/软件接口》里的例子来说明，这本书用洗衣服的过程来类比 CPU 的运行过程。洗衣店的工作流程可以分为：洗衣服、烘干衣服、叠衣服和收衣服四个步骤。在烘干衣服的时候，洗衣机、叠衣服的桌子和收衣服的人都是空闲的。如果采用流水线技术，此时可以让洗衣机去洗下一批衣服，等烘干机的工作结束，把衣服放到桌子上去叠衣服，而下一批的衣服也洗好了，正好可以放到烘干机里…… 下面这张图展示了指令流水线的工作情况，在同一个 CPU 时钟周期里有多条指令同时执行。 流水线可能会遇到在下一个时钟周期里下一条指令不能执行的情况，这种情况称为冒险（hazard）。流水线冒险有很多种情况，比如跳转指令会导致控制冒险。因为在跳转的条件计算出来之前，CPU 无法确定要继续执行哪里的指令，通常的解决方法是分支预测，让 CPU 猜一个分支继续执行。如何解决流水线冒险不是本文的主题因此不继续展开。 另一种指令级并行的技术是多发射（multi-issue），意思是按顺序地一次获取多条指令并同时执行。实现了这种指令级并行的处理器称为超标量处理器（superscalar processor），标量处理器每个时钟周期最多可以完成一条指令，而超标量处理器一个时钟周期可以完成多条指令（IPC &gt; 1）。 执行单元（Execution units, EUs）是 CPU 中用于执行算数逻辑计算、分支和其他操作的独立模块。执行单元一般包括：算术逻辑单元（ALU）、浮点单元（FPU）、地址生成单元（AGU）等。 多发射是通过让 CPU 拥有多个执行单元实现的，将多条指令分配到不同的执行单元，这样指令就可以被同时执行。 这个技术的实现细节是很复杂的，因为并行执行的多条指令之间不可以有数据依赖。编译器在编译阶段可以分析指令间的数据依赖，通过调整指令的顺序以解决数据依赖问题，而且不会影响程序的执行结果。CPU 在运行阶段也可以检查指令间的数据依赖，通过动态调整指令的执行顺序来解决数据依赖问题，这让 CPU 拥有了乱序执行（out-of-order execution）的特性。 线程级并行同时多线程（Simultaneous multithreading, SMT）技术可以在单个 CPU 内核上运行多个任务。SMT 名字里的“线程”不一定是同一个进程的线程，可以是两个不同进程的线程。在 Intel CPU 里，它被称为超线程技术（Hyper-Threading, HT），就是那个让一个处理器核心变两个处理器核心的技术。 同时多线程的原理是把闲置的执行单元利用起来，只需要增加一些寄存器和其他部件来保存机器状态，就可以提升 CPU 的并行性能。 操作系统的多任务计算机的资源（CPU 资源、内存资源或硬盘资源等）由操作系统进行管理，现代操作系统将计算机的物理资源虚拟化处理，比如 CPU 虚拟化和内存虚拟化，让每个程序都以为自己拥有完整的 CPU 和完整的内存。 在只有一个核心的 CPU 上，操作系统依然可以做到同时运行多个程序，其中的原理我相信绝大多数读者都了解过。CPU 资源在时间上被划分，让一个程序使用一段时间的 CPU，然后让下一个程序使用一段时间的 CPU，如此下来，CPU 就被几个程序共享了。 如果要深入了解，推荐阅读人民邮电出版社的《操作系统导论》，原著是《Operating Systems: Three Easy Pieces》，书和翻译都很好。 这种暂停当前程序的执行并切换到另一个程序继续执行的操作，称为上下文切换（Context switch）。上下文切换要保存当前程序的程序计数器（Program Counter, PC）、CPU 当前所有寄存器的值、和内存虚拟化相关的一些值，以及其他，然后恢复另一个程序的程序计数器、寄存器值、内存虚拟化相关的值等等。 虽然看起来上下文切换的开销很大，但是除非进程或者线程很多导致上下文切换很频繁，一般来说不用考虑上下文切换的开销。 多进程和多线程都是实现并发的方法，在可靠性、资源占用、编程难易程度等方面各有优势与不足。 多进程方案在可靠性上有明显优势，多线程程序任意一条线程的异常都会导致整个程序崩溃。Chrome 浏览器和许多有限元分析软件都采用的多进程方案。 多处理器调度的问题现在的处理器基本都是多核心设计，这其实就意味着计算机实际上是有多个处理器的。对操作系统来说，多处理器的多任务调度（决定何时进行上下文切换的策略）会给程序员带来一些麻烦，下面来讨论这些问题。 缓存亲和性CPU 寄存器的访问速度很快，与之相比内存的访问速度就慢多了。缓存（Cache）是介于 CPU 寄存器和内存之间的存储器，容量比内存小很多，访问速度比内存快得多。 现代处理器的缓存是多级的，一般分为 L1、L2、L3 三个级别，容量依次增加，访问速度依次降低。L1 级缓存又会被拆分成两块，一块专门用来存储指令，另一块专门用来存储数据。下图展示了三级缓存的结构（缓存大小的数值是随便填的）。 缓存之所以能够起作用，是因为程序的执行具有局部性特征，局部性有两种：时间局部性和空间局部性。 时间局部性：当一个数据被访问后，它很快会被再次访问。比如循环变量 i 和循环体的指令本身。 空间局部性：当一个数据被访问后，很可能紧接着访问它周围的数据。比如遍历数组和指令的顺序执行。 CPU 在获取数据时会先在 L1 级缓存中寻找，如果没找到，也就是缓存未命中，那么就会到下一级 L2 级缓存寻找，还找不到就从 L3 级缓存寻找，最后从内存中获取数据。 如果频繁遇到缓存未命中，会严重影响 CPU 的运行速度。在编写程序的时候，要考虑到缓存的影响。比如操作系统的多处理器调度策略，要尽可能地让同一个进程保持在同一个 CPU 上。这是因为一个进程运行一段时间后，缓存中维护着该进程的许多状态。当该进程恢复到上一次运行的 CPU 时，缓存就能起作用。 又比如遍历二维数组时，按行遍历和按列遍历的速度是不一样的，按行遍历的速度应该会更快些。 12345678for(int row = 0; row &lt; MAX_ROW; ++row){ for(int column = 0; column &lt; MAX_COLUMN; ++column) { data[row * MAX_COLUMN + column] = 1; // 按行遍历，一行一行地遍历 data[column * MAX_ROW + row] = 1; // 按列遍历，一列一列地遍历 }} 如果指针 data 所指向的内存区域足够大，无法全部装进 L1 缓存中，那么这两种遍历方式的差距将会很大。按列访问每次访问的内存区域跨度很大，很可能会遇到缓存未命中的情况，此时 CPU 不得不去下一级缓存甚至内存中寻找数据，这就降低了效率。用“局部性”的概念来理解，按列访问不符合“空间局部性”的特点，因此缓存无法起到加速作用。 缓存一致性问题如果有多个处理器，每个处理器有自己的缓存，并且共享同一个内存，那么会出现缓存一致性（Cache Coherence）问题。 假设一个运行在 CPU 1 的程序从内存地址 A读取数据。由于数据不在 CPU 1 的缓存中，所以系统直接访问内存，得到了值 D。程序修改了地址 A 处的值，这个修改体现在只是将它的缓存更新为新的值 D’。由于将数据写回内存比较慢，因此系统通常会稍后再进行回写。假设此时操作系统中断了该程序的运行，并在稍后将其交给 CPU 2 继续运行，程序重新读取地址 A 的数据，由于 CPU 2 的缓存中没有该数据，所以又会直接从内存中读取，结果得到了旧值 D，而不是正确的值 D’。 硬件提供了这个问题的基本解决方案：监控内存访问。在基于总线的系统中，一种方式是使用总线窥探（Bus Snooping）来发现内存访问。如果 CPU 从监听到的内存访问中，发现了对它放在缓存中的数据的更新，那么会根据内存访问，作废（Invalidate）缓存的值，或更新（Update）缓存的值为新的值。 关于其中的细节，可以从缓存一致性协议：MESI 中了解到更多。 这个网站：https://www.scss.tcd.ie/Jeremy.Jones/VivioJS/caches/MESIHelp.htm 提供了一个可交互程序来学习 MESI 协议。 内存一致性问题 该内容有待完善。。。 同步问题一些基本概念考虑一个简单的例子，给变量 counter 加上数字 1，其生成的 x86 代码可能是这样的：123mov 0x8049a1c, %eax # 将变量 counter 所在内存的值移入寄存器 %eaxadd $0x1, %eax # 将寄存器 %eax 的值与数字 1 相加mov %eax, 0x8049a1c # 将寄存器 %eax 的值移回变量 counter 所在的内存 现在有多个线程（比如说有 10 条线程），循环执行（比如每条线程循环 1000 次）上面的代码。当所有线程都执行完毕，预期的结果是 counter == 10000。但实际上很可能不是 10000 这个结果，甚至每次运行的结果可能都不一样，可能是 9987 或 9876 或别的什么数字。 问题出现在线程的调度上。暂且考虑只有两条线程同时执行上述代码的情况，并将 counter 的初始值设置为 0。 第一条线程（Thread A）刚把 counter 所在内存的值移入寄存器 %eax 中，操作系统就暂停了它的执行，然后让第二条线程（Thread B）开始执行。 Thread B 也做了同样的事情，把 counter 所在内存的值移入寄存器 %eax 中，将寄存器 %eax 的值与数字 1 相加，最后将寄存器 %eax 的值移回变量 counter 所在的内存。Thread B 顺利的执行了完毕了，此时，counter 的值为 1。 然后，操作系统恢复了 Thread A 的执行，但是 Thread A 的 %eax 寄存器中储存的仍然是 counter 的旧值 0。Thread A 在旧值上加 1，再写回内存，Thread A 执行完毕了，但 counter 的值还是 1，错误就这么产生了。 这里展示的情况称为竞态条件（Race condition）：运行结果取决于代码的时间执行。 执行这段代码的多个线程可能导致竞争状态，因此我们将此段代码称为临界区（Critical section）。临界区是访问共享变量（或更一般的说，共享资源）的代码片段，一定不能由多个线程同时执行。 我们真正想要的代码就是所谓的互斥（mutual exclusion）。这个属性保证了如果一个线程在临界区内执行，其他线程将被阻止进入临界区。 这些术语都是由 dijkstra 创造的，他是该领域的先驱。 原子操作原子化(atomic) 操作：将一系列操作组合在一起，但是只有“全部完成”或“什么都没有发生”两个状态，没有中间状态。这个概念类似于数据库处理中的事务（transaction）。 对于上文中的 counter = counter + 1，如果可以原子化的进行，就不会存在竞态条件了。但存在竞态条件的代码很多，不能指望硬件提供各种各样的原子操作，这难以实现。 实际上只需要硬件提供一些有用的指令，在这些指令上构建一个通用的集合，即所谓的同步原语（synchronization primitive）。通过使用这些硬件同步原语，加上操作系统的一些帮助，就能构建多线程代码，以同步和受控的方式访问临界区，从而可靠地产生正确的结果。 解决同步问题：互斥锁与条件变量考虑将上文提及的关于 counter 自增 1 的临界区代码加上互斥锁，其代码可能如下： 1234lock_t mutex;lock(&amp;mutex);counter = counter + 1;unlock(&amp;mutex); 互斥锁就是一个变量，如上面代码中的变量 mutex。锁变量保存了锁某一时刻的状态，这个锁要么是可用的（available, unlocked, free），表明没有任何线程持有锁；要么是被占有的（acquired, locked, held），表明有一个线程持有锁，正处于临界区。 调用函数 lock() 会尝试获取锁，如果没有其他线程占有锁，那么当前线程会获得锁并进入临界区，此时当前线程被称为锁的持有者(owner)。如果其他线程正占有锁，那么这个调用不会立刻返回。直到持有锁的线程调用 unlock() 释放锁，这个调用才会返回。 锁为程序员提供了最小程度的调度控制。通过给临界区加锁，可以保证临界区内只有一个线程活跃。锁将原本由操作系统调度的混乱状态变得更为可控。 评价锁上面仅仅是介绍了锁的两个基本语义，并未涉及到锁的具体实现。下面罗列一些评估锁实现效果的标准，以便比较各种锁的实现效果。 锁是有效性。锁能否阻止多个线程进入临界区？ 锁的公平性。当锁可用时，是否每一个竞争线程有公平的机会抢到锁？是否有竞争锁的线程会饿死(starve)，一直无法获得锁？ 锁的性能。使用锁之后增加的时间开销。有几种场景需要考虑，一种是没有竞争的情况，即只有一个线程抢锁、释放锁的开支如何？另一种是一个 CPU 上多个线程竞争，性能如何？最后一种是多个 CPU、多个线程竞争时的性能。 控制中断最早提供的互斥解决方案之一，就是在临界区关闭中断。这个方案只适用于单处理器系统，关闭中断后代码就不可能被打断执行了。 但这种方案的缺点很多： 机制容易被滥用。极端的例子：一个恶意程序从运行就获取锁，然后再也不释放，操作系统将失去控制权。 不支持多处理器。如果多个线程运行在不同的处理器， 那么关闭中断也没用。 关闭中断导致中断丢失，后果严重。比如错过硬盘设备完成读取请求的中断，操作系统就无法唤醒等待读取的进程。 效率低下。开启关闭中断的操作执行的较慢。 Peterson 算法Peterson 算法是一种不依赖原子操作（这需要硬件支持）的纯软件实现的锁方案，它只支持两条线程的互斥访问。下面是它的实现代码，注意它无法在松散内存一致性模型上正常工作： 123456789101112131415161718int flag[2];int turn;void init() { flag[0] = flag[1] = 0; // 1 -&gt; thread wants to grab lock turn = 0; // whose turn? (thread 0 or 1?)}void lock() { flag[self] = 1; // self: thread ID of caller turn = 1 - self; // make it other thread's turn while((flag[1 - self] == 1) &amp;&amp; (turn == 1 - self)) ; // spin-wait}void unlock() { flag[self] = 0; // simply undo your intent} 要理解它的原理，可以先假设两个运行场景，分别进行分析：两条线程严格地按顺序调用 lock() 以及两条线程竞争调用 lock() 的情况。 如果两条线程严格地按先后顺序分别调用 lock()，即第二条线程在第一条线程调用返回后（获得锁之后）再调用 lock()，在这种情况下进行分析是很容易的。第二条线程会进入自旋循环，直到第一条线程调用 unlock() 后，使得 flag[1 - self] == 1 的条件不再满足，从而跳出自旋，调用返回，进入临界区。这说明该算法实现的锁，竞争的线程不会被饿死。 如果两条线程竞争地调用 lock()，可以先找出其中的竞态条件，容易发现竞态条件存在于 turn = 1 - self。这导致在两条线程同时调用 lock() 时，变量 turn 的值可能是 self 也可能是 1 - self，即可能是 0 也可能是 1。注意到此时 flag[0] == flag[1] == 1 总是成立，因此自旋循环的第一个条件始终满足。而第二个条件则不一定满足，但至少有一条线程满足，从而进入自旋循环。 上述粗糙的推理说明该算法实现的锁是有效的，且保证竞争的线程不会被饿死。 自旋锁在实现锁时，一个简单的想法是：用一个变量(flag)来标志锁是否被占有，如果锁被占有(flag == 1)则自旋等待，直到锁被释放（flag == 0）则跳出自旋，并重新占有锁(flag = 1)。这种简单的想法所实现的锁称为自旋锁(Spin lock)。 代码实现类似： 123456789101112131415typedef struct lock_t { int flag; } lock_t;void init(lock_t *mutex) { mutex-&gt;flag = 0; // 0 -&gt; lock is available, 1 -&gt; held}void lock(lock_t *mutex) { while(mutex-&gt;flag == 1) // Test the flag ; // spin-wait mutex-&gt;flag = 1; // acquire lock}void unlock(lock_t *mutex) { mutex-&gt;flag = 0;} 但上述的代码是无法让自旋锁正确工作的。如果让多条线程交替执行，很容易构造出一种调度方案，使得两条线程同时获得锁并进入临界区。想象有 3 条线程，其中一条线程持有锁，并即将释放锁，而另外两条线程正在自旋等待锁。当锁被释放时，如果另外两条正在自旋的线程依次跳出自旋（这样的调度情况显然存在），就会导致有两条线程同时持有锁并进入临界区。 上述代码无法正确工作的本质原因就是存在竞态条件，如果能让“测试锁是否被占有”与“占有锁”这两个步骤原子地进行，消除竞态条件，就能正常工作了。利用硬件提供的同步原语，可以实现这一点。 TestAndSet下面的代码展示了 TestAndSet 指令做了什么：12345int TestAndSet(int *old_ptr, int new) { int old = *old_ptr; // fetch old value at old_ptr *old_ptr = new; // store 'new' into old_ptr return old; // return the old value}它返回 old_ptr 指向的旧值，同时将其更新为 new 这个新的值，关键的是它们是原子地执行。利用它重新实现自旋锁的代码如下： 12345678910111213141516typedef struct lock_t { int flag;} lock_t;void init(lock_t *lock) { lock-&gt;flag = 0;}void lock(lock_t *lock) { while(TestAndSet(&amp;lock-&gt;flag, 1) == 1) ; // spin-wait}void unlock(lock_t *lock) { lock-&gt;flag = 0;} CompareAndExchangeCompareAndExchange 指令做的事情类似于下面的代码：123456int CompareAndExchange(int *ptr, int expected, int new) { int actual = *ptr; if(actual == expected) *ptr = new; return actual;}比较并交换的基本思路是检测 ptr 指向的值是否和 expected 相等；如果是，更新 ptr 所指的值为新值。否则，什么也不做。不论哪种情况，都返回该内存地址的实际值，让调用者能够知道执行是否成功。 使用比较并交换实现的 lock() 函数：1234void lock(lock_t *lock) { while(CompareAndSwap(&amp;lock-&gt;flag, 0, 1) == 1) ; // spin-wait} Link-Load &amp; Store-Conditional链接的加载（load-linked）和条件式存储（store-conditional）的配合使用也可以实现锁。 链接的加载和典型的加载指令类似，都是从内存中取出值存入一个寄存器。 条件式存储指令只有在上一次加载的地址没有更新时，才会成功。成功时，条件存储返回 1，并更新值。失败时，返回0，并且不会更新值。 用这两条指令实现的 lcok() 函数：1234void lock(lock_t *lock) { while(LoadLinked(&amp;lock-&gt;flag) || !StoreConditional(&amp;lock-&gt;flag, 1)) // 注意条件短路 ; //spin-wait} 评价自旋锁现在按照之前罗列的标准来评价自旋锁。 首先，正确性。毫无疑问，自旋锁是正确的锁。 然后，公平性。自旋锁不提供任何公平性保证，可能导致饿死。比如三条线程竞争锁，其中两条线程轮番获得锁，而另一条线程永远在自旋。 最后，性能。在单 CPU 的情况下，自旋锁性能开销相当大。假设一条线程持有锁，调度器运行其他的每一个线程时，它们都在自旋，使得任务没有任何进展。在多 CPU 上，如果线程数大致等于 CPU 数，性能表现不错。 Ticket锁Ticket 锁是使用硬件原语 FetchAndAdd 指令实现的。FetchAndAdd 能原子地返回特定地址的旧值，并且让该值自增一。 Ticket 锁的代码实现如下：12345678910111213141516171819202122232425int FetchAndAdd(int *ptr) { int old = *ptr; *ptr = old + 1; return old;}typedef struct lock_t { int ticket; int turn;} lock_t;void lock_init(lock_t *lock) { lock-&gt;ticket = 0; lock-&gt;turn = 0;}void lock(lock_t *lock) { int myturn = FetchAndAdd(&amp;lock-&gt;ticket); while(lock-&gt;turn != myturn) ; // spin-wait}void unlock(lock_t *lock) { FetchAndAdd(&amp;lock-&gt;turn);} 不同于自旋锁，Ticket 锁保证所有线程都能抢到锁，只要一个线程获得了 Ticket 值，它最终会被调度。 解决自旋太多不必要的自旋是在浪费 CPU 时间，有两种避免自旋的方法： 让出时间片。yield 原语可以让线程主动放弃 CPU，让其他线程进行。 休眠代替自旋。维护一个队列，如果锁不可用，则休眠并加入队列；当锁的持有者释放锁时，从队列中恢复一条线程的执行。 让出时间片的方案虽然避免了自旋，但是上下文切换的开销没法避免，而且也没能避免饿死的情况。 以休眠代替自旋的方案则没有这两个问题，但是具体实现上需要小心竞态条件。 更多细节阅读 《操作系统导论》 Section 28.14。 二阶段锁两阶段锁（Two-phase lock）意识到自旋可能很有用，尤其是在很快就要释放锁的场景。因此，两阶段锁的第一阶段会先自旋一段时间，希望它可以获取锁。但是，如果第一个自旋阶段没有获得锁，第二阶段调用者会睡眠，直到锁可用。 条件变量 该部分内容有待完善… 使用互斥锁导致的问题死锁死锁(Deadlock)是类似这样一种情况： 有 2 个线程同时执行，并且都需要访问共享资源 A 以及共享资源 B； 线程 1 获得了共享资源 A 的锁，线程 2 获得了共享资源B的锁； 线程 1 尝试获得共享资源 B 的锁，但是因为这个锁已经被线程 2 占有，因此它失败了，进入休眠状态； 类似的，线程 2 尝试获得共享资源 A 的锁，因为锁已经被线程 1 占有，因此也休眠了； 最后，两条线程都进入了休眠状态，系统的执行不再有进展，形成了死锁。 我在查阅资料时，注意到了形成死锁的四个条件（禁止抢占、持有和等待、互斥、循环等待），因此避免死锁的方法就是破坏这四个条件之一。 但我感觉根据那四个条件来解决死锁等于没说。我认为比较合适的预防死锁的方式是：当需要获得多个资源的锁时，获取锁的顺序应当保证全局一致。 活锁活锁(Livelock)与死锁类似，处于活锁状态的系统虽然有任务在执行，但是依然没有任何推进。以下是一个可能导致活锁的情况： Thread A 尝试获取 Resource X 的锁。 Thread B 尝试获取 Resource Y 的锁。 Thread A 发现 Resource X 的锁已经被 Thread B 获取，它释放 Resource X 的锁并等待。 Thread B 发现 Resource Y 的锁已经被 Thread A 获取，它释放 Resource Y 的锁并等待。 Thread A 和 Thread B 同时重新尝试获取资源的锁。 重复步骤 3 和步骤 4 。 在这个例子中，Thread A 和Thread B 由于竞争资源而无法进展，导致它们不断尝试重新获取资源的锁，但最终都无法成功。这种情况下，线程们一直在等待对方释放资源，而没有任何一个线程能够进一步执行，形成了活锁。 为了解决活锁问题，可以使用一些策略，如引入随机性的等待时间、重新尝试获取资源的锁的顺序调整或者引入一个调度策略来打破竞争的循环，以确保线程能够顺利地获取资源并继续执行。 优先级反转任务可以分优先级，在调度时，高优先级的任务在需要执行时可以打断低优先级任务的执行。优先级反转是这样一种情况： 有 3 个线程，优先级由高到低分别是：线程 1、线程 2、线程 3； 有一个共享资源，线程 1 与线程 3 需要访问这个共享资源； 最低优先级的线程 3 持有共享资源的锁，正在执行； 线程 1 打断了线程 3 的执行，但是因为未获得锁，休眠了； 线程 2 获得了时间片，得以执行； 线程 3 继续执行，并释放了锁； 最高优先级的线程 1 终于可以执行； 上述的过程中，虽然线程 1 有着最高优先级，但实际上却是最后才能执行，这样的情况就是优先级反转（Priority Inversion）。 无阻塞算法 没学会… 无阻塞算法（Non-blocking algorithm）常被称为“无锁编程”。无锁编程常被理解为“没有使用互斥锁的编程算法”，这个理解是正确的，因为只要使用了锁就不会是无阻塞算法，但没有反映出“无阻塞”的本质。 wait-free、lock-free 和 obstruction-free。 其中 lock-free 指的是不会导致总体任务进度被锁住（lock up）的算法，而不是不用互斥锁的算法。 ABA 问题基于事件的并发 未完待续… 总结有许多关于并发编程的内容来自于《操作系统导论》，这是我当时阅读这本书时意想不到的。 更新记录 2023-07-15: 完成后半部分； 2022-08-22: 只完成了小部分内容；","link":"/2022/08/22/CPU%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0%E5%B0%8F%E7%BB%93/"},{"title":"UWP程序开发的一些心得体验","text":"因为想要一个为自己量身定制的英汉字典程序，所以就开始了自己的第一次UWP程序开发。 动机我的需求其实非常简单，有一个软件能够查词就行了，包括英汉释义和英英释义，最好来点例句。但是我的查词习惯是随时可能查词，查完就关掉软件，所以很多巨无霸词典软件我都不喜欢，启动速度太慢了，还给我来几个弹窗广告。 我最常用的英汉词典程序是微软必应词典(UWP)，它的启动速度、查词速度都非常快，而且没有广告，没有弹窗，完美符合我的需求。 非常可惜的是，微软必应词典很久没更新了，它的 UI 实在是太丑了(在 Win11 带来最新的设计之后，我已经看不下去它的设计了)。 所以我就打算偷必应词典的API，自己做个词典程序。因为我的需求本身比较简单，所以这个程序难度不算很大。 我希望这个词典程序有 Win11 Style 的设计，所以选择其实不多，有三个：WinUI 2(UWP) 或者 WinUI 3(WindowsAppSdk、MAUI)。 在我项目开始的时候，WinUI 3 才刚出 Preview 1，还没有带来 Win11 Style，所以这个方案不能选，只能使用 UWP 方案了。 流畅的开发体验我之前开发过 WPF 程序和 Xamarin 程序，所以对 XAML 这一套还是比较熟悉的。这三套方案都用 XAML 来描述 UI 布局，虽然语法一样，但是细节还是有些不同。比如 UWP 就没有 DockPanel 这样的布局，比如 Xamarin 和 UWP 的 Grid 用法略有不同。 要了解这些，主要还是看微软的文档。微软的文档写的很详细，所以文档上有的内容基本没遇到问题，大多符合直觉。 主题支持未完待续。。。 多语言支持未完待续。。。 遇到的一些问题当然还是会有问题的啦。 自定义标题栏处无法修改窗口大小这个问题的具体表现是设置自定义标题栏区域后，无法通过顶部那块区域修改窗口的大小。我换了很多种关键词去搜索，都没搜到类似的问题，就好像我是全网第一个遇到这个问题的人。我又是抄的微软文档的代码，所以我就先入为主觉得代码是没问题的，以为是哪里不兼容。于是我先把 WinUI 库降级，又降级了很多库，问题依旧。 最后我发现，微软文档提供的代码让自定义标题栏区域顶部多了 8 个单位的 Margin。自定义标题栏顶部和窗口边缘没挨在一起，所以不能通过自定义标题栏修改窗口大小。 不知道如何自定义主题也就是 DarkTheme、LightTheme 的设置。默认是自动跟随系统的，但是很多软件都支持自定义主题，所以我也想加入这个功能，但是找了半天没有找到相关的文档。 这个问题的解决方法是抄微软开源的计算器的代码(Calculator)。 。未完待续。。。","link":"/2021/10/23/UWP%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91%E7%9A%84%E4%B8%80%E4%BA%9B%E5%BF%83%E5%BE%97%E4%BD%93%E9%AA%8C/"},{"title":"使用CMake组织C++项目","text":"使用CMake组织C++项目 前言如果你使用过 Visual Studio 或者其他 IDE，那么应该能体验到这些 IDE 在组织 C++ 项目源代码时的便利。使用 Visual Studio 创建的项目往往依赖于一个 sln 文件，只要用 Visual Studio 打开这个 sln 文件，就能打开一个文件结构清晰的 C++ 项目。哪些文件应该被包括到项目中，哪些排除在外，都被 Visual Studio 记录得很好。 大多数情况下，使用 Visual Studio 来组织 C++ 源代码很方便，但也有一些例外的情况。比如 sln 文件有自己的版本，使用新版 Visual Studio 创建的 sln 文件在旧版 Visual Studio 有可能打不开。直接分享 Visual Studio 项目的体验可能不会很好，因为不是所有人装上 Visual Studio 都能直接打开你的项目。 接下来我想介绍的是 CMake 。虽然 CMake 不是专门用来解决上面说的这个问题，但是借助 Visual Studio 或者其他 IDE 管理项目的方式，可以很快理解 CMake 是怎么组织 C++ 项目的。 CMake 是一个工具，它用一些命令(有点像函数)来描述一个项目的安装/编译过程。CMake 描述的内容包括有哪些头文件、源代码文件、依赖哪些第三方库等等。 Cmake 并不直接建构出最终的软件，而是产生标准的建构档（如 Unix 的 Makefile 或 Windows Visual C++ 的 projects/workspaces），然后再依一般的建构方式使用。 快速入门下面借助 Hello World 项目来说明 CMake 是如何工作的。这个项目非常简单，只有一个源文件 main.cpp，没有头文件。使用 CMake 来描述编译 main.cpp 的过程，需要把描述编译过程的 CMake 命令放在 CMakeLists.txt 文件里。因此一个使用 CMake 管理的项目（以下简称 CMake 项目）可能会像这样： 123.├── CMakeLists.txt└── main.cpp main.cpp： 123456#include &lt;iostream&gt;int main(){ std::cout &lt;&lt; &quot;Hello World!&quot; &lt;&lt; std::endl; return 0;} CMakeLists.txt： 12project(hello-world)add_executable(${PROJECT_NAME} main.cpp) 正如使用 Visual Studio 创建的项目一样，CMake 项目也有项目名称，项目类型等概念。在 CMakeLists.txt 文件中，命令 project(hello-world) 描述该 CMake 项目的名字是 hello-world。而命令 add_executable(${PROJECT_NAME} main.cpp)，则描述该 CMake 项目有一个可执行文件，名字是 ${PROJECT_NAME}，源文件有一个，是在当前目录下的 main.cpp。 可以用变量的方式理解 ${PROJECT_NAME}，因此它的内容就是由 project 命令定义的 hello-world。 使用 Visual Studio 2019 (好像有的旧版 Visual Studio 也能打开 CMake 项目) 打开 CMake 项目所在的文件夹，按照 VS 的提示就可以编译运行了。 常用的 CMake 命令以下介绍一些常见 CMake 命令的简单用法。之所以是简单的用法，是因为这些命令非常灵活，一篇文章难以介绍全面，了解他们的最好的方式是阅读 官方文档。 创建可执行文件项目 使用 add_executable(&lt;project name&gt; &lt;src&gt;) 命令可以创建一个可执行程序项目。 使用方法： 123456# 简单写法add_executable(hello-world main.cpp)# 稍微复杂点的写法add_executable(${PROJECT_NAME} main.cpp)# 如果有多个源文件add_executable(${PROJECT_NAME} a.cpp b.cpp c.cpp) 让CMake找到我的源文件 如果源文件太多了，可以把源文件都放到一个目录里。比如把所有的源文件都放在了 src 目录里。 使用 aux_source_directory(&lt;src_dir&gt; &lt;var_name&gt;) 命令把 src_dir 目录下的所有源文件都放到 var_name 变量里。 使用方法： 12345aux_source_directory(./src SRCS)# 可执行程序add_executable(${PROJECT_NAME} ${SRCS})# 静态链接库add_library(${PROJECT_NAME} STATIC ${SRCS}) 注意：aux_source_directory 不会递归包含子目录，而且在源代码目录新增源文件后，要刷新 CMake 缓存才能生效。 让CMake找到我的头文件 用 include_directories(&lt;dir&gt; [dir2] [dir3] ...) 命令设置头文件目录，告诉 CMake 应该到哪些目录里寻找头文件。如果用 target_link_libraries() 让构建目标链接一个库，可以不对这个库的头文件目录使用这个命令，具体参考下文。 使用方法：1include_directories(./include) 创建库项目 使用 add_library(&lt;project name&gt; &lt;type&gt; &lt;src&gt;) 命令可以创建一个库项目。 使用 target_include_directories(&lt;project name&gt; &lt;INTERFACE|PUBLIC|PRIVATE&gt; &lt;include_dir&gt;) 设置库的头文件目录。为了让链接本库的项目能够正常使用，一般设置 PUBLIC 属性。 使用方法： 123456789101112# 静态链接库add_library(${PROJECT_NAME} STATIC a.cpp b.cpp c.cpp)target_include_directories(${PROJECT_NAME} PUBLIC ./include)# 或者：add_library(${PROJECT_NAME} STATIC ${SRCS})target_include_directories(${PROJECT_NAME} PUBLIC ./include)# 动态链接库add_library(${PROJECT_NAME} SHARED ${SRCS})target_include_directories(${PROJECT_NAME} PUBLIC ./include)# Header-Only 库add_library(${PROJECT_NAME} INTERFACE)target_include_directories(${PROJECT_NAME} PUBLIC ./include) 常用的项目结构上面介绍了几个常用的 CMake 命令，接下来结合实际项目常用的结构，谈一谈 CMakeLists.txt 的写法。 简单的可执行文件项目 简单的可执行项目，包括一些头文件、一些 C++ 源文件，其文件结构大致如下： 123456.├── CMakeLists.txt├── include│ └── hello.h└── src └── main.cpp CMakeLists.txt: 12345678# 项目名称 hello-worldproject(hello-world)# 从 src 目录搜索源文件aux_source_directory(./src SRCS)# 创建可执行文件项目add_executable(${PROJECT_NAME} ${SRCS})# 从 include 目录里查找头文件include_directories(./include) 带有 examples 的库项目 对于库项目，我个人一般会写一些 examples。这样可以方便实时执行库代码，同时顺便写了使用样例，方便给别人参考。 12345678910.├── CMakeLists.txt├── examples│ ├── CMakeLists.txt│ ├── A.cpp│ └── B.cpp├── include│ └── hello.h└── src └── hello.cpp ./CMakeLists.txt: 1234567891011# 项目名称 hello-worldproject(hello-world)# 从 src 目录搜索源文件aux_source_directory(./src SRCS)# 创建静态库项目(也可以改成 SHARED 变成动态库)add_library(${PROJECT_NAME} STATIC ${SRCS})# 设置使用库文件所需要的头文件target_include_directories(${PROJECT_NAME} PUBLIC ./include)# 这个命令让 CMake 进入到指定子目录进行项目构建，这个目录也得有 CMakeLists.txt 文件add_subdirectory(examples) ./examples/CMakeLists.txt: 1234567891011121314151617# 项目名称，因为这个是库的样例项目，不是库的一部分，所以另取一个名字project(hello-world-examples)# 创建一个宏来快速创建可执行文件macro(api_exe target) add_executable(${PROJECT_NAME}-${target} ${target}.cpp ) # 注意这里要设置对库的链接 target_link_libraries(${PROJECT_NAME}-${target} hello-world)endmacro()# 使用宏来快速创建可执行文件api_exe(exampleA)api_exe(exampleB)api_exe(exampleC) 结语这篇文章只是简略地总结了 CMake 的大概用法，没有细致地讲解 CMake 以及其命令。关于 CMake 更详细地用法，推荐读者结合官方文档以及其他文章慢慢探索。阅读开源项目的 CMakeLists.txt 也是个好做法，不过那些文件经过多年积累，内容多且复杂，读不懂也不要灰心(读不懂的还有我😭)。","link":"/2020/03/03/%E4%BD%BF%E7%94%A8CMake%E7%BB%84%E7%BB%87C-%E9%A1%B9%E7%9B%AE/"},{"title":"Modern CMake 实践","text":"随着 CMake 版本的迭代变更，使用 CMake 组织项目文件的方法也累积出了很大的变化。考虑到还有不少 CMake 教程停留在一些基础用法，我决定结合我的经验谈谈 CMake 在稍微复杂一些项目上的实践经验。 前言CMake 其实不止能管理 C++项目，但是这里只讨论用 CMake 管理 C++ 跨平台项目的情况。本文所用的 CMake 特性，最低所需的版本是 CMake 3.20 版本。阅读本文需要有一定的 CMake 基础。 如何组织项目结构？全凭个人喜好，我目前习惯的结构是： 1234567891011121314ProjectName/├── ProjectA/│ ├── include/│ ├── src/│ └── CMakeLists.txt├── ProjectB/│ ├── include/│ ├── src/│ └── CMakeLists.txt├── UnitTest/│ ├── ProjectA/│ ├── ProjectB/│ └── CMakeLists.txt└── CMakeLists.txt 在书籍《Modern CMake for C++》中推荐的结构是： 12345678910111213Project/├── cmake/│ ├── include│ ├── module│ └── script├── src/│ ├── app1│ ├── app2│ ├── lib1│ └── lib2├── doc/├── test/└── CMakeLists.txt CMakeLists.txt 起手式下面三行几乎每个文件都必须有，分别是：设置 CMake 所需最低版本、项目名称和版本（后面 install 部分要用到）、设置 C++ 标准。 123cmake_minimum_required(VERSION 3.20)project(ProjectName VERSION 1.0.0)set(CMAKE_CXX_STANDARD 20) 如何添加源代码？视头文件为源代码的一部分头文件会在编译前被前处理器载入，简单地粘贴到到引用它的 C++ 源文件中。所以不把头文件加入到 CMake target 的源文件列表中不会影响编译。但是更好的做法是，把头文件也视为源文件的一部分，加入到源文件列表中。 因为这样做是 “IDE 友好” 的。如果你创建了一个头文件，它没有被任何的源文件引用，也没有被加入到 CMake target 的源文件列表中，我常用的 IDE（CLion）会拒绝对它进行分析，只有基础的语法高亮，而没有编写代码的提示。 记得仍然要设置 target 的头文件的目录：123target_include_directories(TargetName PUBLIC $&lt;BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/include&gt; $&lt;INSTALL_INTERFACE:include&gt;) aux_source_directory优点：简单缺点：IDE 不友好。有新的源文件时必须手动重新建立 CMake 缓存，IDE 不会自动刷新 CMake 缓存。 简单列出的文件列表优点：IDE 友好。添加源文件时必须修改 CMakeLists.txt 文件，IDE 会自动刷新 CMake 缓存。缺点：手动添加每一个文件比较繁琐，但是如果通过 IDE（Visual Studio、CLion）添加头文件或源文件，有自动修改 CMakeLists.txt 源文件列表的功能。 更复杂的文件列表 印象中见过，但博主还没用过，学会了再给大伙总结下优缺点。 如何创建库项目？这一节简要解释两个常见的问题：如何创建跨平台动态库？以及如何让自己的库可以被 “CMake install”，然后被 CMake 中的 “find_package” 找到。 静态链接库与动态链接库在 CMake 中创建静态链接库或是动态链接库，仅仅是 add_library 命令的第二个参数有区别。 12add_library(lib_name STATIC lib.h lib.cpp) # 静态链接库add_library(lib_name SHARED lib.h lib.cpp) # 动态链接库 决定使用动态链接库或静态链接库的因素有很多，比如使用动态链接库可以做到按需加载、替换自身达到功能升级等。甚至在链接开源程序时，考虑使用动态链接可以避免被开源许可证污染。使用静态链接也有一些好处，比如编译产物有更小的体积，或得到单文件程序。 我个人推荐的做法是，把决定权交给库的使用者，让他来决定编译成静态链接库还是动态链接库。这可以用下面的代码做到： 1234567891011option(LibName_BUILD_SHARED_LIBS &quot;Build LibName as a shared library.&quot; OFF)if (LibName_BUILD_SHARED_LIBS) set(LIBRARY_TYPE SHARED) set(CMAKE_WINDOWS_EXPORT_ALL_SYMBOLS ON)else () set(LIBRARY_TYPE STATIC)endif ()set(SOURCE a.hpp a.cpp)add_library(LibName ${LIBRARY_TYPE} ${SOURCES}) 上面的代码首先是创建了一个 Boolean 选项，默认值为 OFF，用来控制是否编译成动态链接库。 如果编译为动态库，则变量 ${LIBRARY_TYPE} 为 SHARED，否则为 STATIC。这样，库的使用者就可以在生成 CMake 缓存时决定要将这个库编译成什么。 另外，在编译成动态库时，还做了一步就是将 CMAKE_WINDOWS_EXPORT_ALL_SYMBOLS 设置为 On。设置这个之后，在编译 Windows 平台的动态链接库，会默认导出所有的符号（除了全局变量）。下面会有更多的解释。 最后，为了做到 “IDE友好”，我建议将源文件列表单独放到一个变量中，即 ${SOURCES}。如果不这么做，CLion 会把 ${LIBRARY_TYPE} 误认为是源文件列表。每次通过 CLion 添加源文件时，CLion 都会想要把新的源文件添加到变量 ${LIBRARY_TYPE} 末尾。 （Visual Studio 暂未做测试） GCC 编译的动态链接库，默认是导出所有符号的。而 MSVC 编译的动态链接库，默认是不导出任何符号的。 说实话这一块知识我没具体探究过，比如是否 MinGW 的 g++ 编译器也不需要指定要导出的符号？挖坑以后再研究… 因此在使用 MSVC 编译动态链接库时，需要在代码中使用 __declspec(dllexport) 指定要导出的符号：全局变量或常量、函数、类。而如果要使用 DLL 中符号，则需要在符号的声明中指定 __declspec(dllimport)。具体规则可以见微软的文档，General Rules and Limitations 一般来说会定义一个宏，在编译动态库时标记为 __declspec(dllexport)，而在使用动态库时标记为 __declspec(dllimport)。 1234567891011#if defined(LibName_STATICLIB)# define EXPORTED#elif defined(_WIN32) # if defined(LibName_WIN_EXPORT)# define EXPORTED __declspec( dllexport )# else# define EXPORTED __declspec( dllimport )# endif#else# define EXPORTED#endif 在编译动态链接库时，定义宏 LibName_WIN_EXPORT。在使用静态链接库时，定义宏 LibName_STATICLIB。在使用动态库时，则什么也不定义。 12target_compile_definitions(TargetName PRIVATE LibName_WIN_EXPORT) # 编译动态链接库时添加该行target_compile_definitions(TargetName PRIVATE LibName_STATICLIB) # 使用静态链接库时添加该行 对于要导出的符号，使用宏 EXPORTED 修饰。 1234class EXPORTED Utility{ // ...}; 上文提到，CMake 提供了一个变量 CMAKE_WINDOWS_EXPORT_ALL_SYMBOLS，当它为 On 时，会导出所有的符号（除了全局变量）。我推荐用这个方法，因为用了它之后，就不需要给每一个要导出的符号指定 __declspec(dllexport) 和 __declspec(dllimport) 了。 让你的库能被 find_package 找到find_package 做了什么？CMake 中的 find_package 有两种模式：Module 模式和 Config 模式。下面只是简要介绍，建议大家阅读 CMake 的详细文档。 在 Module 模式下，CMake 会在 CMAKE_MODULE_PATH 中寻找 Find&lt;PackageName&gt;.cmake 文件。这个 cmake 文件负责寻找 package 的安装路径并检查版本是否符合要求。 Module 模式并不常用，一般都使用 Config 模式。比如下面这段很常见的代码，CONFIG 指的就是 Config 模式。REQUIRED 表示这个库是必须的，如果没找到这个库就中止 CMake 脚本的运行。 1find_package(PackageName CONFIG REQUIRED) 在 Config 模式下，CMake 会去寻找 &lt;lowercasePackageName&gt;-config.cmake 或 &lt;PackageName&gt;Config.cmake 文件（下面简称 config.cmake）。如果指定了版本号，还会去寻找 &lt;lowercasePackageName&gt;-config-version.cmake 或 &lt;PackageName&gt;ConfigVersion.cmake 文件（下面简称 version.cmake）。 通过指定缓存变量 &lt;PackageName&gt;_DIR 的值，来告诉 CMake 应该去哪里寻找 config.cmake 和 version.cmake 这两个文件。 这两个文件通常和库的安装目录放在一起。而且它们通常不是库作者自己写的，而是通过一系列 CMake 脚本自动生成的。 使用 install 指令要让自己的库能被别人使用 find_package 指令找到，必须要生成 config.cmake 文件和 version.cmake 文件。除此之外，还要复制编译产物、头文件目录等。 下面两段代码来自我自己的一个项目 Truss。先贴出来看看，有个整体的概念，再做进一步分解。 下面的代码中涉及到两个项目：LibTrussSolver 依赖 LibTrussDocument，因为 LibTrussDocument 项目是在上一级目录中通过 add_subdirectory 找到的，所以要一起被 install。另外 LibTrussSolver 依赖第三方库 Eigen，LibTrussDocument 依赖第三方库 magic_enum。 下面的代码可以作为模板使用，只需要把项目名称替换成自己的就可以用了。 123456789101112131415161718192021222324252627282930313233343536# CMakeLists.txtoption(LibTrussSolver_INSTALL &quot;INSTALL_LibTrussSolver&quot; ON)if (LibTrussSolver_INSTALL) include(CMakePackageConfigHelpers) write_basic_package_version_file( LibTrussSolverConfigVersion.cmake VERSION ${PACKAGE_VERSION} COMPATIBILITY AnyNewerVersion ) install(DIRECTORY include DESTINATION ${CMAKE_INSTALL_PREFIX} ) install(TARGETS LibTrussSolver LibTrussDocument # 两个项目要一起被导出，因为 LibTrussSolver 依赖 LibTrussDocument。 EXPORT LibTrussSolverTargets RUNTIME DESTINATION bin ARCHIVE DESTINATION lib LIBRARY DESTINATION lib ) install(EXPORT LibTrussSolverTargets FILE LibTrussSolverTargets.cmake NAMESPACE Truss:: DESTINATION cmake/LibTrussSolver ) configure_file(LibTrussSolverConfig.cmake.in LibTrussSolverConfig.cmake @ONLY) install(FILES &quot;${CMAKE_CURRENT_BINARY_DIR}/LibTrussSolverConfig.cmake&quot; &quot;${CMAKE_CURRENT_BINARY_DIR}/LibTrussSolverConfigVersion.cmake&quot; DESTINATION cmake/LibTrussSolver )endif (LibTrussSolver_INSTALL) 12345678910# LibTrussSolverConfig.cmake.ininclude(CMakeFindDependencyMacro)# 被导出的项目的所有依赖都要写在这里find_dependency(magic_enum REQUIRED) # LibTrussDocument 的依赖find_dependency(Eigen3 REQUIRED) # LibTrussSolver 的依赖if(NOT TARGET LibTrussSolver) include(&quot;${CMAKE_CURRENT_LIST_DIR}/LibTrussSolverTargets.cmake&quot;)endif() 上面的代码中，write_basic_package_version_file 和 configure_file 的作用分别是创建 version.cmake 文件和 config.cmake 文件。 在 write_basic_package_version_file 中，COMPATIBILITY AnyNewerVersion 指的是，如果版本号比指定的版本号新，那么就认为是兼容的。还有其他的兼容模式可以选择，比如主版本号一致才认为是兼容的，具体见 CMake 的文档。 configure_file 指令的作用是将 LibTrussSolverConfig.cmake.in 文件复制为 LibTrussSolverConfig.cmake。（该指令会在复制过程中进行了一些变量替换的处理，但是这个特性在我们的例子中没有用到） 而在文件 LibTrussSolverConfig.cmake.in 中，指定了两个依赖（根据自己项目的实际情况进行修改，可能更多依赖，也可以能没有依赖），并且包含了 LibTrussSolverTargets.cmake 文件（下面简称 targets.cmake）。 这个 targets.cmake 文件是由 install(TARGETS) 和 install(EXPORT) 两个指令生成的。 突然发现我对这两个命令的细节并不那么了解，还需要学习一下，再完善这部分。 至于 install(DIRECTORY) 和 install(FILES) 的作用则是复制 头文件目录 和 config.cmake, version.cmake 到安装目标路径。 杂项设置编译器参数通常跨平台项目的源代码都是 utf-8 编码（因为这是 Linux 系统的默认系统编码）。但是，MSVC 编译器对 utf-8 编码的源文件支持不好，需要额外为 MSVC 编译器设置 /utf-8 参数才能正常编译 utf-8 编码的源文件，否则会出现很多编译错误。 我常使用下面两行代码为 MSVC 编译器添加 /utf-8 参数。这两行代码用到了 CMake Generator Expressions。 如果编译器是 MSVC，那么这个表达式的值就是 /utf-8，CMake 会添加它作为编译参数。如果编译器不是 MSVC，那么这个表达式的值是空文本，add_compile_options 遇到空文本是不会起作用的。12add_compile_options(&quot;$&lt;$&lt;C_COMPILER_ID:MSVC&gt;:/utf-8&gt;&quot;)add_compile_options(&quot;$&lt;$&lt;CXX_COMPILER_ID:MSVC&gt;:/utf-8&gt;&quot;) 设置 C++ 标准通过设置 CMAKE_CXX_STANDARD 变量的值来要求编译采用指定的 C++ 标准：1set(CMAKE_CXX_STANDARD 20) # 其他取值：98、11、14、17、20、23 上面那个是全局设置，下面的指令可以针对某个 target 来设置： 1set_property(TARGET &lt;target&gt; PROPERTY CXX_STANDARD &lt;standard&gt;) 总结使用 CMake 组织项目结构时，不应局限于让项目正常编译，还要考虑到和 IDE 的适配效果，即所谓的 “IDE 友好”。不友好的 CMake 脚本可能会阻碍 IDE 智能感知代码的能力（比如智能提示、查找函数或变量的引用、重构功能等）。 写一半发现，我还需要再学习一下。","link":"/2023/03/06/Modern-CMake-%E5%AE%9E%E8%B7%B5/"},{"title":"今日校园APP逆向分析","text":"为了做个自动填表工具，抓包、分析了下今日校园。本篇文章非常长，讲述了整个逆向分析的过程。分析过程对逆向和反逆向或许都有启发。 准备阶段疫情每日填报实在是太烦了，这种机械化的事情，交给软件去做最好了。 打开 HttpCanary 抓包，什么都看不到，而且今日校园表现是断网的样子。我的手机是安装了 HttpCanary 的根证书的。看来今日校园用了 SSL Pinning 来阻止抓包。 这一步其实是比较好办的，对于常见的 http 库，可以用 Xposed + JustTrustMe (还有一个类似的 Xposed 插件：Unpinning)来 hook 信任证书相关的函数，让程序即使是抓包软件的证书也表现为信任，就可以抓包了。 但我的 K30 升级到 Android 11 后，尝试了很多次都装不上 Magisk 和 Xposed。我又没有其他的安卓设备，所以就只能用虚拟机了。 然而今日校园连电脑上的安卓模拟器都防住了，安卓模拟器一打开今日校园就直接闪退。把apk解压缩看了看，发现只有armabi-v7a。说明今日校园无法在 X86 的安卓上运行。 电脑的安卓模拟器不行，那就试试手机的安卓模拟器。我用的是 VMOS Prp(虚拟大师)，直接装了个 Android 5.x 的系统，省的要想办法绕开 SSL Pinning。 VMOS Pro 还是挺好用的，连 ADB 之类的都考虑好了，设置页面能一键打开。 抓包软件我用的是 Fiddler。给 VMOS 的 Wifi 设置代理服务器，装个 Fiddler 的证书，就能开始抓包了。 这一步有个小问题，VMOS 的设置页面是找不到 Wifi 设置的。要看到 Wifi 设置页面，可以装个 Wifi 大师之类的软件。或者用 ADB 执行下面的命令： 1adb shell am start -a android.intent.action.MAIN -n com.android.settings/.wifi.WifiSettings 上面这个命令能直接打开 Wifi 设置页面。 抓包分析刚打开今日校园，Fiddler 就刷屏了，大多数都是各种安卓Sdk的请求(无语)。屏蔽了十几个域名后，终于只剩下今日校园的请求了。 不得不说，今日校园对安全还是很看重的，抓包看到的内容里，无论是请求还是响应，就没有明文的字段。 不仅是没有明文字段，连应该明文的地方，都用了 “p”、”s” 这种简短的字符，防止被猜测出含义。不知道今日校园是如何做到这一步的，如果是手动混淆，那程序员实在太惨了。 12345678910111213141516171819202122232425POST https://mobile.campushoy.com/app/auth/dynamic/secret/getSecretKey/v-8213 HTTP/1.1sessionTokenKey: szFn6zAbjjU=SessionToken: szFn6zAbjjU=clientType: cpdaily_studenttenantId: User-Agent: Mozilla/5.0 (Linux; Android 5.1.1; vmos Build/LMY48G; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/52.0.2743.100 Mobile Safari/537.36 okhttp/3.12.4deviceType: 1CpdailyClientType: CPDAILYCpdailyStandAlone: 0CpdailyInfo: XvWN4SWqyX648L13hW5koOHt5AfBN6jFTi4zR23WludYuPZfzB8fDc5UZUar HHOmexyCccMic4Ad+D7MhoJRl1OJiSDRaFQXyGhY3RphecMkXaPEB+NoKx9O wYd5FSPdIgNvb5nxh7xns6eTidSC+FdD6lZSI3k15PI8BP/iRwLIWe+C6Kb3 /uyzTwXsv4w1Content-Type: application/json; charset=UTF-8Content-Length: 221Host: mobile.campushoy.comConnection: Keep-AliveAccept-Encoding: gzipCookie: acw_tc=2f624a7116118599368446428e16406bf20229eef5cf7fa3bf7a0952dd1bed{&quot;p&quot;:&quot;RyTf8OmNAEbj6Z2gakUc/WT0jxkW8lfkprxy9B4htHXG/S+87jGVfnoZ9t7a cGslGlxLmd0m3JAhdzH4PApmOTRbxm9AED93VleWHiaGaUVPfJu4KVLQLB5T xThWZyz2ZFG+AbUsgItCSkLRBn9m3FGV/D6CYaaxHXu9Mvv4zLw=&quot;,&quot;s&quot;:&quot;b837371696c3773494d25acecd543ca3&quot;}HTTP/1.1 200Date: Thu, 28 Jan 2021 18:55:40 GMTContent-Type: application/json;charset=UTF-8Connection: keep-aliveContent-Length: 209{&quot;errCode&quot;:0,&quot;errMsg&quot;:null,&quot;data&quot;:&quot;R1vtCBeFahygfP0Ik2Ojs47NZq3JF85Nfo/apHc5AcRzxa8JehCBq+0uZn+Cl7Mm+i7u13eQyUauW2dZA+5OVKzqP51FvYWuHb0BpjsdcDimVJQv8xr9lUBHk8vRrvkVZKbHgXkmUXvfLCxPlzHiRgckeXSXCIaTwYk7XWjKeQQ=&quot;} JADX 反编译 APK 静态分析Frida-dexdump脱壳既然有加密，那就没办法了，必须要逆向分析一下了。 从抓包的情况来看，对今日校园是可以比较放心的。加密那么复杂的 APP 会没有加壳吗？所以我压根没看加壳情况，直接用 frida-dexdump 脱壳。 这一步有一个点需要注意，由于是在手机上运行的 frida-server，需要做一个端口转发，才能在电脑上用 frida-dexdump。不然 frida-dexdump 是找不到 frida-server 的。frida-server 默认的监听端口是 27042，可以用 adb 做一个转发。1adb forward tcp:27042 tcp:27042如果你足够熟悉网络协议相关的知识，这不是个问题。 frida-dexdump 真的是我用过的最好用的傻瓜式工具，很轻松地帮我整出了 29 个 dex 文件。 这里有个小技巧，把这些 dex 文件重命名为 classes.dex、classes1.dex、…, 然后压缩成 zip，把后缀改为 apk。再用 jadx 打开这个 apk，就能一次载入所有的 dex 文件了。(或者使用 jadx 1.2，这个版本可以打开多个 dex 文件，我也是后来才发现) 以上都是些基本操作了。 分析getSecretKey请求接下来就是用 jadx 去逆向分析加密的算法。 打开那 29 个 dex 文件，反编译后搜索文本。(我载入的时候有一个 dex 文件有问题，jadx 1.2 无法载入，排除之后才能载入。jadx 1.1 可以载入，但也是提示有错误，无法得到 smali 代码。暂时不清楚什么原因。) 先搜索前面提到的第一个请求 auth/dynamic/secret/getSecretKey，发现如下代码： 12@POST(&quot;app/auth/dynamic/secret/getSecretKey/v-8213&quot;)Observable&lt;Wrapper&lt;String&gt;&gt; getSecretKey(@Body Map&lt;String, String&gt; map); 搜索一下用例，只有一个： 12345678/* renamed from: l */public static void m66682l(uy0&lt;String&gt; uy0) { HashMap hashMap = new HashMap(); String e = ku1.m75647e(((Object) UUID.randomUUID()) + HiAnalyticsConstant.REPORT_VAL_SEPARATOR + ku1.m75649g(UIUtils.getContext()), UIUtils.getContext()); hashMap.put(&quot;p&quot;, e); hashMap.put(&quot;s&quot;, ss0.m80546a(&quot;p=&quot; + e + ContainerUtils.FIELD_DELIMITER + ku1.m75648f(UIUtils.getContext()))); f59478a.mo101637z(f59479b.getSecretKey(hashMap), uy0);} 前面抓包时也看到，请求体是个 Json，有 “p” 和 “s” 两个字段，和反编译的代码完全对上了。 代码里的 HiAnalyticsConstant.REPORT_VAL_SEPARATOR 和 ku1.m75649g() 都是字符串常量，分别是 “|” 和 “firstv”。 因此第一个参数 p 的内容已经出来了: 1p = ku1.m75647e( UUID.randomUUID() + &quot;|&quot; + &quot;firstv&quot; ); 点进去看一眼 ku1.m75647e 函数： 1234/* renamed from: e */public static String m75647e(String str, Object obj) { return ju1.m75051d(JniUtils.encodeByRSAPubKey(str.getBytes(), obj));} 其中 ju1.m75051d() 函数是 base64 编码的函数(熟悉base64编码的话，代码的特征很明显，一眼看出)。 另一个函数就不怎么好分析了，来自 JniUtils 类的静态函数，很可能是个 native 函数，函数具体实现在 native 层。 点进去一看，果然如此： 1public static native byte[] encodeByRSAPubKey(byte[] bArr, Object obj); 不过从名字可以看出很多的内容，比如函数的本质是用Public Key 的 RSA 加密，而且函数没有传递 Public Key，说明 Public Key 和函数的实现是在一起的。因此只要能在 so 文件里找到 Public Key 就可以自己加密了。 另一个参数 s 就不再赘述了，他比较简单，是对 p 参数的值算了下 MD5： 1s = MD5(&quot;p=&quot; + p + &quot;&amp;&quot; + JniUtils.gets()); 其中这个 JniUtils.gets() 函数不用参数还返回了一个字符串。可以猜测这个字符串是固定值。(后面的分析也证实，这个函数的 s 应该是 Salt 的意思，给 MD5 加盐的) 总览一下这个 JniUtils，可以感受一下今日校园的加密方法有多么丰富。AES、DES都是很常见的，一般的 APP 都是用其中的一种。今日校园AES、DES、RSA三种常见的加密方法都用上了。除此之外还有一些摘要算法，MD5、SHA1之类的，这些到不是很重要。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class JniUtils { static { System.loadLibrary(&quot;crypto&quot;); System.loadLibrary(&quot;cipher&quot;); } public static native byte[] decodeByAES(byte[] bArr, byte[] bArr2); public static native byte[] decodeByDES(String str, byte[] bArr, Object obj, boolean z); public static native byte[] decodeByRSAPrivateKey(byte[] bArr, Object obj); public static native byte[] decodeByRSAPubKey(byte[] bArr, byte[] bArr2, Object obj); public static native byte[] encodeByAES(byte[] bArr, byte[] bArr2); public static native byte[] encodeByDES(String str, byte[] bArr, Object obj, boolean z); public static native byte[] encodeByHmacSHA1(Context context, byte[] bArr); public static native byte[] encodeByRSAPrivateKey(byte[] bArr, byte[] bArr2, Object obj); public static native byte[] encodeByRSAPubKey(byte[] bArr, Object obj); public static native String encodeBySHA1(byte[] bArr); public static native String encodeBySHA224(byte[] bArr); public static native String encodeBySHA256(byte[] bArr); public static native String encodeBySHA384(byte[] bArr); public static native String encodeBySHA512(byte[] bArr); public static native String getfdkey(String str, Object obj); public static native String gets(Object obj); public static native String md5(byte[] bArr); public static native String sha1OfApk(Context context); public static native byte[] signByRSAPrivateKey(byte[] bArr, byte[] bArr2); public static native int verifyByRSAPubKey(byte[] bArr, byte[] bArr2, byte[] bArr3); public static native boolean verifySha1OfApk(Context context); public static native byte[] xOr(byte[] bArr);} IDA反编译.so进行静态分析接下来自然是用 IDA 分析 .so 文件了。这个 JniUtils 涉及到两个 .so 文件, libcrypto.so 和 libcipher.so。其中 JniUtils 相关的的代码在 libcipher.so 文件里。 这里又有一个小技巧，由于是 JNI 相关的代码，可以插入一些结构体让反编译的伪代码更加清晰。在 structures 窗口按下快捷键 insert，就可以插入结构体了，JNI 相关的结构体是标准结构体，IDA 自带。 分析gets函数先从 gets() 开始入手，它明显比较简单。 123456789101112131415161718192021jstring __fastcall Java_com_wisorg_wisedu_utils_JniUtils_gets(JNIEnv *env, jclass instance, jobject context){ JNIEnv *v3; // ST08_4 char *v4; // r0 v3 = env; v4 = getSalt(); return _JNIEnv::NewStringUTF(v3, (const unsigned __int8 *)v4);}char *getSalt(){ char *v0; // ST14_4 v0 = (char *)malloc(0x400u); strcpy(v0, (const char *)sk1); // sk1=&quot;2cf24dba5fb0a30e26e8&quot; _strcat_chk(v0, sk2, -1); // sk2=&quot;3b2ac5b9&quot; _strcat_chk(v0, sk3, -1); // sk3=&quot;e29e1b161e5c1fa7425e73&quot; _strcat_chk(v0, sk4, -1); // sk4=&quot;043362938b9824&quot; return v0;} 这两个函数的伪代码都很清晰，不多说明，本质就是返回字符串 “2cf24dba5fb0a30e26e83b2ac5b9e29e1b161e5c1fa7425e73043362938b9824”。 分析encodeByRSAPubKey函数然后再去看 encodeByRSAPubKey 函数。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889jbyteArray __fastcall Java_com_wisorg_wisedu_utils_JniUtils_encodeByRSAPubKey(JNIEnv *env, jclass instance, jbyteArray src_, jobject context){ int v4; // ST50_4 int v5; // r1 int v6; // STF4_4 int v7; // r0 int v9; // [sp+14h] [bp-FCh] _jbyteArray *v10; // [sp+38h] [bp-D8h] int i; // [sp+3Ch] [bp-D4h] jbyte *buf; // [sp+40h] [bp-D0h] void *v13; // [sp+44h] [bp-CCh] void *ptr; // [sp+48h] [bp-C8h] int v15; // [sp+4Ch] [bp-C4h] int v16; // [sp+54h] [bp-BCh] int v17; // [sp+58h] [bp-B8h] jsize length; // [sp+60h] [bp-B0h] jsize size; // [sp+6Ch] [bp-A4h] jbyte *elems; // [sp+70h] [bp-A0h] char *v21; // [sp+74h] [bp-9Ch] unsigned __int8 *s1; // [sp+78h] [bp-98h] _jbyteArray *array; // [sp+80h] [bp-90h] _JNIEnv *enva; // [sp+88h] [bp-88h] _jbyteArray *v25; // [sp+8Ch] [bp-84h] enva = env; array = src_; s1 = sha1OfApk(env, context); if ( !strcmp((const char *)s1, (const char *)signatureOfApk) ) { v21 = getUk(); elems = _JNIEnv::GetByteArrayElements(enva, array, 0); size = _JNIEnv::GetArrayLength(enva, &amp;array-&gt;0); length = 0; v17 = 0; v4 = BIO_new_mem_buf(v21); v16 = PEM_read_bio_RSA_PUBKEY(v4, 0, 0, 0); BIO_free_all(v4); v15 = RSA_size(v16); ptr = malloc(size); v13 = malloc(v15); buf = (jbyte *)malloc((size / (v15 - 11) + 1) * v15); _aeabi_memset(); _aeabi_memset(); _aeabi_memcpy(); for ( i = 0; ; ++i ) { v5 = i; if ( i &gt; size / (v15 - 11) ) break; v5 = i; if ( i == size / (v15 - 11) ) { v5 = size % (v15 - 11); v9 = size % (v15 - 11); } else { v9 = v15 - 11; } if ( !v9 ) break; _aeabi_memset(); v6 = RSA_public_encrypt(v9, (int)ptr + v17, (int)v13, v16, 1); _aeabi_memcpy(); length += v6; v17 += v9; } v7 = RSA_free(v16, v5); CRYPTO_cleanup_all_ex_data(v7); _JNIEnv::ReleaseByteArrayElements(enva, array, elems, 0); v10 = _JNIEnv::NewByteArray(enva, length); _JNIEnv::SetByteArrayRegion(enva, v10, 0, length, buf); free(ptr); free(v13); free(buf); if ( v21 ) free(v21); if ( s1 ) free(s1); v25 = v10; } else { if ( s1 ) free(s1); v25 = 0; } return v25;} 虽然和分析的函数没很大关系，但是有个小发现。注意到这两行代码： 12s1 = sha1OfApk(env, context);if ( !strcmp((const char *)s1, (const char *)signatureOfApk) ) 可以猜测今日校园还检测了 apk 的签名，防止 apk 被修改。 对于我们关注的 Public Key，关键在这几行代码： 12345v21 = getUk();...v4 = BIO_new_mem_buf(v21);...v16 = PEM_read_bio_RSA_PUBKEY(v4, 0, 0, 0); 可以知道 Public Key 来自 getUk 函数，而且还是 PEM 格式的。 12345678910111213char *getUk(){ char *v0; // ST1C_4 v0 = (char *)malloc(0x800u); strcpy(v0, (const char *)uk0); // -----BEGIN PUBLIC KEY----- _strcat_chk(v0, uk1, -1); // MIGfMA0GC... _strcat_chk(v0, uk2, -1); // _strcat_chk(v0, uk3, -1); // _strcat_chk(v0, uk4, -1); // _strcat_chk(v0, uk5, -1); // -----END PRIVATE KEY----- return v0;} 轻松得到 Public Key，至此第一个请求 getSecretKey 分析的差不多了。 解密请求返回的数据java层面的分析多分析几个请求可以发现，大多数请求的响应内容都是同一个 Json 结构： 12345{ &quot;errCode&quot;:0, &quot;errMsg&quot;:&quot;&quot;, &quot;data&quot;:&quot;*被加密的内容*&quot;} 关于被加密的内容的解密方法，分析过程是比较复杂的。 首先是今日校园发送网络请求都不是同步处理的，而是选择了回调一类的做法。对于不同的请求，都从 BaseCommPresenter 类派生出一个子类，其中的 onNextDo 方法就是处理网络请求的响应结果的。即发送了网络请求之后就不管了，等服务器响应之后，再调用 onNextDo 方法，这个 onNextDo 方法可以理解为回调函数。 分析了数个 onNextDo 方法后，就可以总结出如何解密 data 字段了。 除了 getSecretKey 请求之外，所有加密的 data 字段，都用 JniUtils.decodeByDES 来解密。 getSecretKey 请求的 data 字段是被加密的，要用 JniUtils.decodeByRSAPrivateKey 来解密。 通过上面两点，其实还能得到一个信息。就是 JniUtils.decodeByDES 很可能会用到 getSecretKey 返回的数据才能解密，不然没有必要用两种解密方法。(分析证明，这个猜测是对的。虽然当时分析的时候我并没立刻想到这一点，但是对分析过程没影响，所以没想到这个信息也问题不大。) 通过查找 decodeByDES 的用例，可以得知这个函数的第一个参数是密钥，第二个参数是要解密的字节数组。 1public static native byte[] decodeByDES(String str, byte[] bArr, Object obj, boolean z); 而这个密钥来自于下面这个函数： 12345678public static String m66579k() { String string = SPCacheUtil.getString(&quot;chk&quot;, &quot;&quot;); if (!TextUtils.isEmpty(string)) { return new String(ms0.m76724h(string)); // 如果不为空，返回ms0.m76724h(chk) } LoginV6Helper.m66682l(new C20331h()); // LoginV6Helper.m66682l 是发起 getSecretKey 请求的，而 C20331h 类的 onNextDo 函数说明了要用 decodeByRSAPrivateKey 来解密 getSecretKey 的数据。 return &quot;1234&quot;;} 问题是，chk 是什么？ms0.m76724h 又是什么？ 很容易能找到 chk 是怎么来的，就是上面提到的 C20331h 类中的 onNextDo 函数，调用了 m12286L 把 chk 给存起来了。(chk 是 getSecretKey 的返回值之一) 12345public static void m12286L(String str) { if (!TextUtils.isEmpty(str)) { SPCacheUtil.putString(&quot;chk&quot;, ms0.m17919n(str.getBytes())); }} ms0.m76724h 我也不知道是什么，因为反编译出错了。(🐶) 我选择不管这个，继续分析别的。 IDA分析decodeByDES熟悉 AES 和 DES 算法的应该清楚，这类算法重要的是四个参数：模式、填充、密钥和初始向量(Initialization Vector, 变量名常为iv)。这四个参数只有密钥是 java 层提供的，其他的都藏在 native 层，需要静态分析得到。 今日校园用的是 OpenSSL 库来实现的 DES 算法，其中模式、填充和初始向量都很好找，不再赘述。密钥方面有些特别，因为 java 层传入的 key 不是最终的密钥，还被处理了一下。 这是处理 key 相关的代码，其中 iscpdaily 是 decodeByDES 的最后一个参数： 123456789101112131415161718192021if ( iscpdaily ){ if ( v15 ) { l1 = getcKey(); // 返回常量字符串 &quot;OKXv&quot; ptr = getak(enva, l1, o2); } else { ptr = getcKey(); }}else if ( v15 ){ v7 = getfKey(); // 返回常量字符串&quot;b63X&quot; ptr = getak(enva, v7, o2);}else{ ptr = getfKey();} getcKey 和 getfKey 的定义如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859unsigned __int8 *getcKey(){ signed int i; // [sp+4h] [bp-14h] _BYTE *v2; // [sp+8h] [bp-10h] v2 = malloc(0x100u); for ( i = 0; i &lt;= 3; ++i ) { switch ( i ) { case 0: v2[i] = 'O'; break; case 1: v2[i] = 'K'; break; case 2: v2[i] = 'X'; break; case 3: v2[i] = 'v'; break; default: continue; } } v2[4] = 0; return v2;}unsigned __int8 *getfKey(){ signed int i; // [sp+4h] [bp-14h] _BYTE *v2; // [sp+8h] [bp-10h] v2 = malloc(0x100u); for ( i = 0; i &lt;= 3; ++i ) { switch ( i ) { case 0: v2[i] = 'b'; break; case 1: v2[i] = '6'; break; case 2: v2[i] = '3'; break; case 3: v2[i] = 'X'; break; default: continue; } } v2[4] = 0; return v2;} 这里也有个小技巧，IDA 默认显示的是 `v2[i] = 98;` 这种数字，但是其实很好猜测它是个字符。右键这个数字，点击 `char` 就能显示数字对应的 ASCII 字符了。 关键是 getak 函数，其定义反编译出错了，而且很长我没看懂。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124// local variable allocation has failed, the output may be wrong!unsigned __int8 *__cdecl getak(JNIEnv *env, unsigned __int8 *l1, const unsigned __int8 *o2){ void *v3; // r0 char *v4; // r1 int v5; // r0 int v6; // r1 int v7; // r0 int v8; // r0 char *v9; // r1 unsigned __int8 *result; // r0 int v11; // t1 unsigned __int8 *v12; // [sp+0h] [bp-110h] int v13; // [sp+4h] [bp-10Ch] unsigned __int8 *v14; // [sp+8h] [bp-108h] char *v15; // [sp+Ch] [bp-104h] size_t v16; // [sp+10h] [bp-100h] char *v17; // [sp+14h] [bp-FCh] char v18; // [sp+18h] [bp-F8h] int vt; // [sp+20h] [bp-F0h] unsigned __int8 *rets; // [sp+24h] [bp-ECh] unsigned int __vla_expr0; // [sp+28h] [bp-E8h] const unsigned __int8 *v22; // [sp+2Ch] [bp-E4h] int len; // [sp+30h] [bp-E0h] const unsigned __int8 *o2a; // [sp+34h] [bp-DCh] unsigned __int8 *l1a; // [sp+38h] [bp-D8h] JNIEnv *enva; // [sp+3Ch] [bp-D4h] unsigned __int8 *v27; // [sp+40h] [bp-D0h] size_t v28; // [sp+44h] [bp-CCh] int v29; // [sp+48h] [bp-C8h] int v30; // [sp+4Ch] [bp-C4h] const unsigned __int8 *v31; // [sp+50h] [bp-C0h] size_t v32; // [sp+54h] [bp-BCh] char *dest; // [sp+64h] [bp-ACh] char *v34; // [sp+68h] [bp-A8h] int v35; // [sp+6Ch] [bp-A4h] int v36; // [sp+70h] [bp-A0h] unsigned __int8 *v37; // [sp+74h] [bp-9Ch] int v38; // [sp+78h] [bp-98h] char *src; // [sp+7Ch] [bp-94h] int v40; // [sp+80h] [bp-90h] char *v41; // [sp+84h] [bp-8Ch] char *v42; // [sp+88h] [bp-88h] _BYTE *v43; // [sp+8Ch] [bp-84h] int v44; // [sp+90h] [bp-80h] int v45; // [sp+94h] [bp-7Ch] __int64 buf2; // [sp+98h] [bp-78h] _BYTE value2[56]; // [sp+A0h] [bp-70h] OVERLAPPED unsigned __int8 value1[50]; // [sp+D8h] [bp-38h] o2a = (const unsigned __int8 *)env; len = (int)l1; v22 = o2; v27 = l1; enva = (JNIEnv *)-1; l1a = (unsigned __int8 *)-1; v17 = &amp;v18; v28 = strlen((const char *)l1); v31 = v22; v30 = -1; v29 = -1; v16 = v28; v32 = strlen((const char *)v22); __vla_expr0 = v32 + v16; rets = (unsigned __int8 *)&amp;v12; vt = v32 + v16; v15 = (char *)&amp;v12 - ((v32 + v16 + 7) &amp; 0xFFFFFFF8); v14 = (unsigned __int8 *)&amp;v12 - ((v32 + v16 + 7) &amp; 0xFFFFFFF8); v3 = malloc(v32 + v16 + 1); v4 = v17; *((_DWORD *)v17 + 1) = v3; v5 = *((_DWORD *)v4 + 6); dest = v15; *((_DWORD *)v4 + 18) = -1; *((_DWORD *)v4 + 17) = v5; *((_DWORD *)v4 + 16) = *((_DWORD *)v4 + 18); if ( *((_DWORD *)v4 + 16) == -1 ) v34 = strcpy(dest, *((const char **)v17 + 17)); else v34 = (char *)_strcpy_chk(dest, *((_DWORD *)v17 + 17), *((_DWORD *)v17 + 16)); v6 = *((_DWORD *)v17 + 5); v37 = v14; v36 = -1; v35 = v6; v7 = _strcat_chk(v14, v6, -1); *(_QWORD *)&amp;value1[24] = 0LL; *(_QWORD *)&amp;value1[32] = 0LL; *(_QWORD *)&amp;value1[8] = 0LL; *(_QWORD *)&amp;value1[16] = 0LL; *(_QWORD *)&amp;value2[48] = 0LL; *(_QWORD *)value1 = 0LL; *(_WORD *)&amp;value1[40] = 0; *(_QWORD *)&amp;value2[24] = 0LL; *(_QWORD *)&amp;value2[32] = 0LL; *(_QWORD *)&amp;value2[8] = 0LL; *(_QWORD *)&amp;value2[16] = 0LL; buf2 = 0LL; *(_QWORD *)value2 = 0LL; *(_WORD *)&amp;value2[40] = 0; *(_DWORD *)v17 = 0; v13 = v7; v8 = getStr1Str2(v14, &amp;value2[48], (unsigned __int8 *)&amp;buf2); v9 = v17; *(_DWORD *)v17 = v8; if ( *(_DWORD *)v9 == 1 ) { v41 = (char *)*((_DWORD *)v17 + 1); v40 = -1; src = (char *)&amp;buf2; v38 = -1; v42 = strcpy(v41, (const char *)&amp;buf2); v45 = *((_DWORD *)v17 + 1); v44 = -1; v43 = &amp;value2[48]; _strcat_chk(v45, &amp;value2[48], -1); } free(*((void **)v17 + 6)); result = (unsigned __int8 *)*((_DWORD *)v17 + 1); v11 = *((_DWORD *)v17 + 3); v12 = (unsigned __int8 *)*((_DWORD *)v17 + 1); if ( _stack_chk_guard == *(_DWORD *)&amp;value1[44] ) result = v12; return result;} 不过我倒是看懂了 getak 函数调用的 getStr1Str2 函数： 1234567891011121314151617181920212223242526272829303132333435int __fastcall getStr1Str2(unsigned __int8 *souce, unsigned __int8 *buf1, unsigned __int8 *buf2){ unsigned __int8 *v3; // ST28_4 unsigned __int8 *v4; // r1 unsigned __int8 *v5; // r1 signed int j; // [sp+4h] [bp-44h] signed int i; // [sp+8h] [bp-40h] signed int v9; // [sp+Ch] [bp-3Ch] unsigned __int8 *v10; // [sp+14h] [bp-34h] unsigned __int8 *v11; // [sp+18h] [bp-30h] unsigned __int8 *v12; // [sp+1Ch] [bp-2Ch] unsigned __int8 *v13; // [sp+20h] [bp-28h] unsigned __int8 *v14; // [sp+24h] [bp-24h] v3 = souce; v14 = buf1; v13 = buf2; v12 = souce; v11 = buf1; v10 = buf2; v9 = strlen((const char *)souce); if ( !v3 || !v14 || !v13 ) return -1; for ( i = 0; i &lt; v9; i += 2 ) { v4 = v10++; *v4 = v12[i]; } for ( j = 1; j &lt; v9; j += 2 ) { v5 = v11++; *v5 = v12[j]; } return 1;} 其实就是把奇数位置的字符取出来，把偶数位置的字符取出来。 getak 函数没看懂，可就没法分析了呀。所以我找大佬，写了个 frida 脚本，hook 了这个 getak 函数，直接观察 getak 函数的参数和返回值。 这下全搞明白了。这个 “okTq” 字符串，就是 getSecretKey 请求得到的字符串，也就是前面提到的所谓的 chk。 而 getak 函数的返回值，就是 li 的奇数位置的字符 + o2 的奇数位置的字符 + li 的偶数位置的字符 + o2 的偶数位置的字符。 至此，decodeByDES 函数用到的 DES 算法分析完毕。 其他前面提到 GetSecretKey 请求的参数是通过 encodeByRSAPubKey 函数加密的。但在得到 chk 之后，今日校园许多请求的参数都是用 encodeByDES 函数加密的，而且加密密钥有很多种，但大多能在 java 代码里找到。这在后续的分析中很容易发现。 分析总结反逆向今日校园为了安全做了如下措施： 限制软件运行的设备(只能在 Android Arm 平台运行)。 apk 加壳 SSL Pinning 在代码层面对请求的参数进行混淆 对请求的参数和响应都进行了加密，而且加密算法多样，密钥多样。 将加密解密移动到 native 层(也是为了效率) 对 apk 签名进行校验，防止 apk 被篡改。 反动态调试(我尝试过用 IDA 动态调试，确认有反调试) 从效果来看，这些措施是有效的，因为这些措施逆向的难度是比较大的。 但也是有代价的。 首先限制运行的设备降低了用户体验。万一有 Android x86 的用户呢。(😁) 其次是非常多的加密，会降低APP的响应速度而且增加手机耗电，服务器方面也会增加很多计算开销。 最后是代码层面对请求参数进行混淆。如果是人工混淆，那显然是非常麻烦而且不利于代码维护的。自动混淆，则多增加了一个环节，稳健性可能降低。 值得推荐的反逆向措施： 对 apk 进行加壳 HTTPS + SSL Pinning 可以有效防止中间人攻击。 适当加密请求和响应的内容。 逆向有一台有 root 权限的安卓设备很重要。没有也没关系，可以用 VMOS 虚拟机，但是比较麻烦。 frida 是个好工具，对于静态分析困难的地方，可以尝试用 frida hook，观察运行值。如果 hook 能成功分析出结果，那么还能省去反-反调试的功夫。 关于绕过 SSL Pinning 的方法还有很多(Hook、修改 apk 等)，需要多研究。 fidller 在解码 gzip 时经常崩溃。 感想本篇文章的重点不是讲解逆向的工具如何使用，也不是各种加密解密的算法，而是一次逆向分析的思路与完整过程。目的是让逆向新人了解一次完整的逆向需要哪些基本知识，从而达到对技能树查漏补缺的作用。 这其实是我第二次进行安卓APP逆向。本次逆向分析能流畅进行，我认为与我的计算机常识和C++水平是分不开的。我想一定的计算机常识和C/C++水平对逆向分析是很重要的。 我自己也是逆向新人，也看过一些针对新人的逆向教程，常因教程不详细而产生过许多疑惑。本篇文章已尽可能地详细，但因精力有限，难免有照顾不到的地方。希望本篇文章能给读者有所启发，","link":"/2021/02/04/%E4%BB%8A%E6%97%A5%E6%A0%A1%E5%9B%ADAPP%E9%80%86%E5%90%91%E5%88%86%E6%9E%90/"},{"title":"使用EndNote管理文献","text":"毕业论文要求使用 Word 来写，就想用 Word 插件来管理引用文献，记录一下使用时遇到的问题和解决方法。我使用的是 EndNote 20，本文的方法在其他版本可能不适用。 使用 GB/T7714 Style在菜单栏中点击 Tools/Output Sytle/Open Style Manager…，打开样式管理器。 点击样式管理器中的 Get more on the web 按钮，就会打开一个网页，在这个网页里搜索 Chinese Standard 就能找到两个国标样式了，全都下载下来。 将下载得到的两个样式文件放到 EndNote 安装目录的 Style 目录下，比如我的是 C:\\Program Files (x86)\\EndNote 20\\Styles。 然后回到 Style Manager，把两个国标样式都勾选上，再打开你的 Word 文档，就可以选择国标样式了。 相关问题中文期刊只显示前三位作者对于作者数量大于 3 位作者的期刊，我们的毕业论文格式要求只显示前 3 位作者，然后在后面加上 “et al.” 或者 “, 等”。 对于英文期刊来说当然用 “et al.”，但是对于中文期刊来说，应该使用 “, 等”。 EndNote 下载的国标格式，不论英文期刊还是中文期刊，都显示的“et al.”。这是因为不论英文期刊还是中文期刊，都被视为一种文献类型：“Journal Article”。 要对中文期刊做特别设置，就要新创建一种文献类型。 点击菜单栏 Edit/Preferences 打开设置页面，点击 Reference Types。 如图所示，在 Default Reference Type 中选择 Unused 1（因为我已经设置过了，所以图中只剩下Unused 2/3）。 然后点击 Modify Reference Type 按钮，如图填写设置。 保存之后就创建了“中文期刊”这种文献类型，现在要对这种类型进行设置。 在菜单 Tools/Output Sytle/ 中勾选 Chinese Std GBT7714(numeric)。然后再再到菜单 Tools/Output Sytle/ 中点击 Edit “Chinese Std GBT7714(numeric)”，进入编辑界面。 在编辑界面，首先在菜单 File/Save as 另存为新的样式，比如我取名为 Chinese Std GBT7714(numeric) Fix，避免影响下载的国标样式。 然后如图所示，修改 Editor Lists 中的设置，将原来的 “, et al.” 替换为 “, 等”。 这里不要修改 Author Lists 中的设置。因为这两个设置是不限定文献类型的，也就是说英文期刊和中文期刊都会受到影响。而我们对英文期刊和中文期刊分别设置的原理就是将 Author Lists 的设置应用于英文期刊，而 Editor Lists 的设置应用于中文期刊。 接下来编辑中文期刊的 Style 模板。如图所示，点击 Reference types 按钮，勾上 “中文期刊”类型，然后写入如下模板。 1Secondary Author. Title [J]. Journal, Year|, Volume|(Issue)| : Pages|. 注意，这里用的不是 Author 而是 Secondary Author。这里的 Secondary Author 会使用前面 “Editor Lists” 的设置，这就是对英文文献和中文文献使用不同设置的原理。对于英文文献，其 Reference Type 为 “Journal Article”，模板中使用的是 “Author”，则会应用 “Author Lists” 的设置。 还要注意，这里的 “|” 和 “°” 都不是普通文本，不能用复制粘贴的方式填入，应该在右上角的 “Insert Field” 按钮中插入。 其中“Foced Separation” 对应 “|”，“Link Adjacent Text” 对应 “°”，空格对应“·”。 我这里的模板是经过调整的，对于那些没有卷号的期刊，也可以正确显示。（如果使用 Journal Article 的模板，没有卷号的期刊会显示多余的逗号和空格） 保存修改，接下来的操作是把中文期刊的文献类型修改为“中文期刊”。 在文献列表中双击你要修改的文献，然后如图所示将 Reference Type 修改为 “中文期刊”。 将所有的中文期刊的 Reference Type 都修改为“中文期刊”后，接下来要编辑它们的 “Secondary Author”。 首先创建一个 Smart Group，将所有的“中文期刊”都列出来，具体方法是右键左侧的 “MY GROUPS”，点击 “Create smart group”。 切换到刚刚创建的 Smart Group，这时候列表里只有 Reference Type 为 “中文期刊” 的文献。 然后点击菜单栏的 Library/Change/Move/Copy Fields，按照如图所示设置，将 Author 的值复制到 Secondary Author。 然后，回到 Word 里更新引用，作者数量大于三位的文献应该会使用正确的格式显示了。 页码显示问题下载的国标样式的页码显示方式是错误的，要修改为显示完整的页码，其设置方法如图所示。 不要全大写的作者名称下载的国标样式中，英文文献的作者是字母全大写的，要修改为首字母大写，其设置方法如图所示。 中英文混排的 Word 样式调整中英文混合排版主要的问题是字体设置，中文使用宋体，英文使用 Times New Roman 字体。但是 EndNote 的设置只支持设置一种字体，如下图所示。 我找到的一种解决方法是，在 EndNote 的字体设置中设置英文字体：Times New Roman。然后再修改 “EndNote Bibliography” 的字体样式，将中文字体修改为宋体。 很奇怪的是，对“EndNote Bibliography”的段落样式进行修改是无效的，每次更新都会被覆盖，我也不知道应该在哪里进行设置。 段落样式在 EndNote 的设置里可以设置一些简单的参数，如上上图所示，可以修改的项目有：首行缩进、行间距、悬挂缩进、后置字符。 其中行间距只支持单倍行距、1.5倍行距和双倍行距，不支持设置固定值，这点不太灵活。 只能在交稿之前手动修改参考文献列表的样式，不能完全自动化了。","link":"/2022/04/03/%E4%BD%BF%E7%94%A8EndNote%E7%AE%A1%E7%90%86%E6%96%87%E7%8C%AE/"},{"title":"使用 OpenCV 处理 esp32-cam 推流","text":"使用 OpenCV 处理 esp32-cam 推流 使用 Arduino 刷入 esp32-cam 的 CameraWebServer 示例，然后就可以通过访问 http://ip:80/ 进入控制页，或者访问 http://ip:81/stream 获取“实时视频推流”。 但是这个视频推流并不是常见的视频格式，而是 jpg 图片流，这个可以抓包分析出来。 我在浏览器使用 F12 没法查看具体的响应，所以我用 Fiddler 进行抓包分析的。 我的 esp32-cam 响应的内容如下： 1234567\\r\\n--123456789000000000000987654321\\r\\nContent-Type: image/jpeg\\r\\nContent-Length: 5123\\r\\n\\r\\n/* 这里是jpg图片的二进制内容 */ 为了方便查看，我把响应中的\\r\\n都保留了，没有删去。 其中 Content-Length 的内容就是 jpg 图片的长度，所以要先把它的值取出来，然后才能往后取出 jpg 图片的内容。 我的需求是将这一张张 jpg 图片转化为 OpenCV 的 Mat 格式，这样就能使用 OpenCV 作进一步处理了。 因为这个推流是源源不断地进行的，OpenCV 的处理也是不断在进行的，这就需要用两个线程同时进行处理。一个线程不断获取 esp32 推流，另一个线程不断解析响应，并且用 OpenCV 处理响应中的 jpg 图片。另外，两个线程都要访问响应数据，如果同时访问响应数据，可能会出现 race condition，所以还要考虑多线程同步。 我用 libcurl 库发起 HTTP 请求，这是使用 libcurl 发起请求部分的代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152static size_t reWriter(char* buffer, size_t size, size_t nmemb, string* content){ unsigned long sizes = size * nmemb; content-&gt;append(buffer, sizes); return sizes;}int main(){ curl_global_init(CURL_GLOBAL_ALL); CURL* curl; curl = curl_easy_init(); // esp32-cam 推流的网址，改成自己的 string url = &quot;http://192.168.1.123:81/stream&quot;; // 这里使用 string 作为 buffer，比较方便 string buffer; thread th = std::thread([&amp;]() { while (true) { /* 开启跟随跳转, 这里没必要设置，抄代码的时候没删掉 */ curl_easy_setopt(curl, CURLOPT_FOLLOWLOCATION, true); /* 设置超时时间(单位：秒)，不要太长，因为 esp32 的网络不太稳定，如果断连需要尽快重连 */ curl_easy_setopt(curl, CURLOPT_TIMEOUT, (long)5LL); /* 关闭 SSL 验证, 这里没必要设置，抄代码的时候没删掉 */ curl_easy_setopt(curl, CURLOPT_SSL_VERIFYPEER, false); curl_easy_setopt(curl, CURLOPT_SSL_VERIFYHOST, false); /* enable TCP keep-alive for this transfer */ curl_easy_setopt(curl, CURLOPT_TCP_KEEPALIVE, true); /* keep-alive idle time to 120 seconds */ curl_easy_setopt(curl, CURLOPT_TCP_KEEPIDLE, 120L); /* interval time between keep-alive probes: 60 seconds */ curl_easy_setopt(curl, CURLOPT_TCP_KEEPINTVL, 60L); // curl 数据处理函数 curl_easy_setopt(curl, CURLOPT_WRITEFUNCTION, reWriter); curl_easy_setopt(curl, CURLOPT_WRITEDATA, (void*)&amp;(buffer)); // 设置处理HTTP头部的功能函数 curl_easy_setopt(curl, CURLOPT_URL, url.data()); // 发起请求（会阻塞当前线程） cout &lt;&lt; &quot;正在发起请求...&quot; &lt;&lt; endl; curl_easy_perform(curl); cout &lt;&lt; &quot;连接已经断开!&quot; &lt;&lt; endl; } }); th.detach(); // 让线程独立运行 // TODO: 处理响应 return 0;} 其中 reWriter 函数是响应数据的处理函数，将接收到的响应数据存起来并返回其长度就好了。 响应的解析部分我直接在主线程进行，先使用正则表达式取出 Content-Length，然后再取出 jpg 图片的内容。 使用 string 作为 buffer 的好处就是可以用 substr 比较方便地取出其中的部分内容。 具体代码实现如下： 123456789101112131415161718192021222324252627282930while (true){ int64_t buffer_length = buffer.size(); cout &lt;&lt; &quot;buffer_length: &quot; &lt;&lt; buffer.size() &lt;&lt; endl; regex pattern(&quot;\\r\\n--123456789000000000000987654321\\r\\nContent-Type: image\\/jpeg\\r\\nContent-Length: ([\\\\d]+)\\r\\n\\r\\n&quot;); smatch result; if (!regex_search(buffer, result, pattern)) continue; if (result.size() &lt;= 1) continue; int64_t image_length = stoll(result[1].str()); int64_t header_length = result.length(0); // 如果图片完整地储存在 buffer 中，才读取图片的数据 if (header_length + image_length &lt;= buffer_length) { // 取出 jpg 图片内容 string image_buffer = buffer.substr(header_length, image_length); // 清除 buffer，这一步很关键 buffer.clear(); // 使用 OpenCV 读取 jpg 图片 Mat tmp = Mat(1, image_length, CV_8UC1, (void*)image_buffer.data()); cv::Mat decodedImage = imdecode(tmp, 1); if (decodedImage.data != NULL) { // 翻转 esp32-cam 传来的图片，根据需要删去或保留 Mat filped; flip(decodedImage, filped, -1); imshow(&quot;display&quot;, filped); waitKey(10); } }} 这里面有一个步骤非常重要，就是每解析一张图片就清除 buffer。 我们接收到的 buffer 里，可能不止含有一份响应。一份响应里包含一个 HTTP 头部和一张 jpg 图片。 变量 buffer 里储存的内容，可能包含一份完整的响应和半份响应（半份响应：比如完整的 HTTP 头部和 jpg 图片的一部分内容，甚至只有一部分 HTTP 头部）。 正常来说，那半份响应应该保留在 buffer 中。等到接收到更多内容时再尝试解析，因为buffer中旧的内容加上新接收的内容可能就凑出了一份完整的响应。如果我们清除掉未解析的数据，会导致丢失掉一些数据！ 但是我们的需求有点特殊，因为视频推流对实时性要求很高。我们不在意过去的每一帧内容，只在意当前 esp32-cam 看到的那一帧内容。 如果 esp32-cam 推流的速度大于我们解析的速度，那么 esp32-cam 推送的内容就会堆积在 buffer 变量中(因为 TCP 是可靠的协议，TCP 保证将 esp32-cam 发送到内容送达)。占用大量的内存不说，还会遇到累积延迟的问题。也就是说程序当前解析的一帧，其实发生在过去，表现就是画面的延迟。而且这种延迟是会累积的，随着时间的推移，延迟会越来越大。 所以如果我们解析的时候遇到了很多份响应(说明此时 esp32-cam 推流速度大于解析速度)，那么就应该只取其中的一份，其他的响应都丢弃，这样就不会有内容堆积在 buffer 中。 最后，主线程和 libcurl 的线程同时访问了变量 buffer，需要加锁控制。 考虑到只需要在 buffer 被修改后才需要解析 buffer，所以我还用上了条件变量(condition_variable)。 条件变量通常和 lock_guard/unique_lock 一起使用。它会释放锁并阻塞，直到另一个线程将 flag 变为 true，并发出通知后才继续执行。 修改后的完整程序： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;regex&gt;#include &lt;future&gt;#include &lt;curl/curl.h&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;std::mutex mutex_buffer;std::condition_variable cv_buffer;// flag: 表示是否有新数据到达bool arrived = false;static size_t reWriter(char* buffer, size_t size, size_t nmemb, string* content){ unsigned long sizes = size * nmemb; { std::lock_guard&lt;std::mutex&gt; lock(mutex_buffer); content-&gt;append(buffer, sizes); } arrived = true; cv_buffer.notify_one(); return sizes;}int main(){ curl_global_init(CURL_GLOBAL_ALL); CURL* curl; curl = curl_easy_init(); // esp32-cam 推流的网址，改成自己的 string url = &quot;http://192.168.1.123:81/stream&quot;; // 这里使用 string 作为 buffer，比较方便 string buffer; thread th = std::thread([&amp;]() { while (true) { /* 开启跟随跳转, 这里没必要设置，抄代码的时候没删掉 */ curl_easy_setopt(curl, CURLOPT_FOLLOWLOCATION, true); /* 设置超时时间(单位：秒)，不要太长，因为 esp32 的网络不太稳定，如果断连需要尽快重连 */ curl_easy_setopt(curl, CURLOPT_TIMEOUT, (long)5LL); /* 关闭 SSL 验证, 这里没必要设置，抄代码的时候没删掉 */ curl_easy_setopt(curl, CURLOPT_SSL_VERIFYPEER, false); curl_easy_setopt(curl, CURLOPT_SSL_VERIFYHOST, false); /* enable TCP keep-alive for this transfer */ curl_easy_setopt(curl, CURLOPT_TCP_KEEPALIVE, true); /* keep-alive idle time to 120 seconds */ curl_easy_setopt(curl, CURLOPT_TCP_KEEPIDLE, 120L); /* interval time between keep-alive probes: 60 seconds */ curl_easy_setopt(curl, CURLOPT_TCP_KEEPINTVL, 60L); // curl 数据处理函数 curl_easy_setopt(curl, CURLOPT_WRITEFUNCTION, reWriter); curl_easy_setopt(curl, CURLOPT_WRITEDATA, (void*)&amp;(buffer)); // 设置处理HTTP头部的功能函数 curl_easy_setopt(curl, CURLOPT_URL, url.data()); // 发起请求（会阻塞当前线程） cout &lt;&lt; &quot;正在发起请求...&quot; &lt;&lt; endl; curl_easy_perform(curl); cout &lt;&lt; &quot;连接已经断开!&quot; &lt;&lt; endl; } }); th.detach(); // 让线程独立运行 while (true) { std::unique_lock&lt;std::mutex&gt; lock(mutex_buffer); cv_buffer.wait(lock, [] { return arrived; }); arrived = false; int64_t buffer_length = buffer.size(); cout &lt;&lt; &quot;buffer_length: &quot; &lt;&lt; buffer.size() &lt;&lt; endl; regex pattern(&quot;\\r\\n--123456789000000000000987654321\\r\\nContent-Type: image\\/jpeg\\r\\nContent-Length: ([\\\\d]+)\\r\\n\\r\\n&quot;); smatch result; if (!regex_search(buffer, result, pattern)) continue; if (result.size() &lt;= 1) continue; int64_t image_length = stoll(result[1].str()); int64_t header_length = result.length(0); // 如果图片完整地储存在 buffer 中，才读取图片的数据 if (header_length + image_length &lt;= buffer_length) { // 取出 jpg 图片内容 string image_buffer = buffer.substr(header_length, image_length); // 清除 buffer，这一步很关键 buffer.clear(); // 使用 OpenCV 读取 jpg 图片 Mat tmp = Mat(1, image_length, CV_8UC1, (void*)image_buffer.data()); cv::Mat decodedImage = imdecode(tmp, 1); if (decodedImage.data != NULL) { // 翻转 esp32-cam 传来的图片，根据需要删去或保留 Mat filped; flip(decodedImage, filped, -1); imshow(&quot;display&quot;, filped); waitKey(10); } } } return 0;}","link":"/2021/11/10/%E4%BD%BF%E7%94%A8OpenCV%E5%A4%84%E7%90%86esp32-cam%E6%8E%A8%E6%B5%81/"},{"title":"使用Fiddler在WSA(Windows安卓子系统)上抓包","text":"使用Fiddler在WSA(Windows安卓子系统)上抓包。 为什么选择 WSA？因为逆向分析的需要，很多逆向分析的工具都需要 Root 权限。使用 WSA 进行逆向分析的优势之一是摆脱了实体机的限制。在实体机上获取 Root 权限、安装 Xposed 框架都是比较困难的，会受到手机品牌厂商的限制。在 Android 手机越来越封闭的趋势下，连为发烧而生的 MIUI 也做出很多限制。在 MIUI 系统上解锁 Bootloader、获取 Root 权限需要获得内测资格，而获取内测资格需要给 MIUI 社区打工（每周提交 BUG），非常麻烦。 在虚拟机上进行逆向分析就会好很多，因为很多虚拟机一般都已经提供了 Root 权限。但是 Windows 平台的 X86 虚拟机一般不能运行只有 ARM ABI 的 APP（比如今日校园，在 x86 Android 上运行会闪退，因为它只提供了 ARM ABI）。为了解决这个问题，我只能在手机上创建 Android 虚拟机（VMOS Pro）来进行逆向分析。使用 WSA 进行逆向分析的第二个好处就是 WSA 可以将 ARM 指令转译为 x86 指令，从而能够运行这些只有 ARM ABI 的程序（而且效率不低，可以很流畅）。 此外，常用的虚拟机的 Android 版本都比较低，常见的 Android 版本有 Android 5 和 Android 7。这个目前没有造成什么影响，但是 APP 完全可以通过提高最低版本来增加逆向难度，比如限制只能在 Android 10 以及以上版本的系统上运行。而 WSA 的版本是 Android 11，是比较新的版本。刚好 Android 12 也已经推出了，后续还可能有机会升级到 Android 12 Fiddler 简要介绍Fiddler Classic 是一个免费的 Windows 平台抓包软件，适用于抓取、分析 HTTP(S) 协议（但是不支持 HTTP/2）。 Fiddler 的原理是创建一个代理服务器，这样经过代理服务器的 HTTP(S) 协议数据包就都能被捕获了。对于 HTTPS 需要安装 Fiddler 的根证书，才能解密出原文。 说实话这个软件不是最好的软件，因为它还挺容易崩溃的。但是这个软件免费，而且用法简单。只要装上证书、设置好代理就能用。所以我常用来作快速分析。 在 WSA 上使用 Fiddler这里 Fiddler 的下载和安装就不过多介绍了，都是一些基本操作。获取 Fiddler 的下载地址还需要提供一个邮箱，可以使用十分钟邮箱接收下载地址。 配置 Fiddler在菜单栏点击 Tools/Options 打开 Fiddler 的设置页面。 按照如图所示，在 HTTPS 页面 勾选Capture HTTPS CONNECTS 和 Decrypt HTTPS traffic 启用 Fiddler 的解析 HTTPS 协议的功能。 另外在 Connections 页面 勾选 Allow remote computers to connect 以允许远程计算机连接 Fiddler 的代理服务器。 留意一下 Fiddler 代理的端口，后面要用到这个端口，一般来说默认是 8888。 配置 WSAWSA 联网的原理和其他的虚拟机是一样的，都是通过一个“虚拟出来的 Wifi 连接”联网的。 因此只要给这个 Wifi 设置代理，就可以抓取所有 APP 的数据包了。 要打开 WSA 的 Wifi 设置页面，你可以用 ADB 指令： 1adb shell am start -n com.android.settings/com.android.settings.Settings 也可以用一个比较受欢迎的工具箱 WSAToolBox。 然后如图修改 Wifi 的代理设置。代理的 IP 地址即网关的地址，端口即上面 Fiddler 设置页面显示的端口（默认为 8888）。 为了避免 Windows 程序的数据包刷屏，可以点一下 Fiddler 左下角的 Capturing，让它不再显示，这个开关不影响远程连接，只会不再捕获 Windows 程序的数据包。 抓取 HTTPS 包至此，虽然可以通过 Fiddler 进行抓包，但是你的 App 很可能处于“断网状态”。而且 Fiddler 也无法看到数据包的明文。这是因为目前大多数 App 都已经通过 HTTPS 协议进行通讯。 HTTPS 的出现就是为了解决 HTTP 明文传输，容易被中间人查看、修改数据造成的信任问题，刚好 Fiddler 就是这样的中间人角色。 要让 Fiddler 能够看到 APP 发出的数据包的明文，需要安装 Fiddler 的根证书。 在高版本 Android 上安装根证书是比较麻烦的。在 Android 7 以下的版本，只需要在设置里安装一下就可以了。从 Android 7 开始，证书会被分为系统证书和用户证书，而且 App 默认是不信任用户安装的证书的。要把证书安装到系统证书，需要获得 /system 的读写权限，把证书写入到 /system/etc/security/cacerts 中。 网上有很多安装系统根证书的教程，但是可能不适用于 WSA(我试过一些教程，但是失败了)。所以我推荐一种新的方法，那就是使用 MagiskTrustUserCerts。这个 Magisk 模块会在每次开机时把用户证书移动到系统证书里。也就是说，使用这个模块之后，只需要安装用户证书，然后重启，用户证书就变成系统证书从而被所有 App 信任了。 安装 Magisk 和 LSPosed这个部分的教程很可能会随着大佬对 WSA 的探索而更新，所以我不打算把它翻译到这里，读者可以在 MagiskOnWSA 找到如何将 Magisk 和 LSPosed 安装到 WSA。 在这之后，不要忘了安装上面提到的 MagiskTrustUserCerts 模块。 安装 Fiddler 根证书为系统证书可以在 Windows 的浏览器里访问 http://127.0.0.1:8888 下载 Fiddler 的根证书，把它传输到 WSA里。然后在 Android 设置页面 / 安全 / 加密与凭据 / 从SD卡安装 里安装 Fiddler 根证书。 重启 WSA 后，Fiddler 的根证书应该就被移动到 系统根证书里了。 解决 SSL Pinning不少 APP 都使用了 SSL Pinning，也就是只信任自己设置的根证书，那么上面设置的系统根证书就对这个 APP 无效了。要绕开这个限制，可以使用一个 Xposed 模块，JustTrustMe。 装好 JustTrustMe 后，在LSPosed 里启用它，就可以抓取大多数 APP 数据包并进行分析了。 最后我对一些概念不是很了解，尤其是 HTTPS 和 SSL Pinning 相关的知识了解甚少。如果本文有什么错误或者细节需要补充，希望各位大佬指出。 编辑记录2020-11-03: init","link":"/2021/11/03/%E4%BD%BF%E7%94%A8Fiddler%E5%9C%A8WSA-Windows%E5%AE%89%E5%8D%93%E5%AD%90%E7%B3%BB%E7%BB%9F-%E4%B8%8A%E6%8A%93%E5%8C%85/"},{"title":"将UTF8转换成GB18030的疲倦过程","text":"将UTF8转换成GB18030的疲倦过程 编码问题是个很恶心人的问题。—— 鲁迅没说过这句话 &emsp;&emsp;之前用C++开发过一个酷Q机器人插件（酷Q是一个基于Android QQ协议的QQ机器人软件，可以接收、发送各种类型的QQ消息），但是因为插件使用GBK编码的原因，插件无法发送emoji表情。为了让这个插件能够发送emoji表情，必须修改插件程序使用的编码。 &emsp;&emsp;首先可以确定，酷Q的发送消息API用的肯定是GBK/GB2312之类的编码。因为插件在中文Windows+VS环境下开发，VS默认使用的编码就是GB2312（还是GBK？）。而我在调用这个API的时候，没有经过编码转换就能达到预期效果，也就是没有乱码。只有在发送文本里含有如Emoji、颜文字等特殊符号的时候，才会出现如 “????” 这种情况。 &emsp;&emsp;那么酷Q有没有什么发送消息的API是支持Unicode的呢？查阅资料后发现，酷Q的所有API使用的都是GB18030编码[1]。这种编码不仅对GBK/GB2312向下兼容，而且支持Unicode符号。酷Q使用这种编码是因为酷Q的插件大多用易语言开发，而易语言对Unicode的支持不好，如果使用GB18030编码就可以在保证一定的兼容性的同时支持Unicode符号。 &emsp;&emsp;我的插件发送的文本内容来自Web API，使用的是UTF8编码。在调用Web API获得文本内容后，需要把UTF8编码转换成GBK编码。都统一成GBK编码，标准输出、日志输出就不会出现乱码。我的想法是让整个程序都在UTF-8编码的环境下运行，也就是让标准输出、日志输出的文本的编码都是UTF-8。当然这样会有新的问题，中文Windows下CMD默认使用的是GBK编码，也就是说如果标准输出的文本是UTF-8编码，那么控制台黑框框看到的内容全都是乱码。不过我的插件没有用到标准输出，也就暂时不用担心这个问题。 MSVC使用UTF-8编码编译&emsp;&emsp;要做到程序在UTF-8环境下运行，其实只需要把源代码的文件改成UTF-8编码。然而VS保存文件的编码在中文windows下默认是GB2312。为了让保存的文件是UTF-8编码，可以使用一个叫做”forceAllUTF8”的VS扩展。 &emsp;&emsp;我用的是图中框起来的那个插件，第一个扩展和第二个扩展的区别是有无BOM，但是Without BOM好像无法正常编译，提示非法字符”0xXXXX”，不知道什么原因（即使添加了参数 /utf-8 ）。 &emsp;&emsp;这还不够，MSVC对UTF-8的支持不够好，只做到这一步可能会无法编译，所以还需要在编译器的编译选项里加一个 /utf-8 参数。 &emsp;&emsp;在VS里把所有的文件都打开再保存，重新编译、执行，插件运行日志文件的编码果然变成了UTF-8编码。 将UTF-8编码转换成GB18030编码&emsp;&emsp;我知道boost可以轻松做到编码转换。然而当我执行以下测试代码时…… &emsp;&emsp;得到的却是…… &emsp;&emsp;报错了！vector越界？ &emsp;&emsp;经过一系列的测试，发现只有在目标编码是GB18030的时候会出现这个错误。GBK to GB2312、UTF-8 to GBK 、 UTF-8 to GB2312都不会出错。 &emsp;&emsp;查了下资料（这里花了N个小时），发现这可能和boost::locale的实现方法有关。比如在Windows下使用MSVC编译boost，boost会使用Win32 API来实现boost::locale。翻了下报错点的调用栈，也确实发现了Win32 API。 &emsp;&emsp;继续查资料发现，编译boost::locale的时候可以指定使用ICU实现。而且vcpkg就可以做到个性化编译。那这就好办了！删掉原来的boost之后，直接执行: 1./vcpkg install boost-locale[icu] &emsp;&emsp;然而事情并没有那么简单。使用了这个所谓的指定使用 [icu] 实现的boost::locale有同样的问题、而且一样调用了Win32 API，和之前没有任何变化。 &emsp;&emsp;找不到原因，不知道是vcpkg的问题还是boost的问题。没办法，只能暂时放弃使用boost，然后寻找到了同样有编码转换功能的 libiconv 。 &emsp;&emsp;使用 libiconv 的过程异常顺利。贴一下测试用的代码： 1234567891011121314151617181920212223242526272829string utf8_to_gb18030(const string&amp; uStr){ iconv_t conv = iconv_open(&quot;GB18030&quot;, &quot;UTF-8&quot;); if (conv == (iconv_t)-1) { iconv_close(conv); throw &quot;An error occurred in iconv_open.&quot;; return &quot;&quot;; } string ret; ret.resize(uStr.size() * 2, '\\0'); // 不知道转码之后的字符串长度是多少，直接扩容两倍防止溢出 size_t inbytes = uStr.size(); size_t outbytes = ret.size(); char* inPtr = const_cast&lt;char*&gt;(uStr.c_str()); char* outPtr = const_cast&lt;char*&gt;(ret.c_str()); if (iconv(conv, &amp;inPtr, &amp;inbytes, &amp;outPtr, &amp;outbytes) == (size_t)-1) { iconv_close(conv); throw &quot;An error occurred in iconv.&quot;; return &quot;&quot;; } iconv_close(conv); return ret;} &emsp;&emsp;算是暂时解决的编码转换的问题。 libiconv 毕竟是个C语言库，传入的数组指针需要自己分配数组的空间。但是我并不知道转换之后的内容会占用多大的空间，为了防止越界直接设置为原大小的两倍，方法很暴力但是很有效。 [1] 让编写的应用在使用酷Q API时支持Unicode文本, https://cqp.cc/t/38233","link":"/2020/01/04/%E4%BD%BF%E7%94%A8libiconv%E5%B0%86UTF8%E8%BD%AC%E6%8D%A2%E6%88%90GB18030/"},{"title":"可乐","text":"可乐","link":"/2020/03/04/%E5%8F%AF%E4%B9%90/"},{"title":"写了一个WebSocket客户端","text":"写了一个WebSocket客户端 以前就接触过 tcp、udp 的编程，但是一直停留在 “Hello World” 的水平。这一次想写WebSocket客户端，是因为现有的库都非常巨大，但是我只需要一个能收消息的客户端。 之前一直用的是 easywsclient 这个库，只有一个头文件和一个源文件，简单好用。看源代码也没有很复杂，就自己做了一个“复刻版”（LightWebSocketClient）。 WebSocket 协议是有标准的，具体可以在 RFC6455 看到。协议的内容挺长的，但大可不必被吓倒，因为都很好理解。 123456789101112131415161718 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1+-+-+-+-+-------+-+-------------+-------------------------------+|F|R|R|R| opcode|M| Payload len | Extended payload length ||I|S|S|S| (4) |A| (7) | (16/64) ||N|V|V|V| |S| | (if payload len==126/127) || |1|2|3| |K| | |+-+-+-+-+-------+-+-------------+ - - - - - - - - - - - - - - - +| Extended payload length continued, if payload len == 127 |+ - - - - - - - - - - - - - - - +-------------------------------+| |Masking-key, if MASK set to 1 |+-------------------------------+-------------------------------+| Masking-key (continued) | Payload Data |+-------------------------------- - - - - - - - - - - - - - - - +: Payload Data continued ... :+ - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - +| Payload Data continued ... |+---------------------------------------------------------------+ 写这个库花了两天时间，其中大部分时间都在研究怎么写 tcp socket 相关的代码。 下面是写这个库遇到的问题和一些经验。 如何调试使用 nodejs 的 ws 库。几行代码就能创建一个 WebSocket 服务器。 连接ws服务器，发消息总是提示 frame 错误这个问题解决起来特别简单，但是发现问题的来源花了特别久。其实就是发送建立请求的字符串的时候，多发了个’\\0’。 这个 ‘\\0’，储存到了ws服务器的buffer中。于是我的第一帧内容的开头就多了个’\\0’，服务器看不懂了，就报错崩溃了。 我修改了 server 端的代码，把server 收到的 buffer 输出出来，才发现的这个错误。 关于“粘包”，TCP协议不背锅现在去搜索“TCP 粘包”，依然能搜到很多信息。TCP粘包，大概是说服务器/客户端调用了多次 send 发送数据，但是客户端/服务器 recv 一次全都收到了。 粘包其实是一个误会，因为 TCP 传输的数据是抽象成“数据流”的，没有“数据包”的概念。TCP协议保证每次 send 都能收到，但是不会把每次 send 的内容区分开。实际上还可能出现 recv 一次，只能收到 send 的一部分数据。（比如 send 的数据的长度大于 recv 的缓冲区的大小） 解决“粘包”问题，是应用层的事情。比如 HTTP 协议就在头部规定了数据的长度。客户端/服务器在解析的时候，就要根据HTTP协议头部给出的长度，从TCP“数据流”中读取指定长度的数据。 WebSocket 协议也有类似的机制，每一帧数据的头部都储存了数据的长度。 TCP的这个特性在写程序的时候，还是挺麻烦的。 多线程？单线程？TCP 协议常常要提到多线程。因为 recv 会阻塞当前线程，直到有数据到达才返回。简单粗暴的解决方法是，创建一条线程专门执行 recv，有数据到达就存到buffer里。主线程从buffer里取数据解析、处理。 但这就涉及到两条线程访问同一个变量的问题了，最终弄下来，也没有多么简单。 有没有办法在一条线程上既能recv，也能解析呢？ 我找到了 select 模型。select 模型一般的教程都以服务端举例，其实用到客户端上也是可以的。 本质地来说，select 就是监控文件描述符状态的函数（unix的一个设计哲学，一切皆文件，socket 也是一个文件描述符）。 select 函数能同时监控多个文件描述符，如果文件变得“可读”、“可写”或者“有错误”，那么它就会返回。如果已知某个 socket 变得可读，这时候再执行 recv 就一定有数据啦。（当然也可能读到长度为0的数据，意思是socket被关闭了） 最重要的是，select 是可以设置超时时间的。用select监控一会socket，再解析一会buffer，把这个“一会儿”弄得很短，就做到一边监控，一边解析的效果了。 使用单线程，让我的 WebSocketClient 变得非常简洁，单线程比多线程还是简单一点的。 很多 WebSocket 库之所以那么复杂，就是因为引入了 asio 之类的异步库。当然还有因为涉及到安全，引入了 openssl。 跨平台用到的System API都是简单而古老的API，做到跨平台还是比较轻松的。Windows 的 Win32 API看着头大，时不时来个全大写的宏，我英语又不好，要慢慢读才看得懂。 虽然如此，但我还是把 Linux 的 API 往 Windows 上靠近。把 Linux 缺失的宏补上，从而做到跨平台。 Windows 的头文件引入了特别多的宏。为了避免库的使用者被这些宏污染，必须想办法把头文件移动到 .cpp 的源文件里。这里用到了一个C++编程的技巧，PIMPL Idiom。原理就是利用前置声明，即在头文件里声明一个 struct，在源文件里定义这个struct。前置声明的struct是不完整类型，C/C++允许不完整类型的指针存在。","link":"/2021/01/27/%E5%86%99%E4%BA%86%E4%B8%80%E4%B8%AAWebSocket%E5%AE%A2%E6%88%B7%E7%AB%AF/"},{"title":"准备数学建模国赛的心得体会","text":"😂我对准备数模国赛的一些看法，仅供参考。我参加过两届全国大学生数学建模竞赛，我在大一的时候经人推荐和两个学姐组队准备参加数学建模国赛，从此开启了数模之旅。（感谢推荐我的人和选择我的队友，让我能认识到这样一个有意思的比赛） 这篇博文总结了我这两次准备国赛的过程和方法，希望能帮到准备参赛的学弟学妹们。 关于全国大学生数学建模竞赛全国大学生数学建模竞赛一般在九月份进行，差不多是刚开学的第一周的周末。市赛的比赛结果比较快，一般国庆节之后就能有结果。和市赛结果一起出来的，是推荐国奖的队伍名单。推荐国奖不代表一定能拿到国奖，推荐国奖的结果一般在十一月或者十二月出来。 数模国赛总共有 5 道题，有 3 题是本科组（以前只有 2 题），有 2 题是专科组。本科组的 3 题的出题方向是有一定规律的。 规律性最强的是 C 题，它往往和统计有关，有大量的数据需要处理（但是国赛也有可能不提供数据，比如 2019 年的 C 题的数据需要自己去找）。其次是 A 题，2019 年和 2020 年的 A 题都和工业生产有关，有相关专业背景会更好做（我大一的时候看 2019 年的 A 题，当时还没学机械设计基础，所以连凸轮都不认识，题目都没读懂）。 准备国赛的时间线我校对数学建模竞赛是相当重视的。一般在上半年就会开始校赛培训（以网课的形式），还会有数模的宣讲会以及历年获奖选手的经验分享会。然后会组织一次数学建模校赛。数学建模校赛考虑到大家都有课，比赛时长是一周，在课余时间完成比赛。 校赛之后就会组织报名国赛，以及分配指导老师。报名国赛的同学需要在放暑假后留校一星期进行暑期培训（2020 年的暑期培训因为疫情改成网课了，非常可惜，不清楚以后还有没有）。暑期培训除了上课还有一次模拟比赛，这次模拟赛由指导老师完成讲评。 在暑假期间，学校还可能会组织参与深圳杯比赛和重庆市地区的比赛，作为练习。我建议参加深圳杯的比赛，因为深圳杯的题目质量还是不错的，认真完成提交作品，说不定能收获一个大奖。其他的比赛可以看精力决定要不要参加。 在正式国赛开始前还会有第二次模拟赛，作为最终练习。 模拟赛的题目好像都是用的其他学校的题目，这些题目的难度还是偏大的，我感觉比国赛都要难，所以做不出来也不要放心上。 我对组建队伍的想法关于组建队伍，我经常听到一种组队的说法，即数模组队需要一人建模，一人编程，一人写作。 关于这个说法，我有不同的看法。数模的队伍确实要有人建模、有人编程和有人写作，但不是把这三项任务分别分到一个人身上。我认为建模可以三个人一起来，写作则是谁建模谁写作，编程的任务实际上没有很重，只需要一个人就好了。 我两次参赛的队伍都是这样实行的。我主要负责编程和排版（第一个队伍里只有我对 Latex 比较熟，因此排版就全交给我了）。建模部分虽然我不擅长，但我也会帮一点忙。对于一些简单的问题，我会尝试自己解决，然后让队友去思考后面更复杂的问题。我也会学习我队友建立的数学模型，这样在需要编程解模型的地方，我才好写出程序。 数学建模竞赛需要学习的技能关于论文写作与排版论文写作和排版，选择 Latex 还是 Word？很多人认为 Latex 比 Word 更难，但是 Word 想要做到高效排版，可能不比 Latex 简单。 因为已经有前辈做好了数模国赛的 Latex 模板，所以只需要很少的 Latex 知识就可以用 Latex 来写数模国赛的论文了（数模美赛也有现成的模板）。 Latex网上有很多的 Latex 入门教程，篇幅不长，用来入门非常适合。 但是如果想系统地了解 Latex，我建议阅读刘海洋的《Latex 入门》。（来自网络，可能失效: PDF下载） 不管是网上的教程还是《Latex 入门》，都有讲如何安装 Latex 发行版。因此这篇文章不打算展开讲如何安装 Latex 发行版。但是这里我提供 TexLive 发行版的下载地址，以免下载到旧版本，或者忍受百度网盘的缓慢速度。 TexLive 的下载地址(中国科学技术大学镜像站): https://mirrors.ustc.edu.cn/CTAN/systems/texlive/Images/TexLive 的下载地址(重庆大学镜像站): https://mirrors.cqu.edu.cn/CTAN/systems/texlive/Images/获取TexLive ISO镜像的官网页面：https://www.tug.org/texlive/acquire-iso.htmlTexLive 官网介绍的安装方法: https://www.tug.org/texlive/windows.html 要使用 Latex 排版数模论文，要学的 Latex 知识不会很多，所以不用担心学不会。 首先你需要学会使用现成的模板，比如数模国赛的模板可以在 github.com/latexstudio/CUMCMThesis 里找到，数模美赛的模板可以在 github.com/latexstudio-org/mcmthesis 找到。 然后你需要学会使用 Latex 编写公式。我的学习方法是找一篇公式很多很复杂的论文，把里面的公式都写一遍(显示效果要一模一样，这里面可能涉及多行公式的对齐)。这个过程肯定会有很多困难，所以肯定会花很多时间在百度上，最后整理成自己的笔记，以后查自己的笔记本就快了。 最后你要学会插入图片和表格。Latex 的表格是很难用的，我推荐使用 tablesgenerator 来生成 Latex 表格代码，可以明显改善体验。(这个工具支持粘贴 Excel 或者 Word 里的表格，所以你甚至可以在 Excel 里做好表格后粘贴到这个工具里生成 Latex 代码) 这里还要强调一个 Latex 的特性。在 Word 里，你的图片和表格放哪里完全由你说了算。但是在 Latex 里，默认是让 Latex 来管理你图片和表格的位置，Latex 会在合适的位置里插入图片和表格。比如这一页的空间已经放不下一张图片了，那么 Latex 会在下一页的某个位置放置这个图片。 对此我的解决方法是：不要管他，让 Latex 自己选择位置就好了。 所以，文章里尽量不要写 “如下图所示” 之类的文字，因为图片很可能不在你这段文字的下方。尽量用 “如图 \\ ref{XXX} 所示” 的写法代替。 提示： \\ ref{XXX} 是创建交叉引用，XXX 是图片或者表格的标签，Latex 会自动将它替换成编号，比如可能替换成：如图 5 所示 Latex 编辑器有很多，如果熟悉 VSCode，也可以尝试以下 VSCode (+LaTeX Workshop插件) 来写 Latex。这个插件有一个预览公式的功能，写公式的时候不用编译就能先看到结果。 如果三个队友都使用 Latex 写作，可以用 overleaf 这个在线编辑器来同时编辑同一份文档。(但是这个网站国内访问速度很慢) 如果所有队友都会 git，也可以用 git + github/gitee 来实现一起编辑同一份文档。 Word在数模中没用过 Word 来写作，所以我没什么能介绍的东西。 我推荐充分利用 Word 的样式功能，减少设置样式的工作量，可以提高排版效率。 另外就是 Office 2019 版本或者 Office 365 版本的 Word 支持用 Latex 编写公式，如果想在 Word 里使用 Latex 可以升级到 2019 版本或者购买 365 版本。 关于编程和算法Matlab如果有编程基础的话，学习 MATLAB 是很快的事情。学校图书馆有很多 MATLAB 的书，这些书里甚至有不少和数模是有关的。我借了四五本 MATLAB 的教材，挑了两本我能看懂的就开始学了。(现在有的书真的是不喜欢讲人话，所以我借书都会借四五本，把不讲人话的书都还回去) MATLAB 只是个工具，不要花太多时间去专门学习，应该在有需要的时候再去查资料查文档。我入门 MATLAB 大概只用了一个星期，主要是浏览和尝试各种常见函数，也就是运行书上给的例子。(其实书上有很多概念对当时的我来说并不常见，比如我当时根本不认识线性规划和数值积分，我的策略是先了解，留个印象以后方便翻书) MATLAB 的内置函数很多，而且用法和新函数随着版本升级一直在变化，是记不住也没必要记住的。如果有什么书列举了一大堆的函数用法，那一定不是什么好书。我认为学习 MATLAB 的很重要的一点是学会从 MATLAB 的官方文档里找到答案。 MATLAB 官网的快速入门中文教程：https://ww2.mathworks.cn/help/matlab/getting-started-with-matlab.htmlMATLAB 文档：https://ww2.mathworks.cn/help/index.html 有一些常用的制图函数，比较简单可以提前学一下记录到笔记本，要用的时候查资料快一点。 比如 plot(散点图)、fplot(函数画图)、gplot(邻接矩阵画图)、bar(条形图)、subplot(在一个窗口画子图)、xlabel(X坐标的标签)、ylabel(Y坐标的标签)、gtext(在图中写文字)、legend(显示图例)等。还有指令 hold on; grid on; 最后我推荐一下 Matlab 的 cftool 工具箱，这是个曲线拟合工具箱，经常能用到。 LingoLINGO是专门用来求解优化模型的软件。我做的第一个数模的练习题就是用线性规划来解决下料问题，我因此自学了 LINGO。 我看的教材是网上翻到的一个小册子，出处已经找不到了，我感觉讲的还是比较清晰的。(下载: LINGO入门) 12345678910111213141516sets: V/1..56/ : ; L/1..10/ : CPT_L ,CPT_N ; D(V,L) : x ; endsetsdata: CPT_L = 265 275 290 313 328 405 411 414 415 420; CPT_N = 46 60 55 38 6 42 30 16 10 12;enddata@for(D:@gin(x));max = @sum(V(m): @sum(L(n): CPT_L(n)*x(m,n) ) );@for(V(m): @sum(L(n): CPT_L(n)*x(m,n) )&lt;= 2000 );@for(L(n): @sum(V(m): x(m,n))= CPT_N(n)); 如果要用到线性规划，我会先用少量数据，编写 LINGO 程序来验证线性规划模型的正确性。 这是因为 LINGO 的语法比较接近自然语言，如果模型错了改起来比较方便。而 Matlab 线性规划函数(linprog)的参数是一个个矩阵，不如 LINGO 的语法直观。 求结果的时候，由于数据很多，而且往往需要预处理，我会用 Matlab 编程来求解最终答案。 MathematicaMathematica 是我学习数学的工具。它不像别的编程语言需要创建一个源代码文件来写代码，Mathematica 需要创建一个笔记本来写代码。Mathematica 可以把计算的过程一步一步显示出来，这是我最喜欢的功能之一。 Matlab 有的功能 Mathematica 基本都有，如果更喜欢 Mathematica 那么可以用它来代替 Matlab 也不是不可以的。 但我比赛中并没有用过 Mathematica，因为我用它没有 Matlab 熟练。 Python我没有在比赛中用过 Python，但是我的队友使用 Python 进行多元回归分析和使用现成的智能优化算法 (scikit-opt)。 我推荐学习一下这个智能优化算法库，它内置了遗传算法、模拟退火等常用的智能优化算法。我在深圳杯的比赛是自己写的模拟退火算法，看了好几篇论文当场学会当场写算法，如果我当时知道有这个库，我可以节约一个下午的时间。 R语言我也没在比赛中使用过 R 语言，因为我不会。但是我应用统计专业的队友是会的。数模暑期培训也会简单讲解这个 R 语言，它在解决统计相关的问题很有用。 SPSS Statistics这个软件我也提供不了什么有用的信息，因为我自己也不会。我认为要在学习了应用回归分析之后才能正确地使用 SPSS，而不是自己根据网络的教程胡乱分析(说的就是我自己了)。 关于应用回归分析，我的指导老师推荐了一本书是《应用回归分析（第5版）》(何晓群，刘文卿 著)。 关于作图函数图、散点图等图像可以用上面提到的 Matlab 来完成，这里主要说的是流程图。 流程图可以用 PowerPoint 或者 Visio 来完成。Visio 其实也是 Office 的一部分，不过要单独下载。(下载地址，来自网络，可能失效：msdn.itellyou.cn；xyhelp.cn) tianyou 是交大以前的软件下载站，现在已经无人维护。xyhelp 是交大学长的创业项目，里面的软件基本都有校园网内网的下载地址，只要连上校园网就可以下载，内网传输速度更快。 高版本的 Office 已经支持直接导出为 PDF，我推荐将画好的图像导出为 PDF 再插入到 Latex 文章里。这样保存、插入到论文里的图片是矢量的，怎么放大都是清晰的。 从 Office 文档里导出的 PDF 一般都有白边，可以使用 Latex 发行版里自带的一个 PDF 裁剪工具(pdf-crop)，将白边去掉。 pdfcrop 是个命令行工具，装好 Latex 发行版之后一般就能直接用了。 12# 在 img_001.pdf 所在目录执行 pdfcrop：pdfcrop img_001.pdf 上面的指令会在 img_001.pdf 目录下生成一个 img_001-crop.pdf。 大量数据预处理有的比赛会发布一个很大的数据集，格式通常是 csv 文件。这个类型的文件可以用 excel 打开，但是尽量别这样做，excel 需要很长时间（长达几分钟）才能打开。 csv 文件是纯文本文件，可以用 VSCode 等文本编辑器打开，这样速度会快很多。 其实我不会处理数据的，所以接下来我写不下去了。🤣 比赛期间的感受比赛第一天的下午 18 点出题到第四天的晚上 20 点结束，这期间的节奏是一种先慢后快的节奏。 数模选题很重要，数模国赛没有简单的题目，数模的选题选的是最适合自己团队的题目。 我认为我两次比赛的队伍都很适合解决和运筹学相关的题目，因为平时模拟赛都对这种题目更有感觉。如果选题确实不对，是可以大胆考虑换题的。我两次比赛都有过换题的经历，一次换成功了，第二次最终没有换题。 我第一次比赛是第二天上午决定题目，然后第三天上午换题，最后拼命完成。这一次比赛我们一开始选的是 A 题，之所以选这个题是因为 B 题没看懂而C 题的数据不好找。我们这样选题完全没考虑团队的做题经验，我们从没做过 A 题这样的题目。可以说我们选题很失败，我们做不出来 A 题。 我们为了能够交上作品，我们换了 C 题，换题的时候已经浪费了一半的时间了，所以第三天的晚上我们不得不通宵写论文了。 做 C 题的时候才发现，我们的队伍更适合做 C 题，这个题对我们来说并没有选题时想象的难，最后做的非常快及时完成了作品。 第二次比赛实际上我们选对了题，我觉得那个题真的很适合我们队伍，但是我们没有解题的思路，所以考虑换题。那个时候是第二天晚上，即使是换题也来得及。但是凭借上一次比赛的经验，我从我们队伍以前的选题情况来看，我很确定我们不适合另外两道题。这一次我们选的是 B 题，“走出沙漠” 的题目。另外两道题分别是 A 题 “炉温曲线” 和 C 题 “信贷决策”。 我们队伍在练习赛中从未选过 A 题这种类型，所以我心里压根没有想过换到 A 题。C 题这种类型的题目我们只做过 1 次，而且做的很糟糕，我对换到 C 题也不抱希望。 但是我也怕死磕 B 题，错失了换题的最佳时机。所以我和我的队友说先放下 B 题，找一找 C 题的资料，看看 C 题有没有思路，如果有我们就换题。 一开始我也在找 C 题资料，但是我发现我查到的方法，我都没见过，不仅如此，我不知道这些方法能不能套用到这个 C 题上。这时候我就知道，我们不可能换到 C 题的。如果随便搜到个方法就拿来套用，连适用条件都搞不清楚，这样做出的结果连自己都骗不过。所以后来我又回到 B 题，继续找 B 题的解法了。 最终我们队伍决定死磕 B 题。","link":"/2021/05/11/%E5%87%86%E5%A4%87%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E5%9B%BD%E8%B5%9B%E7%9A%84%E5%BF%83%E5%BE%97%E4%BD%93%E4%BC%9A/"},{"title":"基于ObjectARX .NET的AutoCAD二次开发：项目配置","text":"ObjectARX 是 AutoCAD 的开发环境，提供面向对象的 C++ 以及 .NET 编程接口。本文将介绍两种配置 Visual Studio 项目的方法，包括不使用 Wizard 的方法。 🔗开发目标在基于 ObjectARX .NET API的 AutoCAD 二次开发中，最终需要得到的是一个（或若干个） .dll 文件。在 AutoCAD 中使用 NETLOAD 指令加载这个 .dll 文件，就可以导入包含在其中的 指令，从而扩展 AutoCAD 的功能。这些指令具体做什么工作都是自己编写代码实现的，名字也是自己取的，使用的时候和执行 AutoCAD 的内置指令没有区别。 如果你有一定的 C# 语言的程序开发基础，那么你应该已经联想到你需要一个类型为 类库(class library) 的项目，因为它的编译产物正是 .dll 文件。下文中我会介绍两种创建这个项目的方法：一种是基于 AutoCAD DotNet Wizard 的向导式创建方法，这个向导会询问你 ObjectARX 与 AutoCAD 的安装位置，自动完成项目的依赖引用与调试设置；另一种是创建普通的类库项目，然后通过 Nuget 或手动编辑的方式完成依赖引用的设置。 🔗前期准备📖安装 Visual Studio网上教程很多，这里不再介绍，注意你只需要在 Visual Studio Installer 里勾选 .NET 桌面开发 即可。 Visual Studio Installer 从 Visual Studio 2019 版本开始有（如果我没记错的话），更旧的版本应该是默认安装 .NET 桌面开发的。 我个人是推荐采用最新版本的 Visual Studio。虽然这可能会导致你无法使用 AutoCAD DotNet Wizard，因为它同时要求了 Visual Studio 与 AutoCAD 的版本。比如 AutoCAD 2023 DotNet Wizard，要求 AutoCAD 2023 以及 Visual Studio 2019。如果你使用的是早期的 AutoCAD 版本，可能会同时要求你使用非常古老的 Visual Studio，这非常的不推荐。 下文会介绍不使用 AutoCAD DotNet Wizard 的方法，采用此方法可以不考虑 Visual Studio 的版本，请直接安装最新版本，以获得最佳的开发体验。 📖下载并解压 ObjectARX请根据你的操作系统（Windows Or Mac）以及电脑上的 AutoCAD 版本，在这个链接 https://www.autodesk.com/developer-network/platform-technologies/autocad/objectarx-download 里下载 ObjectARX。 这个页面在搜索引擎中可能搜索不到，因为它是填写了邮箱之后跳转而来的。 ObjectARX 没有安装过程，下载好之后运行会提示需要解压，解压得到的目录就是 ObjectARX 本身，这个目录的名字类似于： ObjectARX_for_AutoCAD_2024_Win_64bit_dlm。 📖下载并安装 AutoCAD DotNet Wizard（可选）Wizard 可以在链接 https://www.autodesk.com/developer-network/platform-technologies/autocad 的最下面，Tools 一栏里找到。（请下载 AutoCAD DotNet Wizard 而不是 AutoCAD Wizard） 上面提到 AutoCAD DotNet Wizard 同时要求了 Visual Studio 与 AutoCAD 的版本，但其实安装程序只会检测你电脑上所安装的 Visual Studio 是否满足版本要求，因此可以只根据 Visual Studio 的版本来选择 Wizard 的版本。比如 Wizard 2024 要求 Visual Studio 2022，Wizard 2023 要求 Visual Studio 2019（有一个对应关系，可以逐个版本下载，看看哪个能装上）。 🔗使用 Wizard 创建项目打开 Visual Studio 创建项目的时候能看到 AutoCAD CSharp plug-in，按照步骤创建即可。 如下图所示，向导会询问两个路径，第一个填 ObjectARX 的 inc 目录，比如我填写的是： D:\\ObjectARX_for_AutoCAD_2024_Win_64bit_dlm\\inc。第二个路径填写的是 AutoCAD 的安装路径（包含 acad.exe）。 创建好项目后直接开始调试，调试器会启动 AutoCAD，此时注意到 AutoCAD 本身也处于调试模式。在加载插件之前，设置的断点会提示无法命中，如下图。 这是因为插件还没有被 AutoCAD 载入，在 AutoCAD 中新建一个图纸，然后执行 NETLOAD 命令，选择编译出来的 .dll 文件，就会注意到断点可以命中了。执行 MyCommand 指令，断点成功命中。 🔗手动配置项目首先创建一个 Class Library (.NET Framework) 项目，注意必须是带有 .NET Framework 的才可以。 📖设置依赖引用方法 1：从 ObjectARX 的文件进行设置如下图所示，右键项目中的 References（引用），选择 Add Reference（添加引用）。 由于我的 Visual Studio 是英文，菜单选项的中文译名依赖回忆，因此可能不准确。 展开 Browse（浏览）页面，然后点击 Browse（浏览）按钮进行选择。 导航到 ObjectARX 的 inc 目录，选择 “AcMgd.dll”、”AcCoreMgd.dll” 与 “AcDbMgd.dll” 三个 .dll 文件。 至此，依赖引用设置完成。 方法 2: 使用 NuGet如下图所示，右键项目中的 References（引用），选择 Manage NuGet Pacakages（管理 NuGet 包）。 在 Browse 页面中，搜索关键词 “AutoCAD”，在搜索结果中选择 “AutoCAD.NET”。注意右侧可以选择版本，请根据你的 AutoCAD 版本进行选择。比如图中所选择的版本 “24.1.51000”，从下方的 Description 中可以发现它对应的是 AutoCAD 2022。 选择正确的版本后，点击 Install，完成依赖配置。 📖设置调试方法如图，点击 调试按钮 右边的 倒三角按钮 展开菜单，选择菜单中的 Debug Properties (调试属性)。 如图，将 Start action 修改为 Start external program（启动外部程序），路径填写为 AutoCAD 安装目录下的 acad.exe 的路径。 至此，调试方法设置完毕。 📖创建基本代码这里的代码来自 Wizard 生成的项目，去掉了大部分注释（但其实那些注释还挺有用的，有助于了解这些代码在做什么）并略作修改。 创建一个 .cs 文件，命名为 “MyPlugin.cs”，内容如下： 1234567891011121314151617181920212223using Autodesk.AutoCAD.ApplicationServices;using Autodesk.AutoCAD.DatabaseServices;using Autodesk.AutoCAD.EditorInput;using Autodesk.AutoCAD.Geometry;using Autodesk.AutoCAD.Runtime;using System;[assembly: ExtensionApplication(typeof(ClassLibrary.MyPlugin))]namespace ClassLibrary{ public class MyPlugin : IExtensionApplication { void IExtensionApplication.Initialize() { // Initialize your plug-in application here } void IExtensionApplication.Terminate() { // Do plug-in application clean up here } }} 注意把代码中的 “ClassLibrary” 修改为你自己项目的命名空间 再创建另一个 .cs 文件，命名为 MyCommand.cs”，内容如下： 123456789101112131415161718192021222324252627using Autodesk.AutoCAD.ApplicationServices;using Autodesk.AutoCAD.Colors;using Autodesk.AutoCAD.DatabaseServices;using Autodesk.AutoCAD.EditorInput;using Autodesk.AutoCAD.Geometry;using Autodesk.AutoCAD.Runtime;using System;[assembly: CommandClass(typeof(ClassLibrary.MyCommands))]namespace ClassLibrary{ public class MyCommands { [CommandMethod(&quot;MyCommand&quot;, CommandFlags.Modal)] public void MyCommand() // This method can have any name { Document doc = Application.DocumentManager.MdiActiveDocument; Editor ed; if (doc != null) { ed = doc.Editor; ed.WriteMessage(&quot;Hello, this is your first command.&quot;); } } }} 至此，一个带有 “MyCommand” 命令的 AutoCAD 插件项目配置完毕。 🔗最后受限于写作经验，本文可能仍有不足，恳请批评指正。如果想转载本文，请在评论区或邮件联系我。","link":"/2023/07/11/%E5%9F%BA%E4%BA%8EObjectARX-NET%E7%9A%84AutoCAD%E4%BA%8C%E6%AC%A1%E5%BC%80%E5%8F%91%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/"},{"title":"多元牛顿迭代法的 Matlab 实现","text":"这学期的《最优化方法》课和《矩阵与数值分析》课都用到了牛顿迭代法，在《优化》里需要多元函数的牛顿迭代法，在《矩阵》里只用到一元函数的牛顿迭代法。 x^{(k+1)} = x^{(k)} - \\frac{f(x)}{f'(x)} \\tag{1} \\label{1}设计这两门课程的上机作业都需要自己编写一个牛顿迭代法的程序，我希望这个牛顿迭代法的实现要能同时用于求解多元函数问题和一元函数问题，还要能指定初始迭代点、目标精度和最大迭代次数。 代码最后写出来就这样：123456789101112131415161718192021222324252627282930function [fval, xval, precision, iteration] = Newton(... calc_fval, calc_grad, initial_point, target_precision, max_iteration)%% 牛顿迭代法(一元或多元函数)% INPUT:% calc_fval (function_handle): 计算目标函数值的函数句柄% calc_gard (function_handle): 计算目标函数梯度的函数句柄% initial_point (vector): 初始迭代点% target_precision (scalar): 目标精度% max_iteration (scalar): 最大迭代次数%% OUTPUT:% fval (scalar): 函数值% xval (vector): 迭代值% precision (scalar): 精度% iteration (scalar): 迭代次数%%N = 0; % 迭代次数xval = initial_point; % 迭代解precision = inf;while precision &gt;= target_precision if (N &gt;= max_iteration); break; end N = N + 1; fval = calc_fval(xval); grad = calc_grad(xval); d = grad \\ fval; xval = xval - d; precision = norm(d);enditeration = N;end","link":"/2023/01/08/%E5%A4%9A%E5%85%83%E7%89%9B%E9%A1%BF%E8%BF%AD%E4%BB%A3%E6%B3%95%E7%9A%84-Matlab-%E5%AE%9E%E7%8E%B0/"},{"title":"学校教务系统登录前端加密分析","text":"我又无聊了……学校教务系统登录前端加密分析 突然想做一个方便自己的课表程序，课表的数据在教务系统里，所以就想写个爬虫程序，从教务系统里爬取课表。首先是要通过模拟表单提交，登录进教务系统。清空Cookies、打开开发者工具、开启网络分析（其实就是抓包）、刷新页面……基本操作，没有什么问题。 分析一下Cookie组成，非常简单，就一个Cookie。 验证码地址也很简单，没有什么奇怪的参数。 1Request URL: http://马赛克/jsxsd/verifycode.servlet 再分析一下表单提交的数据…… 居然有加密！这个破系统居然还有加密！ 问题不大，登录入口那么重要，有加密也挺正常，先从源代码里找找有没有“encoded”。 一下子就找到了，加密方式是先加密学号、再加密密码，再把密文拼接起来，中间用“%%%”分隔。而且学号和密码的加密方法是同一种方法，加密函数也一起找到了，就叫做“encodeInp”。 在开发人员工具里按下Ctrl+Shift+F,打开全局搜索，找一找这个叫做“encodeInp”的函数。很轻松地找到了线索。 这一整个js文件里，就放了这一段代码。虽然这段代码里没有出现任何“encodeInp”字样，但是凭借我的直觉，并且我相信chrome不出错，这一段就是我要找的代码。 1234567891011121314151617181920212223eval(function(p, a, c, k, e, d) { e = function(c) { return (c &lt; a ? &quot;&quot; : e(parseInt(c / a))) + ((c = c % a) &gt; 35 ? String.fromCharCode(c + 29) : c.toString(36)) } ; if (!''.replace(/^/, String)) { while (c--) d[e(c)] = k[c] || e(c); k = [function(e) { return d[e] } ]; e = function() { return '\\\\w+' } ; c = 1; } ;while (c--) if (k[c]) p = p.replace(new RegExp('\\\\b' + e(c) + '\\\\b','g'), k[c]); return p;}('b 9=&quot;o+/=&quot;;p q(a){b e=&quot;&quot;;b 8,5,7=&quot;&quot;;b f,g,c,1=&quot;&quot;;b i=0;m{8=a.h(i++);5=a.h(i++);7=a.h(i++);f=8&gt;&gt;2;g=((8&amp;3)&lt;&lt;4)|(5&gt;&gt;4);c=((5&amp;s)&lt;&lt;2)|(7&gt;&gt;6);1=7&amp;t;k(j(5)){c=1=l}v k(j(7)){1=l}e=e+9.d(f)+9.d(g)+9.d(c)+9.d(1);8=5=7=&quot;&quot;;f=g=c=1=&quot;&quot;}u(i&lt;a.n);r e}', 32, 32, '|enc4||||chr2||chr3|chr1|keyStr|input|var|enc3|charAt|output|enc1|enc2|charCodeAt||isNaN|if|64|do|length|ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789|function|encodeInp|return|15|63|while|else'.split('|'), 0, {})) 这段代码里用到了eval函数，大胆猜测这个“eval”所执行的代码会生成一个名为“encodeInp”的函数。不然教务系统的js代码不可能成功调用encodeInp这个函数。进一步观察，不难看出这段代码就是一个匿名函数的调用，而且把函数的定义和函数的调用写在了一起。给匿名函数取个名字，分离出函数的定义和函数的调用这两个部分。 匿名函数：1234567891011121314151617181920212223function test(p, a, c, k, e, d) { e = function(c) { return (c &lt; a ? &quot;&quot; : e(parseInt(c / a))) + ((c = c % a) &gt; 35 ? String.fromCharCode(c + 29) : c.toString(36)) } ; if (!''.replace(/^/, String)) { while (c--) d[e(c)] = k[c] || e(c); k = [function(e) { return d[e] } ]; e = function() { return '\\\\w+' } ; c = 1; } ;while (c--) if (k[c]) p = p.replace(new RegExp('\\\\b' + e(c) + '\\\\b','g'), k[c]); return p;} 函数的调用：1test('b 9=&quot;o+/=&quot;;p q(a){b e=&quot;&quot;;b 8,5,7=&quot;&quot;;b f,g,c,1=&quot;&quot;;b i=0;m{8=a.h(i++);5=a.h(i++);7=a.h(i++);f=8&gt;&gt;2;g=((8&amp;3)&lt;&lt;4)|(5&gt;&gt;4);c=((5&amp;s)&lt;&lt;2)|(7&gt;&gt;6);1=7&amp;t;k(j(5)){c=1=l}v k(j(7)){1=l}e=e+9.d(f)+9.d(g)+9.d(c)+9.d(1);8=5=7=&quot;&quot;;f=g=c=1=&quot;&quot;}u(i&lt;a.n);r e}', 32, 32, '|enc4||||chr2||chr3|chr1|keyStr|input|var|enc3|charAt|output|enc1|enc2|charCodeAt||isNaN|if|64|do|length|ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789|function|encodeInp|return|15|63|while|else'.split('|'), 0, {}) 扔到开发人员工具里执行，果然吐出来个encodeInp。 1234567891011121314151617var keyStr = &quot;ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=&quot;;function encodeInp(input) { var output = &quot;&quot;; var chr1, chr2, chr3 = &quot;&quot;; var enc1, enc2, enc3, enc4 = &quot;&quot;; var i = 0; do { chr1 = input.charCodeAt(i++); chr2 = input.charCodeAt(i++); chr3 = input.charCodeAt(i++); enc1 = chr1 &gt;&gt; 2; enc2 = ((chr1 &amp; 3) &lt;&lt; 4) | (chr2 &gt;&gt; 4); enc3 = ((chr2 &amp; 15) &lt;&lt; 2) | (chr3 &gt;&gt; 6); enc4 = chr3 &amp; 63; if (isNaN(chr2)) { enc3 = enc4 = 64 } else if (isNaN(chr3)) { enc4 = 64 } output = output + keyStr.charAt(enc1) + keyStr.charAt(enc2) + keyStr.charAt(enc3) + keyStr.charAt(enc4); chr1 = chr2 = chr3 = &quot;&quot;; enc1 = enc2 = enc3 = enc4 = &quot;&quot; } while (i &lt; input.length); return output;} 那么接下来就有两个选择，一是我的程序嵌入一个JS引擎，执行这段JS代码；二是翻译这段代码，翻译成C++直接用。这段代码才十几行，变量名也不复杂，嵌入一个庞大的JS引擎去执行它简直是杀鸡用牛刀。所以我决定翻译这段JS代码。然而正当我准备翻译，我再仔细观察这段代码……我总感觉有点熟悉……这好像是Base64编码？ 赶紧去验证一下 果然就是Base64编码！ 分析了半天，居然就一个Base64编码！这破系统也太敷衍了。","link":"/2020/01/06/%E5%AD%A6%E6%A0%A1%E6%95%99%E5%8A%A1%E7%B3%BB%E7%BB%9F%E7%99%BB%E5%BD%95%E5%89%8D%E7%AB%AF%E5%8A%A0%E5%AF%86%E5%88%86%E6%9E%90/"},{"title":"对C++左值和右值的理解","text":"对C++左值和右值的理解 左值和右值的定义C++03标准中的左值和右值&emsp;&emsp;左值 (lvalue) 和右值 (rvalue) 中的“左”和“右”其实就是左手右手中的“左”和“右”。因为最初产生这个概念的时候，左值总是出现在赋值符号的左边，右值总是出现在赋值符号的右边。在C++03标准中，左值和右值是这样定义的： 1.Every expression is either an lvalue or an rvalue.2.An lvalue refers to an object or function.……5.The result of calling a function that does not return a reference is an rvalue. User deﬁned operators are functions, and whether such operators expect or yield lvalues is determined by their parameter and return types. &emsp;&emsp;即：对于每一个表达式，它要么是左值要么是右值。左值指向一个对象或函数。函数的返回值如果不是个引用，那么是个右值。用户定义的运算符是函数，此类运算符是期望值还是产生左值取决于其参数和返回类型。 &emsp;&emsp;左值是一个对象，这个对象占据了内存中的空间，并且可以取得地址。而如果一个表达式它不是左值，那么就认为这个表达式是一个右值。 &emsp;&emsp;借助代码也许会更好理解。12345int a;a = (9 + 1);int *pa = &amp;a;(9 + 1) = a; // 这一句代码是错误的，MSVC会提示：“表达式必须是可修改的左值”。int *pb = &amp;(9 + 1); // 这一句代码是错误的，MSVC会提示：“表达式必须为左值或函数指示符”。&emsp;&emsp;上面的代码中，变量a显然是一个左值，它可以出现在赋值符号的左边，也可以取得它的地址。而对于表达式 “(9 + 1)” 来说，它是一个临时的计算结果，它完全可能不存在于内存中（比如存在于某个临时寄存器中），也就是没有一个确定的内存地址，因此这个表达式不是一个左值，而是一个右值。只能给左值赋值，因为对一个不存在的内存赋值，是没有意义的。同样的道理，只能对左值取地址，因为对一个不存在地址的表达式取地址，是没有意义的。 &emsp;&emsp;前面提到在以前左值总是出现在赋值符号的左边，右值总是出现在赋值符号的右边。现在这个说法已经不那么准确，接下来谈谈两种特殊的情况。 &emsp;&emsp;左值未必能放在等号左边。考虑下面这段代码：12const int a = 10; // a是一个左值a = 100; // 错误！a不能放在等号左边！&emsp;&emsp;变量a显然是个左值，但是因为它被 const 修饰，不可被修改，所以变量a不能出现在赋值符号的左边。对于可以修改的左值，一般称为 “可修改左值”。 &emsp;&emsp;等号的左边未必是左值。考虑下面这一段代码： 12345678910111213141516171819202122232425class A{public: A() = default; A&amp; operator=(int) { return *this; }};A func1(){ return A();}int func2(){ return 123;}int main(){ func1() = 5321; // 语句1 可以运行，因为这一句代码相当于 func1().operator=(5321); func2() = 4321; // 语句2 错误，MSVC会提示：“表达式必须是可修改的左值” return 0;} &emsp;&emsp;从定义来看，函数 func1 和 func2 的返回值不是引用，所以是右值。而对一个右值赋值是无意义的，所以“语句 2”是错误的。但是因为 func1 返回的是类型A，这个类型重载了自己的赋值操作符。因此对它的赋值操作实际上等同于执行了成员函数 “operator=”，所以“语句 1”是可以运行的。 C++11标准中的左值和右值&emsp;&emsp;C++11标准中的左值和右值明显复杂了许多。在C++11标准中，表达式可以分为广义左值 (glvalue, generalized lvalue)和右值(rvalue)。广义左值又可分为左值(lvalue)和消亡值(xvalue, eXpiring value)。右值又可分为消亡值(这里没有打错，它既是广义左值也是右值)和纯右值(prvalue, pure rvalue)。下面这幅图直观地说明了它们之间的关系。 &emsp;&emsp;C++11标准中对它们的定义是： 1.An lvalue (so called, historically, because lvalues could appear on the left-hand side of an assignment expression) designates a function or an object.2.An xvalue (an “eXpiring” value) also refers to an object, usually near the end of its lifetime (so that its resources may be moved, for example). An xvalue is the result of certain kinds of expressions involving rvalue references (8.3.2). [Example: The result of calling a function whose return type is an rvalue reference is an xvalue. —end example]3.A glvalue (“generalized” lvalue) is an lvalue or an xvalue.4.An rvalue (so called, historically, because rvalues could appear on the right-hand side of anassignment expression) is an xvalue, a temporary object(12.2) or subobject thereof, or a value that is not associated with an object.5.A prvalue (“pure” rvalue) is an rvalue that is not an xvalue. [Example: The result of calling a function whose return type is not a reference is a prvalue. The value of a literal such as 12, 7.3e5, or true is also a prvalue. —end example] &emsp;&emsp;C++11中左值(lvalue)的定义和C++03中的左值定义差不多。纯右值的定义依然是用“排除法”的方式定义，即：“不是消亡值就是纯右值”，关键在于这个消亡值(xvalue)。 &emsp;&emsp;按照定义的意思，消亡值也指向了一个对象，因为这个对象通常接近它生命周期的末期(也就是即将被销毁)，所以把它叫做消亡值。很好理解为什么消亡值是“广义上的左值”，其实就因为它指向了一个对象。 &emsp;&emsp;纯右值和C++03的右值很相似，比如字面值(如12, 3.14f, true)、函数的返回值(不是引用)都是纯右值。需要注意的是，C++规定字符串(const char*)是左值，而不是右值，虽然字符串也是字面值。(对此我的理解是:字符串是可以取得地址的，因此它至少是个“广义上的左值”) 左值与右值之间的转换&emsp;&emsp;如果某个表达式期待一个右值，但是却给了一个左值，那么这个左值会被转换成右值。考虑下面这一段代码：123int a = 9; // 变量a是一个左值int b = 1; // 变量b是一个左值int c = a + b; // 加法运算需要一个右值，左值b被转换成右值&emsp;&emsp;正如注释中所述，变量a和变量b都是左值，而加法运算需要一个右值，所以变量b会被隐式地转换成右值。&emsp;&emsp;但是这可不意味着可以反过来把右值转换成左值，这就不符合左值的定义了。但右值转换成左值也不总是不成立，考虑下面这一段代码。123int arr[] = {1, 2};int* p = &amp;arr[0];*(p + 1) = 10; // 行得通，(p + 1)是右值，但是*(p + 1)是左值&emsp;&emsp;这一段代码中，(p + 1) 计算的结果是一个临时值，但是操作符 * 可以使 (p + 1) 变为左值，所以 *(p + 1) 可以出现在赋值符号的左侧。&emsp;&emsp;反过来，操作符 &amp; 则可以将左值转换成右值。1234int var = 10;int* bad_addr = &amp;(var + 1); // 错误：&amp; 操作符需要一个左值int* addr = &amp;var; // 可行：var是一个左值&amp;var = 40; // 错误：赋值符号左侧需要一个左值&emsp;&emsp;符号 &amp; 的另一个作用是定义 “左值引用”，下面一段代码定义了一个左值引用。12int a = 123;int&amp; b = a;&emsp;&emsp;在上面这一段代码中，变量a是一个左值，而变量b是a的 “左值引用”。不能给 非常量左值引用 赋予一个右值，因为这会产生从右值到左值的转换。但是 常量左值引用 则可以被赋予右值。1234567string&amp; str1 = string(); // 错误:不能给“非常量左值引用”赋予右值const string&amp; str2 = string(); // 可行：可以给常量左值引用赋予右值void func(const string&amp; str); // 函数func的参数类型是“常量左值引用”string str = &quot;Hello&quot;;func(str); // 可行，可以把左值赋值给“常量左值引用”func(string(&quot;Hi!&quot;)); // 可行，虽然string(&quot;Hi!&quot;)是右值，但是也可以赋值给“常量左值引用”&emsp;&emsp;上面这段代码演示了C++中一个很常见的优化方法，即按引用传参。从左值和右值的角度来看，这样做之所以行得通是因为左值和右值都可以赋值给“常量左值引用”。 CV限定下的左值和右值&emsp;&emsp;CV限定(cv-qualified) 这个术语指的是 const 和 volatile 两个类型限定符。按照C++中的定义，每一个没有被 const 和 volatile 的完成类型、未完成类型和 void 类型都有相应的三个 CV限定 版本的类型。举个例子，int 这个类型有三个 CV限定 版本的类型，分别是 const int、volatile int 和 const volatile int。&emsp;&emsp;在C语言里，只有左值有CV类型限定符而右值不会有。在C++中，类的右值 可以有CV限定，但是内建类型(比如 int)没有。考虑下面这个例子：12345678910111213141516// 这里的代码直接使用了参考文献[3]中的代码class A{public: void foo() const { cout &lt;&lt; &quot;A::foo() const\\n&quot;; } void foo() { cout &lt;&lt; &quot;A::foo()\\n&quot;; }};A bar() { return A(); }const A cbar() { return A(); }int main(){ bar().foo(); // 调用 foo cbar().foo(); // 调用 foo const}&emsp;&emsp;在 main 函数中 对 foo 函数的第二次调用，实际上调用的是 A类 中的 void foo() const方法。因为函数 cbar 返回的是 const A。const A 和 A 不是同一个类型。 右值引用与移动语义&emsp;&emsp;右值引用就是对右值的引用，这个特性在C++11标准中引入。符号 &amp; 可以声明 左值引用，对于右值引用则使用符号 &amp;&amp; 声明。&emsp;&emsp;加入右值引用的特性是为了实现 移动语义(move semantic) 和 精确转发(perfect forwarding)。这一节只简单地谈一下移动语义。(因为我也只是懂得那么点)&emsp;&emsp;要理解 移动语义 这个概念，最好还是结合一个实际的例子。考虑需要实现一个边长数组的类(类似std::vector)。在实现赋值语句操作符的时候，可能会有这种实现：12345678// 这里的代码直接使用了参考文献[3]中的代码Intvec&amp; operator=(const Intvec&amp; other){ Intvec tmp(other); std::swap(m_size, tmp.m_size); std::swap(m_data, tmp.m_data); return *this;}&emsp;&emsp;这个实现对传入的 other 对象做了一个完全的拷贝，也就是创造了个副本 tmp。然后，将自己的成员变量和副本 tmp 交换。在这个函数结束的时候，自己原本的数据随着 tmp 的析构而销毁，并拥有了和 other 对象完全一样的新数据。使用它的代码如下：12345Intvec v1(20);Intvec v2;v2 = v1; // 语句1 : 给v2赋值一个左值v2 = Intvec(30); // 语句2 : 给v2赋值一个右值&emsp;&emsp;对于 语句1 可以认为是确实需要一个和v1一模一样的副本，所以上面的代码完全没有问题。但是对于 语句2，也就是把一个右值赋值给v2，会发生什么？&emsp;&emsp;首先 Intvec(30) 这个表达式会调用 Intvec 类的构造函数，创造一个 Intvec 对象，为了方便说明，可以称他为 临时对象1。&emsp;&emsp;然后，调用 v2.operator=(const Intvec&amp; other)，把 临时对象1 传递进去。(虽然这个函数的参数要求是 常量左值引用 而 临时对象1 是个右值，但是上文已经说明这样做是合法的，这里没有问题。)&emsp;&emsp;之后，这个函数(v2.operator=)对传入的参数 other，做了一个完全的复制，得到 临时对象2 ，也就是副本 tmp。&emsp;&emsp;到这里我想可以停止说明了。这短短一行代码，居然创建了两个临时对象！然而这真的有必要吗？考虑加入下面这个代码：1234567// 这里的代码直接使用了参考文献[3]中的代码Intvec&amp; operator=(Intvec&amp;&amp; other){ log(&quot;move assignment operator&quot;); std::swap(m_size, other.m_size); std::swap(m_data, other.m_data); return *this;}&emsp;&emsp;这里的赋值语句操作符的参数和上一个有所不同。这里的参数类型是一个 右值引用，而上一个是 常量左值引用。区别在于，当编译器检测到参数是右值是，编译器会调用这个参数为 右值引用 版本的赋值语句操作符函数，而不是上一个版本的函数。也就是说，上面用例中的 语句2 将会调用这个新的 Intvec&amp; operator=(Intvec&amp;&amp; other) 函数(语句1没有变化，因为语句1的参数v1是个左值)。&emsp;&emsp;另一个主要区别是，这个版本的函数没有了创造副本 tmp 的过程。这是因为副本 tmp 的使命只有两个：1.将other完全复制一份 2.在析构的时候把旧的数据给销毁。副本 tmp 能够做到第二个使命是因为它是一个临时变量，在函数结束的时候就会被析构，所以它是“濒临死期”。而传入参数的右值也是如此。在语句2(“v2 = Intvec(30);”)执行完后，这个 临时对象1 就会被析构，它也是“濒临死期”。还记得上文讲到的“消亡值”吗，消亡值指的就是即将消亡的值，实际上这里的other参数就是个消亡值。&emsp;&emsp;利用这一点，就没有必要再创造一个副本 tmp 。临时对象1 拥有需要的新数据，同时它又即将消亡，能够代替副本 tmp 完成那两个使命。所以直接和 临时对象1 交换新旧数据就可以了，而不需要一个副本 tmp 作为中介。为了能够修改右值，C++11引入了右值引用。将旧数据移动到右值中，将右值中的数据移动给自己，使用“移动数据”代替“复制数据”，这就称为“移动语义”。(个人理解) 参考文献[1] http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2005/n1905.pdf[2] http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3690.pdf[3] https://eli.thegreenplace.net/2011/12/15/understanding-lvalues-and-rvalues-in-c-and-c[4] https://en.cppreference.com/w/cpp/language/value_category","link":"/2020/01/17/%E5%AF%B9C-%E5%B7%A6%E5%80%BC%E5%92%8C%E5%8F%B3%E5%80%BC%E7%9A%84%E7%90%86%E8%A7%A3/"},{"title":"开源Android QQ协议库mirai使用教程(2020-08版本)","text":"简单的入门教程, 适合无基础小白。因水平有限，本文内容可能会有错误，还请指正。 前言其实之前已经写过一篇类似的mirai使用教程。但是mirai（以及相关作品）经过几个版本的迭代，已经有了较大的变化，旧文章中的许多内容已经不再适用，故有了这篇新的文章。 mirai 项目简介mirai与mirai-console&emsp;&emsp;Mirai 是一个在全平台下运行, 提供 QQ Android 和 TIM PC 协议支持的高效率机器人框架(官方定义)。实际上因为一些原因, TIM PC 协议停止更新了。目前功能最齐全, 运行最稳定的是 QQ Android 协议。(mirai 项目地址: Github ) &emsp;&emsp;Mirai 是由 Kotlin 语言编写的协议库, 提供使用 QQ Android 协议的一些 API。但是 mirai 本身不是一个 “QQ机器人” 程序, 而是一个库。与机器人软件/框架 (例如酷Q) 对应的应该是 mirai 官方的衍生项目 mirai-console。(mirai-console 项目地址: Github ) 图 1 mirai-console 运行时截图(测试版) &emsp;&emsp;mirai-console 提供了插件系统, 支持安装 由 Java/Kotlin 编写的 mirai-console 插件。如果安装了 mirai-native 插件, 还可以支持酷Q的插件。由于酷Q插件相关的机制没有开放，因此无法直接加载cpk类型的插件, 需要将酷Q的插件重新编译为 dll 才能给 mirai-native 使用。( mirai-native 项目地址: Github )。安装 mirai-api-http 插件, 则可以使用基于 mirai-api-http 开发的插件。( mirai-api-http 项目地址: Github ) 开始使用 mirai-console使用前的注意事项下面是使用之前必须阅读的声明(源自mirai的README.md)： 一切开发旨在学习，请勿用于非法用途 mirai 是完全免费且开放源代码的软件，仅供学习和娱乐用途使用 mirai 不会通过任何方式强制收取费用，或对使用者提出物质条件 mirai 由整个开源社区维护，并不是属于某个个体的作品，所有贡献者都享有其作品的著作权。 Mirai 在各个平台均没有任何所谓官方交流群或论坛, 请不要轻信任何所谓学习, 交流群, 不造谣不传谣不信谣从我做起 如果你是开发者，你还需要了解 mirai 的开源协议。mirai 采用 AGPLv3协议开源。按照这个协议，任何与 mirai 有直接或间接关系的程序，都应该采用相同的协议开源。比如，开发基于 mirai-console 的插件会直接引用 mirai 相关的库，因此这个插件需要采用 AGPLv3 协议开源。此外，开发基于 mirai-api-http 的插件会间接使用到 mirai，因此这个插件也需要采用 AGPLv3 协议开源。 在 windows 上使用 mirai-console准备运行环境&emsp;&emsp;运行 mirai-console 需要安装 Java 运行环境。安装 jre1.8 (或 jdk8) 以及更高版本都可以。(jre1.8 安装包下载地址: baidu ; jdk8安装包下载地址: baidu ) 图 2 安装 Java 运行环境(jre)截图 &emsp;&emsp;安装完成后, 重启计算机。打开 Powershell, 输入 java -version 或者 java --version 然后回车, 查看是否正确安装 Java。正确安装 Java 并执行上面的指令后, 其结果应该如 图 3 所示。 打开 Powershell 的方法: 同时按下键盘上的 Win 按键 (印着 windows 图标的按键) 和 字母 R 按键, 这会启动 “运行” 程序。输入 powershell 然后点击确定, 就可以打开 Powershell。 图 3 执行 java -version 截图 下载 mirai-consolemirai-console 包含两个部分：前端和后端。后端是 mirai-console 的核心部分，包含插件系统、指令系统、配置系统等。前端则是和后端进行交互的部分。比如在控制台中进行交互，可以使用 Pure 前端；需要图形界面的交互可以使用 Graphical 前端；Unix 终端界面可以使用 Terminal 前端。 mirai-console 前端和后端可以在 mirai-repo 中下载。 mirai-console 的后端位于 mirai-console 文件夹内。mirai-console 的 Pure 前端位于 mirai-console-pure 文件夹下。(图 4) 下载 mirai-core-qqandroidmirai-core-qqandroid 位于 mirai-repo 的 mirai-core-qqandroid 文件夹下，它是 mirai 的核心组件，mirai-console 需要它才能正常工作。(图 4) 图 4 mirai-repo 的内容 运行 mirai-console将 mirai-console 的前端、后端以及 mirai-core-qqandroid 共三个文件放在同一个目录下。在资源管理器的地址栏中输入 powershell.exe 然后回车, 这会在当前目录启动 Powershell。(如 图 5) 图 5 准备执行 mirai-console &emsp;&emsp;启动 Powershell 后, 输入以下指令并回车启动 mirai-console。(图 6) 1java -cp ./* net.mamoe.mirai.console.pure.MiraiConsolePureLoader 图 6 mirai-console 运行时截图 在 Linux 上使用 mirai-console以下内容在 WSL 中进行，以 Debian 10 为例。 准备运行环境执行以下命令安装个 openjdk 就好了： 12sudo apt-get updatesudo apt-get install default-jdk 下载 mirai-console 与 mirai-core可以用 curl 或者 wget，也可以在windows系统下载好之后用 scp 指令传输到 Linux。 运行 mirai-console执行以下指令启动 mirai-console。 1java -cp ./* net.mamoe.mirai.console.pure.MiraiConsolePureLoader 如果出现 Error: Could not find or load main class 的错误，尝试以下解决方法： 首先找到 /usr/lib/jvm/java-XXX-openjdk-amd64/ 目录的路径 可以执行以下指令寻找： 1whereis jvm 如图所示，在我的 Linux 上，该目录的路径是 /usr/lib/jvm/java-11-openjdk-amd64/ 然后，根据你自己的情况，修改并执行以下指令，启动mirai。 1java -cp /usr/lib/jvm/java-11-openjdk-amd64/lib:./* net.mamoe.mirai.console.pure.MiraiConsolePureLoader 让 mirai 在服务器中持续运行断开 ssh 链接时，会把在会话期间运行的程序一起结束掉。要让 mirai-console 和其他插件在服务器中持续运行，推荐使用 screen 程序。 下面以启动 mirai-console 为例简单介绍 screen 的用法。 执行以下指令安装 screen： 1sudo apt-get install screen 创建一个屏幕（SCREEN_NAME是屏幕的名称，可以改成合适的名字）： 1screen -S SCREEN_NAME 然后在新创建的屏幕启动 mirai-console。 要断开屏幕连接，先按下组合键 Ctrl+A 再按下字母 D。 之后再关闭终端，就不会把 mirai-console 结束掉了。 要重新连接之前的屏幕，执行以下指令： 1screen -r SCREEN_NAME 如果忘记了有哪些屏幕，可以执行以下指令列出所有屏幕： 1screen -ls 插件推荐：mirai-native 与 mirai-api-httpmirai-native 插件提供了和酷Q类似的插件API，如果有dll版本的酷Q插件，可以直接使用（cpk文件不行），该插件只能用于 windows，java x86 环境。 mirai-api-http 插件提供了一系列HTTP API，其他语言可以很方便地使用HTTP API使用mirai。现在已经有很多基于HTTP API的SDK，因此即使不擅长 kotlin/java 语言也可以开发 mirai 机器人。 // 未完待续…","link":"/2020/08/25/%E5%BC%80%E6%BA%90Android-QQ%E5%8D%8F%E8%AE%AE%E5%BA%93mirai%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B-2020-08%E7%89%88%E6%9C%AC/"},{"title":"开源安卓QQ协议库 mirai 使用教程","text":"简单的入门教程, 适合无基础小白。因水平有限，本文内容可能会有错误，还请指正。 mirai 项目简介&emsp;&emsp;Mirai 是一个在全平台下运行, 提供 QQ Android 和 TIM PC 协议支持的高效率机器人框架(官方定义)。实际上因为一些原因, TIM PC 协议停止更新了。目前功能最齐全, 运行最稳定的是 QQ Android 协议。(mirai 项目地址: Github ) &emsp;&emsp;mirai 是由 Kotlin 编写的协议库, 提供使用 QQ Android 协议的一些 API。但是 mirai 本身不是一个 “QQ机器人” 程序, 而是一个库。与机器人软件 酷Q 对标的应该是 mirai 官方的衍生项目 mirai-console。(mirai-console 项目地址: Github ) 图 1 mirai-console 运行时截图 &emsp;&emsp;mirai-console 提供了插件系统, 支持安装 由 Java/Kotlin 编写的 mirai-console 插件。如果安装 mirai-native 插件, 那还可以支持 酷Q 的插件, 但是目前为止机制还不够完善, 需要将 酷Q 的插件重新编译为 dll 才能给 mirai-native 使用。( mirai-native 项目地址: Github )。安装 mirai-http-api 插件, 则可以提供 HTTP API 来使用 mirai, 方便其他语言使用 mirai。( mirai-http-api 项目地址: Github ) 在 windows 上使用 mirai-console准备运行环境&emsp;&emsp;运行 mirai-console 需要安装 Java 运行环境。安装 jre1.8 (或 jdk8) 以及更高版本都可以。(jre1.8 安装包下载地址: baidu ; jdk8安装包下载地址: baidu ) 图 2 安装 Java 运行环境(jre)截图 &emsp;&emsp;安装完成后, 重启计算机。打开 Powershell, 输入 java -version 或者 java --version 然后回车, 查看是否正确安装 Java。正确安装 Java 并执行上面的指令后, 其结果应该如 图 3 所示。 打开 Powershell 的方法: 同时按下键盘上的 Win 按键 (印着 windows 图标的按键) 和 字母 R 按键, 这会启动 “运行” 程序。输入 powershell 然后点击确定, 就可以打开 Powershell。 图 3 执行 java -version 截图 下载 mirai-console-wrapper&emsp;&emsp;前面介绍了 mirai-console 才是真正的 “QQ 机器人程序”。但是为了方便使用 mirai-console 总共有 6 个版本, 各个版本的说明可以见 表 1。 表 1 mirai-console 各个版本的介绍 名称 介绍 Mirai-Console-Pure 最纯净版, CLI环境, 通过标准输入与标准输出 交互 Mirai-Console-Terminal (UNIX)Terminal环境 提供简洁的富文本控制台 Mirai-Console-Android 安卓APP (TODO) Mirai-Console-Graphical JavaFX的图形化界面 (.jar/.exe/.dmg) Mirai-Console-WebPanel Web Panel操作(TODO) Mirai-Console-Ios IOS APP (TODO) &emsp;&emsp;根据不同的运行环境和需求, 选择对应的版本。因为本篇文章涉及到将 mirai-console 部署到 Linux, 这里以 Pure 版本为例进行讲解。 &emsp;&emsp;要使用 mirai-console-pure , 需要下载 mirai-console-wrapper 。mirai-console-wrapper 提供了安装、更新各个版本 mirai-console 的功能。 mirai-console-wrapper 的下载地址: https://github.com/mamoe/mirai-console/releases &emsp;&emsp;找到 wrapper 开头的标题, 下载最新版本的 mirai-console-wrapper.jar 文件。(如 图 4 ) 图 4 mirai-console-wrapper 的下载地址 &emsp;&emsp;将下载好的 mirai-console-wrapper 移动到合适的位置。在地址栏中输入 powershell 并回车, 这会在当前目录启动 Powershell。(如 图 5) 图 5 准备执行 mirai-console-wrapper &emsp;&emsp;启动 Powershell 后, 输入 java -jar .\\mirai-console-wrapper-0.3.0.jar 并回车启动 mirai-console-wrapper。 &emsp;&emsp;启动 mirai-console-wrapper 后, 它会让你选择安装哪个 mirai-console 版本, 本文要安装 Pure 版本, 所以这里输入了 Pure。你可以按照你的需求来选择版本。 &emsp;&emsp;输入 Pure 并回车, mirai-console-wrapper 会自动从服务器下载最新版的 mirai-console 和 mirai 库 (保存在 content 文件夹里)。并会自动创建 plugins 文件夹, 这个文件夹用于存放插件和插件的配置文件。 图 6 正在下载 mirai-console-pure &emsp;&emsp;等待下载完成后, 会显示如图 7的结果, 这就说明成功的启动了 mirai-console-pure。 图 7 正在下载 mirai-console-pure &emsp;&emsp;直接输入 /login 你的机器人的qq号码 你的机器人的qq密码 然后回车确认, 就能登录QQ机器人了。 安装插件自动安装插件&emsp;&emsp;输入 /help 可以查看 mirai-console-pure 的指令。这个指令列表是会变化的, 比如有的插件会提供一些指令。 123456789-&gt; manager :Add a manager-&gt; login :机器人登录-&gt; status :获取状态-&gt; say :聊天功能演示-&gt; plugins :获取插件列表-&gt; command :获取指令列表-&gt; about :About Mirai-Console-&gt; reload :重新加载全部插件-&gt; install :Install plugin from PluginCenter &emsp;&emsp;输入 /install 可以查看插件列表。 12345678=&gt;BiliBiliLinker ;作者: Karlatemp ;介绍: 解析BiliBili视频信息=&gt;DrawLots ;作者: Sincky ;介绍: 群抽签解签插件, 抽取当天玄学的运势, 遇事不决, 量子力学=&gt;History ;作者: Logiase ;介绍: 记录本地聊天记录=&gt;HsoPro ;作者: unknown ;介绍: 支持群内看高清涩图, 允许配置每个群允许,不允许看普通/r18的图=&gt;KeywordReply ;作者: Anders ;介绍: 群内关键字回复, 可选择精准问答或模糊问答, 分群配置=&gt;PingMyMcServer ;作者: NaturalHG ;介绍: 在QQ中ping MCPE服务器=&gt;Rcon ;作者: Angel、 ;介绍: 对服务器发送命令, 可在QQ群内或私聊执行服务器命令。=&gt;Runcode ;作者: Simper16 ;介绍: 在线运行代码 &emsp;&emsp;输入 /install 插件名称 如: /install Rcon 就可以安装插件。 123[INFO] [Command] 正在连接崔云[INFO] [Command] 正在安装Rcon[INFO] [Command] 安装Rcon成功 手动安装插件&emsp;&emsp;有几个很重要的插件没有出现在列表里, 接下来介绍手动安装插件。 &emsp;&emsp;mirai-http-api 插件会在本地运行一个Web服务器, 从而提供 HTTP API。这允许其他程序通过 HTTP API 来使用 mirai。安装了它, 就可以运行各种编程语言编写的插件。(按理说这类插件会很多, 但是目前来说这类插件比较少, 因为各个大佬都自己玩, 少有发布插件的) mirai-http-api 插件下载地址: https://github.com/mamoe/mirai-api-http/releases &emsp;&emsp;mirai-console-addition 插件增强了 mirai-console 的功能, 它提供了 MD5密码登录 以及 MD5密码自动登录 等功能。 mirai-console-addition 插件下载地址: https://github.com/ryoii/mirai-console-addition/releases &emsp;&emsp;以 mirai-console-addition 为例, 下载最新版的 mirai-console-addition-V0.2.3.jar , 将它复制到 plugins 目录下。 &emsp;&emsp;重新启动 mirai-console-wrapper, 该插件即可生效。 &emsp;&emsp;此时再次输入 /help, 可以发现比原来多出了几个指令: 123456789101112-&gt; manager :Add a manager-&gt; login :机器人登录-&gt; status :获取状态-&gt; say :聊天功能演示-&gt; plugins :获取插件列表-&gt; command :获取指令列表-&gt; about :About Mirai-Console-&gt; reload :重新加载全部插件-&gt; install :Install plugin from PluginCenter-&gt; login-md5 :[console addition]使用md5作为密码登录-&gt; auto-login :[console addition]自动保存本次登录的qq号和密码md5值, 下次启动时自动登录-&gt; rcon :rcon插件命令 &emsp;&emsp;多出的 login-md5 和 auto-login 指令由 mirai-console-addition 插件提供。 将 mirai 机器人部署到 Linux 服务器未完待续… 准备运行环境开始使用进阶使用","link":"/2020/04/18/%E5%BC%80%E6%BA%90%E5%AE%89%E5%8D%93QQ%E5%8D%8F%E8%AE%AE%E5%BA%93-mirai-%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/"},{"title":"快速入门LS-DYNA:基本概念","text":"本科毕业论文要用 LS-DYNA 进行有限元仿真，有一些基本概念发现很多资料、书籍都没说清楚，结合自己的理解浅谈一下。 LS-PrePost和LS-DYNA有限元分析的基本工作流程总体分为三步：前处理、数值计算、后处理。 LS-DYNA 这个程序就是做第二步的数值计算工作，它读取 .k 文件，并生成一系列计算结果文件。所以要完成一次有限元分析，实际上学的并不是 LS-DYNA 这个程序如何使用，更多的还是在学如何进行前处理和后处理。关于 LS-DYNA，其实学的是其进行有限元分析的理论，而不是程序使用的方法。 我得强调这一点，因为我刚开始查资料的时候，搜索关键词都是 “LS-DYNA 如何如何…”。但实际上我的疑问都是关于前处理方面的，以 LS-DYNA 为关键词导致我什么资料都没搜出来。 在数值计算之前，需要建立有限元模型，这属于第一步的前处理的工作。 进行前处理工作的软件有很多，比如 Ansys、LS-PrePost 等。其中 LS-PrePost 是最合适的，因为它是专门为 LS-DYNA 设计的前处理软件（LS-PrePost 也有后处理功能，所以它叫“Pre + Post”）。 虽然 LS-DYNA 是收费的商用有限元软件，但是 LS-PrePost 却是免费的，最好使用最新版。 有限元分析的前处理在有限元分析中，前处理的工作量可能是最大的。我本科毕业论文研究的是碰撞问题，那么这种碰撞问题的前处理工作通常包括：绘制几何模型、建立有限元模型、选择材料参数、设置接触条件和计算终止条件等。 LS-PrePost 有几何模型的绘制功能，但是我觉得不太好用，我更习惯用 AutoCAD 和 Solidworks 绘制几何模型。LS-PrePost 支持导入 .IGES、.ST(E)P、.STL 格式的几何模型文件，所以在绘制几何模型上可以选用别的软件进行，再通过这些文件将几何模型导入到 LS-PrePost 继续前处理的工作。 LS-PrePost 导入几何模型之后，就可以进行其他的工作，比如简化模型、网格划分等等。 对于网格划分，也可以使用更强大的 HyperMesh，这需要多花一点时间去学习。我做毕业论文的时候只剩下两个月不到了，就没时间学这玩意。 理解.k文件和LS-DYNA的基本关键词前处理工作的最终结果是得到一个（或若干个） .k(.key) 文件，k 指的是 keyword，因为 LS-DYNA 的有限元模型是由一个个关键词描述的。.k 文件是纯文本文件，可以用文本编辑器查看、修改。 .k 文件里是不包含几何模型的，所以如果觉得网格划分不满意，那么只能重新导入原来的几何模型文件（比如 .IGES 文件），重新进行网格划分工作。 要理解 LS-DYNA 中关于 *Part、*Element_{option}、Section_{option} 等关键词的区别和联系，需要先了解 .k 文件是如何描述有限元模型的：.k文件的本质就是个关系型数据库。 *Part 关键词描述一个实体，该实体有相同的材料（由 *MAT_{} 系列关键词设置）、相同的单元类型（Shell、Solid等）和单元属性（由 *Section_{} 系列关键词设置），组成该实体的各个单元使用 *Element_{} 系列关键词描述。 *Part 就是个关系表，将多个 Element 组装成一个 Part，同时赋予材料属性（MAT）、单元类型和单元属性（Section） *Node 关键词描述空间直角坐标系（LS-DYNA 只有三维直角坐标系）中的各个节点。 *Element_{Option} 关键词一个 Elment 描述一个单元的类型和组成该单元的各个节点。Part 和 Element 属于一对多关系，一个 Part 可以由多个 Element 来描述，组合成形状复杂的实体。 对于 Element_Shell，每个单元需要 4 个节点来描述（四个节点中可能有两个点是相同的，表明这是一个三角形单元）。对于 Element_Solid，每个单元需要 8 个节点描述。 *Section_{Option} 关键词一个Section用于对某种单元类型设置相应的属性，比如 Shell 类型单元可以设置厚度属性。同一种单元类型可以创建多个Section，也就是说可以创建多个 Section_Shell 然后分别设置不同的厚度。 *Segment 关键词一个单元某个方向上的面。对于 Solid 类型单元，可能是六面体，因此该单元有 6 个 Segment。若干单元在某个方向上的Segment 可以组成一个集合，用 *SET_Segment 关键词描述。 总结突然发现本文的标题具有误导性，这篇文章并不能带你入门，但是它的内容又刚好是入门者需要的。我学习 LS-DYNA 的资料主要是《LS-DYNA3D理论基础与实例分析》、《LS-DYNA动力学分析指南》和 dynasupport.com 网站的资料。这两本书对这些常见关键词的描述真的太模糊了，光靠直觉根本理解不了。后来我才发现其实 .k 文件的本质就是个关系型数据库，用关系表、实体表的角度去看这些关键词，豁然开朗，就很清晰通透。于是我写了这篇博文，或许刚好就能帮到你。","link":"/2022/05/20/%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8LS-DYNA-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"},{"title":"我的 2022 总结","text":"不知道从哪里开始总结，好像也没什么可以总结的。 上半年忙于毕设，几乎每天都投入其中，最后顺利毕业！ 然后是暑假，因为疫情也没去哪里玩。看了几本书想把 C++20 Coroutine 研究明白，拖拖拉拉也没什么进展。写了几篇博文，因为懒又没写完，现在还只剩个框架在那里。 暑假之后就是研究生开学了，研一课程多，每天不是在上课就是在写作业。不过这学期学的《最优化理论》和《矩阵分析与数值计算》这两门课程挺有用的，感觉可以写一篇文章分享下我的上机作业代码。 看了下我 2022 年的 GitHub 的记录，commit 数量比 2021 年少得多。这不是我在偷懒，确实是没什么代码可写的。我不想总是去写那些我会的东西，增删改查、适配个 SDK 或者逆向分析 APP 写爬虫什么的，写多了有些枯燥了。 今年其实学了不少新东西的，只是新东西太多太难了，不是三两天能学会，然后马上就能写出什么好作品。 到了明年，2023 年，应该就不一样了。我还会花很多时间去写代码，不过写的东西肯定都和以前不一样了。 我会继续我 2022 年没完成的想法。比如继续了解 C++20 Coroutine，或许可以试着写一个协程库；了解一下并行编程，比如 OpenMP 或者 CUDA，或许我可以把一些线性代数的算法改写成并行的实现。然后是新东西，比如说这学期学了有限元分析，我觉得我可以写一个玩具有限元求解器（已经在做了）；再了解下机器学习方面的东西，没时间就算了。 关于 2023 年的展望。 下学期不封校，把学校附近的美食都吃一遍。 拍很多好看的照片。 找到我喜欢做的事情，投入其中。","link":"/2022/12/31/%E6%88%91%E7%9A%84-2022-%E6%80%BB%E7%BB%93/"},{"title":"折腾IPv6的一天","text":"不想学习的一天。看无聊新闻的时候得知现在IPv6已经比较成熟（个屁），家庭宽带基本上都能启用IPv6。所以就有了折腾IPv6的想法。家庭宽带虽然可以启用IPv6服务，但是默认是不启用的（不知道什么原因，据说是装宽带的师傅省事？）。所以要进入IPv6的世界，要自己动手配置光猫的设置。 我家是电信的宽带，光猫是中兴生产的。百度查了它的超级管理员账号密码是：12telecomadminnE7jA%5m一试就直接登录进去了，这一步我进行的非常顺利。 启用IPv6的步骤网上能找到，说实话这方面的资料不是很多，有的都是比较久远的贴子在讨论。 进入光猫的超级管理员界面后，先看上网功能的连接名称。 然后找到如图所示的界面，设置对应连接名称的网络连接参数。 把IP模式从IPv4改为IPv4&amp;IPv6，这样光猫就同时支持IPv4和IPv6了。 然后是IPv6方面的设置，其中获取前缀要勾上。其他的地址获取方式、前缀获取方式、DNS获取方式，我也不清楚该怎么填。我找到的教程的设置方式在我的光猫里没有对应的设置，所以我就全部弄成AutoConfigured了。 搞完这些设置，点保存，然后重启光猫。再次连上网络后，我的电脑获取到了IPv6的地址，而且确定了不是局域网的IPv6地址。 然后我就找了个IPv6的测试网址，一系列检测之后说我无法访问IPv6。 这时候我是有点迷惑的，明明都获取到IPv6地址了，怎么会访问不了呢？我以为是光猫没设置对，所以又去查了一些资料。 后来才发现，其实光猫设置的没错。真正原因是我的代理软件的IPv6设置没开。打开之后就可以了。 然后我又想起路由器也有个IPv6的开关，一起开启了。 至此，我成功通过了测试网站的检测。 然后我就买了个IPv6 Only的vps，想要试一下是不是真的能连上。（其实我是想找现成的IPv6的网站来测试的，但是国内的纯IPv6网站我没找到，要么就是找到了几年前的信息，已经访问不了了。而国外的IPv6网站又访问不上，被墙了） ssh毫不意外的连上了。 又装了个Nginx，解析到ipv6.uint128.com。看到了熟悉的 Welcome to nginx!。 而且我套了一层cloudflare CDN后，发现没有IPv6的设备也是可以访问的。 这个发现还挺惊喜的，这意味着IPv6 Only的服务器也是可以做Web服务器的。 我又把服务器解析到ipv6test.uint128.com，这个地址没有经过CDN，所以可以用来测试IPv6。如果你也能看到Welcome to nginx!，那么你的网络可以访问纯IPv6网站！ 因为ssh直接连接国外的服务器实在是太卡了，操作起来很不舒服，所以我又打算装一个mosh(mobile shell)。因为mosh是基于UDP的，而且考虑了网络不佳的情况，所以会比ssh流畅一点。 这期间遇到了两个奇葩问题。 第一个是这个 mosh 没有 windows 客户端，所以我只能在 wsl 上用 mosh 连接，但是却出现了无法连接的情况。 因为 mosh 一开始是用 ssh 进行验证，然后才用 udp 进行通信。我就试了下在 wsl 中用 ssh 连接服务器。（之前都用的powershell的ssh客户端） 结果连接不上，提示：1ssh: connect to host 2001:***:f888 port 22: Network is unreachable 很奇怪吧，我以为是系统问题，又用 ssh 连接了一台 IPv4 服务器，这 IPv4 可以很顺利的连上。 所以问题就是 wsl2 无法通过 ssh + IPv6 连接服务器。我猜到是 wsl2 的问题，但是我不知道怎么解决了。 我又装了个 wsl1 的系统。这次可以用 ssh + IPv6 连接服务器了。 第二个奇葩问题出现了，因为 mosh 还是无法工作。 防火墙是允许 mosh 的端口通信的，但是我试了很多次，mosh 都无法工作。","link":"/2021/08/21/%E6%8A%98%E8%85%BEIPV6%E7%9A%84%E4%B8%80%E5%A4%A9/"},{"title":"数值积分辛普森法的推导以及MATLAB实现","text":"数值积分在船体计算中很常用。以前只会用, 花点时间搞明白它近似计算的原理。(我没有完全搞懂, 本文可能有错误) 我个人理解的数值积分, 就是把原函数 \\( f(x) \\) 在 \\( f(0) \\) 处用麦克劳林级数展开, 用多项式来拟合原函数。多项式的次数为\\( 1 \\) 时, 就是梯形法; 为 \\( 2 \\) 时就是辛普森一法; 为 \\( 3 \\) 时就是辛普森二法。 多项式的次数越高, 拟合精度越高。 数值积分的一般形式对于函数 \\( f(x) \\) 在区间 \\( [a,b] \\) 上的积分有 A = \\int_0^L f(x) dx = \\int_0^L y dx \\tag{1} \\label{1}假定用 \\( n \\) 次多项式曲线对 \\( f(x) \\) 进行拟合。将该多项式曲线在 \\( f(0) \\) 处用麦克劳林级数展开, 则得 f(x) \\approx \\sum_{i = 0}^{n} \\frac{1}{i!} f^{(i)}(0) x^i \\tag{2} \\label{2}将式 \\( \\eqref{2} \\) 代入式 \\( \\eqref{1} \\) 可得 \\begin{aligned} A &= \\int_0^L f(x) dx \\\\\\\\ &\\approx \\frac{1}{0!} f(0) \\int_0^L dx + \\frac{1}{1!} f^{'}(0) \\int_0^L x dx + \\cdots + \\frac{1}{n!} f^{(n)}(0) \\int_0^Lx^ndx \\\\\\\\ &= \\sum_{i = 0}^{n} \\frac{L^{i+1} }{(i+1)!}f^{(i)}(0) \\end{aligned} \\tag{3} \\label{3}令面积 \\( A \\) 为 A = \\sum_{i = 0}^{n} k_iy_i \\tag{4} \\label{4}上式中的 \\( y_i \\) 可由式 \\( \\eqref{2} \\) 得到 \\begin{aligned} y_0 &= f(0) \\\\\\\\ y_1 &= f(0) + f^{'}(0)x_1 + \\cdots + \\frac{1}{n!} f^{(n)}(0)x_1^n \\\\\\\\ & \\cdots \\cdots \\\\\\\\ y_n &= f(0) + f^{'}(0)x_n + \\cdots + \\frac{1}{n!} f^{(n)}(0)x_n^n \\end{aligned} \\tag{5} \\label{5}将式 \\( \\eqref{5} \\) 代入式 \\( \\eqref{4} \\), 得 (注意:如果看不出来, 可以先在式 \\( \\eqref{5} \\) 左右同时乘以\\( k_i \\) 然后再把 \\( f^{(i)}(0) \\) 提出来 ) A = (k_0 + k_1 + \\cdots + k_n)f(0) + \\\\\\\\ \\frac{1}{1!} (k_1x_1 + k_2x_2 + \\cdots + k_nx_n) f^{'}(0) + \\\\\\\\ \\cdots + \\\\\\\\ \\frac{1}{n!} (k_1x_1^n + k_2x_2^n + \\cdots + k_nx_n^n) f^{(n)}(0) \\tag{6} \\label{6}将式 \\( \\eqref{6} \\) 与式 \\( \\eqref{3} \\) 相比较, 可以得到 k_0 + k_1 + \\cdots + k_n = L \\\\\\\\ k_1x_1 + k_2x_2 + \\cdots + k_nx_n = \\frac{L^2}{2} \\\\\\\\ \\cdots \\\\\\\\ k_1x_1^n + k_2x_2^n + \\cdots + k_nx_n^n = \\frac{L^{n+1}}{n+1} \\\\\\\\ \\tag{7} \\label{7}至此得到了数值积分的一般形式。通过式 \\( \\eqref{7} \\) 解得 \\( k \\) 的值, 再通过式 \\( \\eqref{4} \\) 就可以求得面积 \\( A \\) , 即数值积分。 梯形法取 \\( n = 1 \\) , 以直线段近似地代替 \\( y = f(x) \\) 的曲线, 坐标值只有 \\( y_0 \\) 和 \\( y_1 \\) , 区间长度 \\( L = x_1 - x_0 \\) , 且 \\( x_1 = L \\)。 由式 \\( \\eqref{7} \\) , 可得 \\left\\{ \\begin{array}{l} k_0 + k_1 = L \\\\\\\\ k_1x_1 = \\frac{L^2}{2} \\end{array} \\right.解得 \\left\\{ \\begin{array}{l} k_0 = \\frac{L}{2} \\\\\\\\ k_1 = \\frac{L}{2} \\end{array} \\right.代入式 \\( \\eqref{4} \\) , 可得 A = \\frac{L}{2} (y_0 + y_1)辛普森一法步骤和梯形法一样。取 \\( n = 2 \\) , 以二次抛物线近似地代替 \\( y = f(x) \\) 的曲线, 坐标值有 \\( y_0 \\) 、 \\( y_1 \\) 和 \\( y_2 \\) , 区间长度 \\( L = x_2 - x_0 \\) , 且 \\( x_1 = L/2 , x_2 = L \\)。 由式 \\( \\eqref{7} \\) , 可得 \\left\\{ \\begin{array}{l} k_0 + k_1 + k_2= L \\\\\\\\ k_1x_1 + k_2x_2 = \\frac{L^2}{2} \\\\\\\\ k_1x_1^2 + k_2x_2^2 = \\frac{L^3}{3} \\end{array} \\right.解得 \\left\\{ \\begin{array}{l} k_0 = \\frac{L}{6} \\\\\\\\ k_1 = \\frac{4L}{6} \\\\\\\\ k_2 = \\frac{L}{6} \\end{array} \\right.代入式 \\( \\eqref{4} \\) , 可得 A = \\frac{L}{6} (y_0 + 4y_1 + y_2)一般使用的时候, 会把积分区间等分为偶数份, 每三个点用一次辛普森一法。 MATLAB 程序实现MATLAB 中的 trapz 函数是梯形法的实现, 但是对于辛普森法没有对应的函数。quad 函数采用自适应辛普森法, 但是好像只能对函数对象进行积分, 而不能对离散的函数值进行积分。所以我自己实现了一个 simpson 函数, 用法和 trapz 函数类似。但是多了个使用限制, 即必须把函数等分成偶数份 (输入的 y_vec 必须有奇数个值), 这个限制是为了方便生成辛普森系数。 使用方法: 1234567891011121314clear;clc;% 辛普森一法res1 = 10 * simpson([1 2 3 4 5].^2);% 梯形法res2 = 10 * trapz([1 2 3 4 5].^2);% 自适应数值积分res3 = 10 * integral(@(x)x.^2 ,1,5);fprintf('辛普森一法结果: %.2f \\n', res1);fprintf('梯形法结果: %.2f \\n', res2);fprintf('自适应数值积分结果: %.2f \\n', res3);% 执行结果: % 辛普森一法结果: 413.33 % 梯形法结果: 420.00 % 自适应数值积分结果: 413.33 simpson 函数的实现: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546function [ result ] = simpson( y_vec , d_num)%SIMPSON 适用于离散数据的辛普森一法% y_vec : 等间距 y 值向量% d_num : 间距大小 (默认为 1)%% 适用条件判断if (nargin == 1) d_num = 1;endif length(y_vec) &lt; 3 error('y_vec 的长度太小了');endif mod(length(y_vec),2) == 0 error('y_vec 的长度必须是奇数');endif d_num &lt;= 0 error('d_num 必须大于0');end%% 常用量% y_vec 的长度Len = length(y_vec);%% 生成系数向量 MM = zeros(1,Len);if d_num == 3 M = [1 4 1];else M(1) = 1; M(2) = 4; for i = 1: (Len - 4) if mod(i,2) == 1 M(2 + i) = 2; else M(2 + i) = 4; end end M(Len - 1) = 4; M(Len) = 1;end%% 计算结果t = y_vec .* M;result = (1/3) * sum(t(:)) * d_num;end","link":"/2020/04/13/%E6%95%B0%E5%80%BC%E7%A7%AF%E5%88%86%E8%BE%9B%E6%99%AE%E6%A3%AE%E6%B3%95%E7%9A%84%E6%8E%A8%E5%AF%BC%E4%BB%A5%E5%8F%8AMATLAB%E5%AE%9E%E7%8E%B0/"},{"title":"牛顿插值法的 Matlab 实现","text":"意外的发现了卷积可以用来求多项式相乘的系数。 特点在学插值之前就已经在 Matlab 上用过多项式插值了，也就是 polyfit 和 polyval。所以在实现牛顿插值的时候，我就希望我的实现在用法上要和 polyfit 的用法是相似的。 函数 polyfit 的作用是返回多项式的系数，而函数 polyval 是根据多项式的系数，得到一系列点对应的多项式值。那么我的 Interpolation_Newton 也应该返回多项式的系数。 然后我就遇到了问题，我需要把含有商差的多项式转化为标准的多项式，这就需要做多项式乘法，但我不知道如何高效地实现（其实是懒得写这个程序）。查了别人关于牛顿插值的实现代码，发现有不少实现都用到了卷积计算(conv)。最后我在 MathWorks 的文档页面得到了我想要的东西： w = conv(u,v) 返回向量 u 和 v 的卷积。如果 u 和 v 是多项式系数的向量，对其卷积与将这两个多项式相乘等效。 之前也看过一些关于卷积的科普，但好像都没提到卷积还和多项式相乘有关系。 代码最后写出来就是这样：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647%% INIT% 《数值分析方法与应用》张宏伟、孟兆良编著；大连理工大学出版社% 第 217 页：四、插值与逼近 第 5 题clear;clc;format short;%% 初始化参数% 区间range = [0 1];% 函数定义func = @(x) sin(pi .* x);%% 计算与输出% 已知数据xx = range(1):0.1:range(2);yy = func(xx);% 插值数据p = Interpolation_Newton(xx, yy);xx1 = range(1):0.05:range(2);yy1 = polyval(p,xx1);% 原函数x = range(1):0.01:range(2);plot(x,func(x)); hold on;% 插值点图像plot(xx1,yy1,'--o'); hold on;legend('原函数', '插值')%% 函数定义function factors = Interpolation_Newton(x, y) n = length(x); dd = zeros(n,n); % 计算均差 dd(1,:) = y; for k = 1:n-1 for r = 1:n-k dd(k+1, r) = ( dd(k, r+1) - dd(k, r) ) / (x(r+k)-x(r)); end end % 计算各阶多项式系数 p = zeros(n,n); p(1,end) = 1; for k = 2:n % conv (卷积计算): % 对两个多项式系数进行卷积计算可得到多项式相乘的系数 p(k,:) = conv(p(k-1,2:end), [1, -x(k-1)]); end factors = sum(dd(:,1) .* p);end","link":"/2023/01/08/%E7%89%9B%E9%A1%BF%E6%8F%92%E5%80%BC%E6%B3%95%E7%9A%84-Matlab-%E5%AE%9E%E7%8E%B0/"},{"title":"玩一玩泛域名解析","text":"玩一玩泛域名解析 先看看作品的最终效果。访问 http://XXX.我喜欢你.top:521/ 会返回字符串 一直都很喜欢 XXX 呢。其中 “XXX” 可以改为任意字符(中文也可以)。 实现原理其实很简单。首先是泛域名解析。泛域名解析就是把某一级子域名全部解析到同一IP(A记录)。比如将 *.test.uint128.com 解析到 127.0.0.1。这样访问 任意字符.test.uint128.com 都会指向 127.0.0.1。 那么, 服务器怎么知道用户是从哪个域名访问过来的呢？这里利用了 HTTP 协议头部的 Host 字段。Host 字段记录了域名, 使得服务器可以分辨用户访问服务器时使用的域名。这个字段就是用来实现一台服务器部署多个网站的效果。比如把 baidu.com 和 jd.com 都部署到 1.1.1.1 这台服务器上。为了区分两个网站, 浏览器在发出请求时, 要在 Host 字段上记录域名。服务器在分析 HTTP 协议头部的时候, 就能正确地把请求转发给不同网站的程序。所以只要分析 HTTP 请求的头部, 读取 Host 字段的值, 就能知道请求是通过哪个域名发来的了。 最后一个技术点, 就是让 URL 支持中文。请求参数部分如果要支持中文, 一般使用 百分号编码 (Percent-encoding, 有时候也叫 URL 编码)。这种编码就是把 GBK 编码或者 UTF-8 编码的字符串, 用 16 进制表示, 再加上百分号。比如 %C4%E3%BA%C3%CA%C0%BD。 但是域名部分要支持中文, 可就不能用百分号编码了, DNS 服务器不认识。域名部分要支持非 ASCII 字符, 一般用 Punycode (国际化域名编码)。它长得像这样 xn--rhq34a65tw32a, 一般以 “xn—“ 开头, 中间是ASCII 字符。 虽然上面说了很多, 但是实现这个小作品非常简单: 买个域名、泛域名解析、写个程序。这个程序的工作也很简单: 读取 HTTP 请求头部的 Host 字段, 返回相应的欢迎文本。我这个程序用 C# 来实现, 代码如下: 1234567891011121314151617[HttpGet]public IActionResult Home(){ // idnMapping 用于将 Punycode 转化为 Unicode 字符串 IdnMapping idn = new IdnMapping(); // 读取 HTTP请求头部的 Host 字段 string rawHost = Request.Headers[&quot;host&quot;]; // 将 Punycode 转化为 Unicode 字符串 string host = idn.GetUnicode(rawHost); // 使用正则表达式匹配域名中的姓名 Regex regex = new Regex(@&quot;([^.]+)(.*?)&quot;); Match match = regex.Match(host); string info_name = match.Groups[1].Value; // 返回对应的欢迎文本 string text = $&quot;一直都很喜欢 {info_name} 呢!&quot;; return Ok(text);} 枯燥。","link":"/2020/04/06/%E7%8E%A9%E4%B8%80%E7%8E%A9%E6%B3%9B%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90/"},{"title":"理解 C++20 Coroutine: 协程的概念","text":"理解 C++20 Coroutine: 协程的概念。C++ coroutine 的细节非常的多，但是能查到的资料却不是很多。我一边学习一边记录，打算写很多篇文章来分享我的理解。 这篇文章本来是想做成笔记的，但是写着写着就成了翻译。我参考的文章是 https://lewissbaker.github.io/2017/09/25/coroutine-theory，真的非常推荐大家将他的四篇文章都看完，讲解的非常详细清晰，我的文章不及他的千分之一。 我是在运行了一些协程的实际应用（cppreference里的一个例子：switch_to_new_thread）之后才看的这篇文章，所以我还是很容易理解原文中所谓的“执行额外的逻辑”是什么意思。 C++20 所引入的协程只有一套机制，没有更多其它东西了，而这套机制非常的灵活，允许你在协程执行的各个关键节点运行你自己的逻辑代码，这就是“执行额外的逻辑”的含义。 协程理论（Coroutine Theory） 协程就是函数“普通”函数（“Normal”function 或称为 subroutine）有两种操作：调用（Call）和**返回（Return）。这里的返回，也包括函数因为异常而退出的情况。 调用操作会创建一个 “活动帧”（Activation Frame），挂起调用者（Caller）的执行，然后转移到被调用函数（function being called）的开始继续执行。 返回操作会将返回值传递给调用者，销毁“活动帧”，并让调用者恢复执行。 关于调用和返回以及活动帧的概念，会在下面进行深入而详细地分析。 协程（coroutine）也是函数，因此函数的两种操作协程也有，即协程也支持调用和返回。协程的特点是它还支持额外的三种操作：挂起（Suspend）、恢复（Resume）和销毁（Destroy）。 挂起操作会暂停协程当前的执行，然后让调用者（Caller）继续执行。与返回操作不同的是，协程的挂起操作不会导致“活动帧”被破坏（这里的活动帧指的是协程活动帧）。函数的返回操作只在特定的节点发生，即在 return 关键词处发生返回操作。协程的挂起操作也是如此，只在使用 co_await 或 co_yield 关键词时，才会发生挂起操作。 恢复操作会恢复被挂起的协程，让它在被挂起的位置继续执行。这个操作会重新建立协程的活动帧（这里的活动帧指的是栈活动帧）。 销毁操作会销毁活动帧，而且不需要恢复协程的执行。用于储存活动帧的内存会被释放。 活动帧（Activation Frames）你可以将活动帧认为是一块保持着某个被调用函数状态的内存。这些状态包括所有函数参数的值和所有临时变量的值。 对于普通函数，活动帧里也包括返回地址。在返回操作发生时，需要通过这个地址才能回到调用者，进而继续向后执行。 对于普通函数，所有的活动帧都有严格的嵌套的生命周期。这种严格的嵌套允许我们使用一种高效率的内存分配数据结构来分配和释放每一次函数调用的活动帧。（也就是“栈”） 当一个活动帧被分配到栈时，通常称为 “栈帧”（stack frame）。 这个栈是如此地常用，以至于几乎所有的 CPU 架构都有一个特定的寄存器来存储这个栈的顶端（比如在 x64 架构是 rsp 寄存器）。 要为新的活动帧分配空间，你只需要根据新活动帧的大小将这个寄存器的值增加。反之，要释放活动帧的空间，你只需要根据活动帧的大小将这个寄存器的值减小。（原文末尾有图片，参考着原文末尾的图片会更好理解。） 调用操作（The ‘Call’ Operation）当一个函数调用另一个函数，调用者必须首先准备好将它自己挂起。 这个挂起步骤通常包含将所有当前寄存器的值保存到内存。这些值会在将来函数恢复执行时被还原。根据函数的调用约定，调用者和被调用者会协调由谁来保存这些寄存器的值，但是你可以直接地认为这个步骤是调用操作的一部分。 调用者还会将所有传递给被调用函数的参数保存到新的活动帧，这样被调用函数就可以访问他们。 最后，调用者将调用者的恢复点地址写入新的活动帧，并将执行转移到被调用函数的开始处。 在 x86/x64 架构中，最后一个操作有它自己的指令，也就是 call 指令。它将下一条指令的地址写入栈，将栈寄存器递增一个地址的大小，然后跳转到 call 指令指定的地址继续执行。 返回操作（The ‘Return’ Operation）当一个函数使用 return 语句返回时，这个函数首先会将返回值（如果有）储存到调用者可以访问到的地方。这个地方可以认为处于调用者的活动帧也可以认为处于当前函数的活动帧（因为两个函数都能访问它，所以活动帧的边界会因为它而变得模糊）。 然后，函数会经历以下步骤来销毁活动帧。 销毁返回点范围内的所有局部变量（调用析构函数）；（返回点之外可能还声明了局部变量，它们可能尚未被初始化，因此不需要析构它们） 销毁所有参数； 释放活动帧占用的内存； 最后，在调用者处恢复执行： 通过设置栈寄存器以还原调用者的活动帧，并且还原所有的寄存器值，它们可能被函数给破坏了； 跳转到调用者的恢复点，这个恢复点在调用操作时被储存； 注意，和调用操作一样，某些调用约定可能将返回操作的一些职责分摊到调用者和被调用者的指令中。 协程活动帧（Coroutine activation frames）由于协程具有可以被挂起而不销毁活动帧的特点，我们不再能保证活动帧的生命周期是严格嵌套的。这意味着活动帧不能像通常那样被分配到栈中，因此可能要分配到堆中。 在 C++ 协程提案中有一些规定允许将协程活动帧的内存分配到调用者的活动帧中，如果编译器能够证明协程帧的生命周期严格嵌套在调用者活动帧的生命周期之内。有一个足够聪明的编译器可以在许多情况下避免堆分配。（TODO：需要进一步了解何时可以节约堆分配） 对于协程来说，活动帧可以被分为两部分：一部分需要在协程被挂起时被保留，而另一部分只在协程执行时存在。 123456task&lt;&gt; func(){ int a = 123; co_await bar(a); co_await foo(); // 不再需要a, 因此 a 不需要在协程被挂起时保留} 123456task&lt;&gt; func(){ int a = 123; co_await bar(); co_await foo(a); // 跨越了一个挂起点，在第二个挂起点需要a, 因此 a 需要在协程被挂起时保留，分配到堆中} 比如上面所示代码，一个不跨越协程挂起点的局部变量 a，它可以被储存在栈中。而跨越了挂起点的局部变量，需要储存到堆中。可以将协程的活动帧逻辑上分成两个部分： 对于需要在协程被挂起时而不被销毁的活动帧，将会分配到堆中，将这部分称之为协程帧(coroutine frame)。 对于只在协程执行时存在的活动帧，将会分配到栈中，将这部分称为栈帧(stack frame)。 栈帧部分只有在协程执行时存在，并且会在协程挂起时和转移执行到调用者(恢复者)时被释放。 挂起操作（The ‘Suspend’ operation）挂起点使用了 co_await 或 co_yield 关键词的地方就是挂起点。 挂起时进行的工作首先，做好恢复协程的准备： 将寄存器的值写入到协程帧中； 将协程的挂起点写入协程帧中（这个工作让后续的恢复操作能够知道从哪里恢复，或者后续的销毁操作能够知道哪些值在范围内并且需要被销毁）；//TODO： 不知道具体是如何工作的当协程准备好被恢复，那么协程就可以被认为是处于挂起状态。 然后，在协程将执行转移回调用者/恢复者之前，协程有机会去执行一些额外的逻辑。这些额外的逻辑允许访问一个句柄(handle)，用以控制协程稍后如何恢复或销毁。 在协程进入挂起状态后执行额外逻辑的能力允许不需要同步地安排协程恢复。（TODO：不懂） 之后，协程可以选择立刻恢复（就是继续执行协程），或者选择将执行转移回调用者/恢复者。 如果执行被转移回调用者/恢复者，协程活动帧的栈帧部分会被释放并且从栈中弹出。 恢复操作（The ‘Resume’ operation）恢复操作可以在一个处于挂起状态的协程上执行。 通过调用句柄的 void resume() 方法来执行恢复操作。 和普通的函数调用一样，对 resume 方法的调用会在转移执行之前分配新的栈帧并且储存调用者的返回地址到栈帧中。 不一样的是，普通函数调用会将执行转移到被调用函数的开始，恢复操作的 resume 调用会将执行转移到恢复点(resume-point)，这个恢复点储存在协程帧中。 当协程再次遇到挂起点或者执行完毕，resume 方法就会返回。 销毁操作（The ‘Destroy’ operation）销毁操作会销毁协程帧，而且不会恢复协程的执行。 销毁操作只能作用在处于挂起状态的协程。 销毁操作和恢复操作很相似，因为它们都重新激活了协程活动帧，包括分配新的栈帧和储存返回地址（调用者）。 另一个相似的地方是，销毁操作也是需要调用特定的方法，void destroy()。 不同的地方是，恢复操作会跳转到挂起点之后继续执行，销毁操作会跳转到另一个代码分支。这个代码分支负责析构所有恢复点之前范围内的局部变量，然后释放它们在协程帧中占用的内存。 协程的调用操作（The ‘Call’ opeartion of a coroutine）从调用者的角度来说，和普通函数的调用操作没什么区别。 普通函数会在执行完毕时返回，协程会在遇到第一个挂起点时或执行完毕时返回。 当调用一个协程的时候，调用者会分配新的栈帧，将调用参数压入栈中，将返回地址压入栈中，然后将执行转移到协程。 协程所做的第一件事情是在堆上分配协程帧，然后从栈帧中复制(copy)/移动(move)调用参数到协程帧中，以使得调用参数的生命周期超过第一个挂起点。 协程的返回操作（The ‘Return’ opeartion of a coroutine）当一个协程执行返回声明(return-statement)时（即 co_return 关键词），会将返回值储存在某个地方（这个地方可以自定义），然后销毁所有的局部变量（但是不包括调用参数）。 然后协程有机会在将执行转移回调用者/恢复者之前执行一些额外的逻辑。 这些额外的逻辑可能执行一些操作来发布返回值，或者恢复执行其他需要这个返回结果的协程。这是完全可自定义的。 然后协程要么执行挂起操作（保持协程帧存活），或者执行销毁操作（销毁协程帧）。","link":"/2022/02/16/%E7%90%86%E8%A7%A3-C-20-Coroutine-%E5%8D%8F%E7%A8%8B%E7%9A%84%E6%A6%82%E5%BF%B5/"},{"title":"理解C++20 Coroutine: co_await与Awaiter","text":"理解C++20 Coroutine: co_await与Awaiter 这是我学习 C++20 Coroutine 笔记的第二篇，打算做成一个系列，如果感兴趣可以从头开始读： 理解 C++20 Coroutine: 协程的概念 这篇笔记参考的原文是：C++ Coroutines: Understanding operator co_await，更推荐大家直接看原文，因为原文写的就很好，我的笔记大部分都是翻译的原文。 协程提案给我们提供了什么？(What does the Coroutines TS give us?) 三个新关键词：co_await、co_yield、co_return。 几个新类型： coroutine_handle&lt;P&gt; coroutine_traits&lt;Ts…&gt; suspend_always suspend_never 一套通用的机制，库的编写者可以使用它与协程交互并自定义协程的行为。 一种使得编写异步代码更简单的语言工具。 C++20 协程提案所提供的工具可以被认为是协程版的“低级汇编语言”。这些工具很难被安全地、直接地使用，它们的主要目的是让库的编写者去构建其他开发者可以安全使用的、高度抽象的程序。 编译器和库之间的交互（Compiler &lt;-&gt; Library interaction）协程提案实际上并没有定义协程语义。它没有定义如何产生返回给调用者的值。它没有定义如何处理传递给 co_return 语句的返回值或如何处理从协程传播的异常。它也没有定义协程将会在哪一条线程恢复运行。 取而代之的是，它为库代码指定了一种通用的机制，可以通过实现符合特定接口的类型以定制协程的行为。编译器会生成调用这个类型实例方法的代码。这种方法类似于库编写者可以通过定义 begin()/end() 方法来自定义 range-based for-loop。 事实上，协程提案没有规定任何特定的协程机制语义使得它成为了一个很强大的工具。这允许库的编写者可以为了各种不同的目的，定义不同类型的协程。 举例来说，你可以定义一个协程，它异步地产生一个值；或者定义一个协程，它“懒惰地”（lazily）产生一系列值（即在需要时才计算值，而不是预先计算出整个序列再返回其中一个）；或定义一个协程来简化控制流程，如果 std::optional&lt;T&gt; 的值是 std::nullopt，那么就尽早退出执行。 协程提案定义了两种接口：Promise 接口和 Awaiter 接口。 !注意，这里原文用的是 Awaitable 接口，但是我觉得应该用 Awaiter 接口，因为下文提到：“实现了三个方法的类型称为 Awaiter 类型”，那么这三个方法所对应的接口称为 Awaiter 接口会更容易理解，因此我这里采用了“Awaiter 接口”。 这里的接口指的就是面向对象里接口的含义。只要你的类型实现了标准所指定的一系列函数，也就是实现了 Promise 接口 或 Awaiter 接口，那么这个类型就是 Promise type 或 Awaiter type。 Promise 接口指定了一些方法来控制协程自身的行为。库的编写者可以自定义当协程被调用时会发生什么、当协程返回时会发生什么（这里的返回既可以指寻常意义的函数返回，也可以指因为未捕获的异常而退出）、以及自定义协程内所有 co_await 或 co_yield 表达式的行为（这里指的是 await_transform 的工作）。 Awaiter 接口指定了一些方法来控制 co_await 表达式的语义。当一个值被 co_await 时，代码会被翻译成 awaitable 对象的一系列方法的调用。Awaiter 接口允许你：是否挂起当前的协程(1)、当协程已经挂起后执行额外的逻辑来安排协程之后何时恢复执行、在协程恢复执行并产生 co_await 表达式的结果后执行一些逻辑。 (1).比如一种可以被多次 co_await 的设计，第一次会挂起进行计算并保存计算结果，之后再co_await 都直接返回计算结果而无需挂起 Awaiter和Awaitable:解释operator co_await(Awaiters and Awaitables: Explaining operator co_await)操作符 co_await 是一个新的可以作用于一个值的一元操作符，比如说：co_await someValue。 操作符 co_await 只能被用于协程中。 这是一种“恒真逻辑”（tautology）的思想，因为根据定义，所有包含co_await操作符的函数会被编译成协程。 其实我更喜欢 C# 的方式，C# 将带有 async 关键词的方法编译为异步函数，通过关键词这样可以一眼看出一个函数是不是异步函数。而 C++ 的这种方式，协程和普通函数的区别就没那么清晰了。我注意到有人提案添加 async 关键词，类似 C#，将有 async 关键词标记的函数编译为协程。并同时将 co_await、co_yield及co_return分别简化为 await、yield、return。这个提案的结果是“没有达成一致认识”，看来是失败了呢。 一个支持 co_await 操作符的类型被称为 Awaitable 类型(Awaitable type). 请注意一个类型是否可以被 co_await 操作符应用可以依赖于 co_await 表达式出现的上下文。协程所使用的 Promise type 可以使用它的 await_transform 方法来改变 co_await 表达式的含义。 await_transform 方法我还没有使用过，但是我猜测它可以把一个类型转化为一个 Awaitable 类型。这样一个即使不是 Awaitable 类型（比如std::string），在某些协程里也可以使用： co_await std::string 的用法。 更具体地说，在需要时，我喜欢使用术语 Normal Awaitable 来描述在没有 await_transform 成员的协程上下文中支持 co_await 运算符的类型。而且我喜欢使用术语 Contextually Awaitable 来描述一种类型，该类型仅在某些类型的协程的上下文中支持 co_await 运算符，因为协程的 promise 类型中存在 await_transform 方法。 总结： Normal Awaitable：因为实现了 Awaiter 接口而变得 Awaitable 的类型。 Contextually Awaitable: 因为 promise type 实现了相关 await_transform 方法而变得 Awaitable 的类型。 一个 Awaiter 类型是实现了三个特定方法的类型，这些方法作为 co_await 表达式的一部分被调用，这三个特定方法是：await_ready、await_suspend、await_resume。 请注意，我无耻地从C# async关键词的机制中“借用”了术语 “Awaiter”，该机制是根据 GetAwaiter() 方法实现的，它返回对象的接口类似于C++中Awaiter 的概念。(这里的“我”，是原文的作者，我只是翻译) 请注意，一个类型可以同时是 Awaitable 类型和 Awater 类型。 实现了这三个方法的类型根据定义自然是一个 Awater type，而 Awaiter 可以被 co_await 关键词应用，天然是 Awaitable type。但是Awaitable type 不一定是 Awater type！比如你可以重载 operator co_await，然后返回一个 Awaiter，这样的类型是 Awaitable type，但是因为没有实现 Awaiter 接口，所以不是 Awaiter type。 获取 Awaiter (Obtaining the Awaiter)对于被 co_await 的值，编译器做的第一件事情是生成获取 Awaiter 对象的代码。N4680 第 5.3.8(3) 节列出了一些获取 awaiter 对象的步骤。 让我们假设被 co_await 的协程的 Promise type 是 P，而且变量promise 是当前协程的 Promise object 的左值引用。 如果 Promise type P 有一个名为 await_transform 的成员函数，那么表达式 &lt;expr&gt; 首先被传入到函数调用 promise.await_transform(&lt;expr&gt;) 中以获取 Awaitable 值，awaitable。 如果没有 await_transform 成员函数，那么表达式 &lt;expr&gt; 的结果被直接认为是 Awaitable 对象，awaitable。 然后，如果 Awaitable 对象 awaitable 有一个 operator co_await 操作符重载，那么操作符重载会被调用来获取 Awaiter 对象。反之，awaitable 将用作 awaiter 对象。 如果把这些流程写成代码，那么两个函数 get_awaitable() 和 get_awaiter() 可能看起来像： 12345678910111213141516171819template&lt;typename P, typename T&gt;decltype(auto) get_awaitable(P&amp; promise, T&amp;&amp; expr){ if constexpr (has_any_await_transform_member_v&lt;P&gt;) return promise.await_transform(static_cast&lt;T&amp;&amp;&gt;(expr)); else return static_cast&lt;T&amp;&amp;&gt;(expr);}template&lt;typename Awaitable&gt;decltype(auto) get_awaiter(Awaitable&amp;&amp; awaitable){ if constexpr (has_member_operator_co_await_v&lt;Awaitable&gt;) return static_cast&lt;Awaitable&amp;&amp;&gt;(awaitable).operator co_await(); else if constexpr (has_non_member_operator_co_await_v&lt;Awaitable&amp;&amp;&gt;) return operator co_await(static_cast&lt;Awaitable&amp;&amp;&gt;(awaitable)); else return static_cast&lt;Awaitable&amp;&amp;&gt;(awaitable);} 这一段主要是想表达对于 co_await &lt;expr&gt; 这么一行代码，其中这个 &lt;expr&gt; 可以是很多很多种情况。比如 &lt;expr&gt; 可以是一个 Awaiter type 或者 Awaitable type 的 object，那么肯定行得通。又比如 &lt;expr&gt; 可以是一个函数调用，但是它的返回值是 Awaitable type，那么也行得通！再极端点，&lt;expr&gt; 既不是 Awaiter type 也不是 Awaitable type，但是因为协程的 Promise type 实现了相关的 await_transform() 函数，那么这个 co_await &lt;expr&gt; 也是合法的代码。 Awaiting the Awaiter 这个标题还真不知道怎么翻译好。这一部分主要讲解 C++ 编译器是如何把 co_await &lt;expr&gt; 翻译成一系列 Awaiter 接口的函数调用的。 我们假设将 &lt;expr&gt; 的结果转化为 Awaiter 的逻辑可以封装成上面所说的两个函数，那么对于代码 co_await &lt;expr&gt; 的语义可以被粗糙地翻译为以下代码： 1234567891011121314151617181920212223242526272829303132333435{ auto&amp;&amp; value = &lt;expr&gt;; auto&amp;&amp; awaitable = get_awaitable(promise, static_cast&lt;decltype(value)&gt;(value)); auto&amp;&amp; awaiter = get_awaiter(static_cast&lt;decltype(awaitable)&gt;(awaitable)); if (!awaiter.await_ready()) { using handle_t = std::experimental::coroutine_handle&lt;P&gt;; using await_suspend_result_t = decltype(awaiter.await_suspend(handle_t::from_promise(p))); &lt;suspend-coroutine&gt; if constexpr (std::is_void_v&lt;await_suspend_result_t&gt;) { awaiter.await_suspend(handle_t::from_promise(p)); &lt;return-to-caller-or-resumer&gt; } else { static_assert( std::is_same_v&lt;await_suspend_result_t, bool&gt;, &quot;await_suspend() must return 'void' or 'bool'.&quot;); if (awaiter.await_suspend(handle_t::from_promise(p))) { &lt;return-to-caller-or-resumer&gt; } } &lt;resume-point&gt; } return awaiter.await_resume();} 方法 await_suspend() 根据返回值类型可以分为两个版本，void 版本和bool 版本。其中，void 版本无条件地将执行转移回 caller/resumer。而bool 版本允许 awaiter 对象根据条件选择是否立即恢复协程的执行，而不返回到 caller/resumer。 bool版本的 await_suspend() 方法可以被用于这种情况：awaiter 可以异步地进行计算，但有时也想同步地执行。 在 &lt;suspend-coroutine&gt; 节点，编译器会生成一些代码来保存当前协程的状态并准备协程的恢复。这包括保存恢复点的地址以及将寄存器中的值保存到协程帧的内存中。 在 &lt;suspend-coroutine&gt; 的操作完成之后，当前的协程就被认为是处于挂起状态。你能观察挂起的协程的第一个点在 await_suspend() 的调用里。一旦协程被挂起，它就可以被恢复或者销毁。 函数 await_suspend() 的责任是安排协程在未来的恢复（或销毁）。注意，从 await_suspend() 返回 false 算作是安排协程在当前线程立刻恢复。 函数 await_ready() 的目的是允许你避免 &lt;suspend-coroutine&gt; 操作的消耗，在某些情况，当你已知要同步地进行，就不需要挂起协程再恢复。 在 &lt;return-to-caller-or-resumer&gt; 节点，执行会被转移回 caller/resumer，当前栈帧弹出，但是保持协程帧活跃。 当挂起的协程最终被恢复，则在 &lt;resume-point&gt; 恢复执行。 函数 await_resume() 的返回值类型就是 co_await 表达式的结果类型。函数 await_resume() 也可以抛出异常，来向外传播 co_await 表达式中的异常。 请注意，如果一个异常在调用 await_suspend() 时传播出来，那么协程会自动地恢复，并且不会调用 await_resume()。 协程句柄(Coroutine Handles)类型 coroutine_handle&lt;P&gt; 表示协程帧的一个非拥有句柄（non-owning handle），可以通过它来恢复协程的执行或销毁协程帧。它也可以被用来访问协程的 promise object。 什么是 non-owning handle？我不知道怎么翻译好。 概括的说，协程句柄有这些接口：1234567891011121314151617181920212223242526namespace std::experimental{ template&lt;typename Promise&gt; struct coroutine_handle; template&lt;&gt; struct coroutine_handle&lt;void&gt; { bool done() const; void resume(); void destroy(); void* address() const; static coroutine_handle from_address(void* address); }; template&lt;typename Promise&gt; struct coroutine_handle : coroutine_handle&lt;void&gt; { Promise&amp; promise() const; static coroutine_handle from_promise(Promise&amp; promise); static coroutine_handle from_address(void* address); };} 当你实现一个 Awaiter type 时，你将会用到 coroutine_handle 里一个关键的 resume 方法。当某些操作完成时，你想要恢复协程的执行，就调用resume 方法。resume 方法将会在遇到下一个 &lt;return-to-caller-or-resumer&gt; 节点时返回（有两种情况：1.再次遇到 co_await，并且将会再次挂起协程； 2.执行到协程的末尾；）。 destroy 方法会销毁协程帧，调用所有作用范围内的变量的析构函数，并且释放协程帧所用的内存。你通常不需要（而且应该尽量避免）去调用 destroy 函数，除非你是一个库的作者，正在实现协程的 Promise type。通常来说，协程帧会被某种 RAII 类型所持有，并且来自协程调用的返回值。所以调用destroy 而没有和 RAII 对象协作的话，会导致双重析构的BUG。 promise 方法返回当前协程的 promise object 的引用。和 destroy 方法一样，它通常只有在你是协程的 promise type 的作者时才会用到。 通常来说，对于绝大多数的 Normally Awaitable 类型，应该使用 coroutine_handle&lt;void&gt; 作为 await_suspend() 方法的参数类型，而不是 coroutine_handle&lt;Promise&gt;。如果考虑为某些协程 Promise type 做特别实现，才使用 coroutine_handle&lt;Promise&gt;。 方法 coroutine_handle&lt;P&gt;::from_promise(P&amp; promise) 允许你从协程的 Promise object 的引用重新构造 coroutine handle。请注意，你必须确保类型 P 和具体协程的 promise type 相匹配。如果尝试构造一个 cotoutine_handle&lt;Base&gt; 而具体协程的 promise type 是 Derived 会导致未定义行为。 方法 address()/from_address() 允许你将 coroutine handle 转化为/转化自 一个 void* 指针。 这主要是为了允许作为“上下文”参数传递到现有的 C-Style API，你在某些情况下实现 Awaiter type 时才会发现它的用处。不过，在我所发现的大多数案例里，需要额外传递信息给这个“上下文”参数。所以我通常将 coroutine_handle 储存在一个 struct 中，然后把 struct 的指针传递给这个“上下文”参数，而不是使用 address 的返回值。 无需同步的异步代码（Synchronisation-free async code）co_await 操作符的一个强大的设计特性是可以在协程暂停后且将执行返回到caller/resumer之前执行代码。 这允许 Awaiter object 在协程已经挂起后去初始化异步操作，将已经挂起的协程的 coroutine_handle 传入给异步操作。当异步操作完成后，这可以安全地恢复（可能在另一条线程）而不需要额外的同步。 当协程恢复之后的第一件事情是调用 await_resume 来获取返回值，并且通常立即销毁 Awaiter object（举例说，await_suspend 里使用 this 指针）。协程是有可能在await_suspend返回之前就运行到结尾、销毁协程和 promise object的。 所以，在 await_suspend 方法里，一旦协程有可能在另一条线程恢复，你需要确保避免访问 this 指针和协程的promise object(通过.promise()方法)，因为它们可能都已经被销毁了。通常来说，在异步操作开始之后和协程已经被安排恢复，在await_suspend方法里你可以安全地访问的唯一东西就是await_suspend的局部变量。 我看的一脸懵逼，没有相关编程经验，不知道到底说的什么情况。 总结原文作者很详细地讲解了 co_await &lt;expr&gt; 语句是如何被翻译成 Awaiter 接口的调用的。我感觉原文不适合给初学者了解 C++ 协程，它非常枯燥，而且有很多新概念（我也是写了一些协程代码后，再回头看这篇文章，才顺利地看明白了）。我觉得原文更适合那些希望了解 C++ 协程工作细节的人，绝对值得多次阅读。 Awaiter type实现了 Awaiter 接口的类型。 它用三个函数控制 co_await 表达式如何工作。 bool await_ready(); : 表示 co_await 是否要挂起，false -&gt; 挂起。 void/bool await_suspend(coroutine_handle&lt;P&gt;); : 在这个函数里安排何时恢复协程的执行（通过调用 resume() 方法）。 T await_resume() : 在这个函数返回执行的返回值。类型 T 表示 co_await &lt;expr&gt; 表达式的类型。 Awaitable type可以被 co_await 的类型。（可以是 Awaiter type 也可以是重载了 operator co_await 的类型）","link":"/2022/02/21/%E7%90%86%E8%A7%A3C-20-Coroutine-co-await%E4%B8%8EAwaiter/"},{"title":"理解C++20 Coroutine: Promise type","text":"理解C++20 Coroutine: promise type 这是我学习 C++20 Coroutine 笔记的第三篇，打算做成一个系列，如果感兴趣可以从头开始读： 理解 C++20 Coroutine: 协程的概念 理解C++20 Coroutine: co_await与Awaiter 本文的主要参考文献是 C++ Coroutines: Understanding the promise type，建议直接读原文而不是我的笔记。 Promise objects前面的笔记提到过，Promise object 是用来控制协程的行为的。 promise type 的实例 promise object 会在每次调用协程时被创建。然后编译器会为协程函数的调用生成一些代码，在协程执行到特定点时调用 promise 特定的函数。 举例说明，假设有一个协程被调用之后，创建了一个 promise object: promise，那么对于这个协程的调用可能会是这样的： 12345678910111213{ co_await promise.initial_suspend(); try { &lt;body-statements&gt; } catch (...) { promise.unhandled_exception(); }FinalSuspend: co_await promise.final_suspend();} 其中 &lt;body-statements&gt; 是协程的代码。 相比于普通函数调用，协程的调用会额外多一些步骤： 通过 operator new 分配协程帧(coroutine frame)；(可选步骤) 复制所有函数参数到协程帧； 调用 promise type 的构造函数，得到 promise object: promise。 调用 promise.get_return_object() 来获取协程第一次返回时的返回结果； 调用 promise.initial_suspend() 并 co_await 它的返回结果； 当 co_await promise.initial_suspend() 恢复执行(resume)，你所编写的协程主体代码开始执行。 当执行遇到 co_return 时执行的一些额外的步骤： 调用 promise.return_void() 或 promise.return_value(&lt;expr&gt;)； 以创造它们的反向顺序销毁所有局部变量； 调用 promise.final_suspend() 并 co_await 它的返回结果； 或者，执行因为遇到未处理异常而退出，那么： 捕获该异常并在 catch-block 调用 promise.unhandled_exception()； 调用 promise.final_suspend() 并 co_await 它的返回结果； 一旦协程主体的代码执行完毕，协程帧就会被销毁，销毁步骤包括： 调用 promise object 的析构函数； 调用函数参数副本的析构函数； 调用 operator delete 来释放协程帧的内存；(可选步骤) 将执行迁移回 caller/resumer； 分配协程帧传递给 operator new 的大小不是 sizeof(promise type)，而是整个协程帧的大小，包括所有函数参数的大小、promise object 的大小、局部变量的大小和编译器用于管理协程状态的内存大小。 作为一种优化，编译器可能不会使用 operator new 分配协程帧。 it is able to determine that the lifetime of the coroutine frame is strictly nested within the lifetime of the caller; and the compiler can see the size of coroutine frame required at the call-site. 在这种情况下，编译器可以将协程帧分配到调用者的激活帧中（栈帧(stack-frame) 或 协程帧(coroutine-frame) 都有可能）。 promise type 可以定义 operator new() 的重载来替换全局的 operator new。 复制参数到协程帧如果参数以值传递的方式(pass-by-value)，那么会调用移动构造函数复制到协程帧。 如果参数以引用传递的方式(pass-by-reference)，无论是左值还是右值，都只有引用会被复制到协程帧。 构造 promise object在复制所有参数到协程帧之后会构建 promise object，这种设计允许你在构造 promise object 时（构造函数内）可以访问这些参数。 获取返回对象成功构造 promise object 后的第一件事情就是通过调用 promise.get_return_object() 获取返回对象。","link":"/2022/03/02/%E7%90%86%E8%A7%A3C-20-Coroutine-promise-type/"},{"title":"给博客换了个新主题","text":"毕业论文取得了阶段性进展，终于可以腾出时间搞点别的事情了，先给博客换了个新主题，好久没写东西了。 我觉得新主题比旧主题更精致一点，一贯的简约风格但是更有高级感？换了主题后感觉心情都好了些。 新主题的代码高亮支持浅色方案，和主题很搭。新主题还支持夜间模式（原始版本的主题不支持，这个大佬的魔改版支持），走在设计趋势的前沿了。 比较遗憾的是评论全都没了。之前所用的 GitTalk 版本比较旧，对于中文标题的博文很大概率无法创建评论 Issues，被我魔改了一下。现在新版对中文标题支持变好了，我就不做魔改了，原来的评论没了就没了吧。","link":"/2022/05/19/%E7%BB%99%E5%8D%9A%E5%AE%A2%E6%8D%A2%E4%BA%86%E4%B8%AA%E6%96%B0%E4%B8%BB%E9%A2%98/"},{"title":"百度网盘导致资源管理器(explorer)崩溃","text":"我对百度网盘的评价是：用户体验极差的毒瘤软件。 突然发现电脑的资源管理器打不开了，一打开资源管理器就会卡住，开始菜单打不开，任务栏也无响应。 对于资源管理器崩溃的问题，通常在“可靠性历史记录”里找崩溃的原因。 可以在 Windows 搜索里直接搜索“可靠性”或者 “控制面板 -&gt; 系统和安全 -&gt; 查看你的计算机状态 -&gt; 维护 -&gt; 查看可靠性历史记录” 查看可靠性历史记录。 打开之后，可以发现最近一段时间的计算机可靠性，错误越多可靠性越低。（我这个问题持续了有一段时间了，实在是烦了才抽时间找原因） 点击 “查看技术详细信息”，一般来说运气好的话，直接能找到一些蛛丝马迹。比如说第三方程序的进程，那么这个崩溃很有可能就是对应的程序导致了，卸载了也许就好了。 我之前遇到过一次金山毒霸导致的资源管理器崩溃，在详细信息里看到了“kingsoft”字样，于是我把电脑里的所有金山的软件都卸载了，果然就好了。 但是这次没有找到什么有用信息，于是我进一步点击 “查看啥啥文件”（我给忘了，没截图）。 之后会打开临时目录下的一个文件夹，里面有一个 memory.hdmp 文件。 用 Visual Studio 可以打开它，拉到最下面，能发现一些第三方软件的模块。 看到 YunShellExtV164.dll 的路径，就知道它是百度网盘的玩意。 把百度网盘卸载了，问题解决。 实际上那些第三方模块都有可能是导致崩溃的罪魁祸首，之所以第一个挑百度网盘卸载，是因为它的用户体验实在是太差了，让我不得不怀疑它的制作水平。 我觉得我只需要罗列一下它的问题，就能感受到百度网盘的用户体验有多差： 打开百度网盘的时候静默更新，没有任何的窗口提示。百度网盘那么大的体积做不到秒下载秒更新，静默更新居然不给个提示？我一度以为百度网盘崩溃了。 卸载程序居然也会触发自动更新。我tmd想卸载百度网盘还得更新到最新版。而且也是静默更新，我在任务管理器盯着他完成更新下载。 把自己装到不需要管理员权限的目录下（用户数据目录），违反了微软的软件开发规范，只为了方便自己往用户电脑里拉屎。 基于 electron 的桌面软件开发技术已经很成熟了，但是百度网盘的UI在高分屏下显示很差劲。我甚至找不到和他一样UI差劲的国产软件，在这一方面成为国产之最当之无愧。 用很恶心的方法引导用户将数据备份到百度网盘，这一点在手机客户端做的尤其过分，同意备份的按钮做得特别大，不小心一点很容易点到。 客户端里的广告多且恶心，比如注册贷款软件送会员，相当于用身份证、银行卡等信息换几天的会员。 我对百度网盘的评价是：用户体验极差的毒瘤软件。","link":"/2022/05/21/%E7%99%BE%E5%BA%A6%E7%BD%91%E7%9B%98%E5%AF%BC%E8%87%B4%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86%E5%99%A8-explorer-%E5%B4%A9%E6%BA%83/"},{"title":"《深入理解计算机系统》之优化程序性能(第五章)笔记","text":"高三毕业的暑假就看了这本书，但是当时水平很浅，只能看进去前两章，现在又回来继续往后看。 这本书是了解计算机的一本好书，光是前两章的内容就让我在一段时间学习计算机相关课程的速度飞快。 这本书的第五章主要讲解如何优化程序性能。作者的讲解方式很适合我学习，但是结构上不太适合复习。因此我将其中的知识点重新排列组合，方便我以后复习。 笔记正文： 优化程序性能的方式主要可概括成三种： 减少不必要的开销 (比如不必要的函数调用、内存引用) 让代码可以被编译器优化 (比如内存引用可能会阻止编译器优化) 利用现代处理器的硬件特性 (利用超标量处理器指令并行特性) 减少不必要的开销这是最简单的优化方式，很多时候只要稍微留意就能注意到可以改善的地方。 不必要的函数调用比如书里很经典的一个例子，在循环里调用一个返回值固定的函数。 1234for(int i = 0; i &lt; strlen(str); ++i){ // do sth...} 上面的代码，每一次循环，都会调用 strlen(str)，计算一次字符串的长度。而计算一次字符串的长度需要遍历整个字符串以寻找字符串末尾的 ‘\\0’ 字符。这种情况下效率肯定是很低的。 如果字符串的长度是不会改变的，那么更好的写法是只调用一次 strlen。 12345int length = strlen(str);for(int i = 0; i &lt; length; ++i){ // do sth...} 在我看这本书之前我就听说现代编译器（不知道是哪个语言）能够优化上面的代码。但是在这本书里指出，C 语言编译器可能会认为 strlen(str) 的返回值是变化的，从而阻止了优化。 在 C++ 中，vector&lt;T&gt; 根据索引访问元素有两种方式，一种是使用 operator[]，另一种是使用 at() 成员函数。这两个函数是有区别的，at() 函数会进行越界检查，如果索引越界会触发异常，而 operator[] 则不会。 如果循环中，可以保证逻辑上不会出现越界访问，那么每次都进行越界检查显然是没必要的。 123456789vector&lt;int&gt; vec = {1,2,3,4};for(int i = 0; i &lt; vec.size(); ++i){ // 在这个循环里，通过 i 访问 vec 不会导致越界 // 如果用 at 函数进行越界检查是没必要的 cout &lt;&lt; vec[i] &lt;&lt; endl; // good cout &lt;&lt; vec.at(i) &lt;&lt; endl; // bad} C++ 标准库把最常用的 operator[] 设计为不进行越界检查估计就是为了效率。 编译器的内联优化也可以消除不必要的函数调用，C++ 通过 inline 关键词标记一个函数为内联函数，但这不是强制性的约束，是否进行内联优化取决于编译器。 不必要的内存引用这是我以前很少注意到的细节，这个细节需要结合代码来分析。 比如下面这个 sum1 函数，它对数组进行求和，并把结果存到 result 里。 123456789101112131415161718void sum1(int* array, int length, int* result){ *result = 0; for(int i = 0; i &lt; length; ++i) { *result += array[i]; }}void sum2(int* array, int length, int* result){ int tmp = 0; for(int i = 0; i &lt; length; ++i) { tmp += array[i]; } *result = tmp;} result 是一个 int 指针，它指向一片内存。这个函数的循环，将会多次通过 result 访问这一片内存。 对于函数 sum2，会有更好的效率。因为临时变量 tmp 完全可以存到某个寄存器里，CPU 在循环里只需多次访问一个寄存器。CPU 访问内存的速度和 CPU 访问寄存器的速度是不一样的，CPU 访问寄存器的效率要远远大于访问内存。 我觉得 CPU 会把 array 的数据从内存复制到高速缓存里来提高效率，这本书似乎也有提到，但是我还没看完。 让代码可以被编译器优化可能阻止编译器优化的情况下面这两个函数，直觉上看 func2 似乎是 func1 更优雅的实现，所以现代编译器把 func1 优化成 func2 是行得通。函数 func1 有 4 次内存引用。而 func2 只有两次，如果能这么进行优化，那执行效率会有所提升。 12345678910void func1(int* a, int* b){ *a += *b; *a += *b;}void func2(int* a, int* b){ *a += 2 * (*b);} 但是实际上，编译器可能不会做出这样的优化。这是因为当参数 a 和 参数 b 的指针是同一个指针时，两个函数的计算结果是不同的。 比如： 123int v = 1;func1(&amp;v, &amp;v); // return: 4func2(&amp;v, &amp;v); // return: 3 编译器的优化必须保证优化前后的一致性，所以编译器不会把 func1 优化成 func2。 这里我觉得可以总结出一条结论：相同的内存引用，可能会阻止编译器优化。 利用现代处理器的硬件特性 不了解现代 CPU 的工作细节，我看完也还是一知半解啊。所以以下内容很可能有错误，请批评指正。 X86 中一条汇编指令可能要多个时钟周期才能完成。而且这些指令是有可能乱序执行的。线代处理器使用一种分支预测技术，在遇到分支(if语句可能产生分支)的时候，处理器不会等待条件检测完成再去选择分支，而是先猜测一条分支是成立的，执行这条分支的指令。如果分支预测错误，那么代价是很大的：之前执行的结果只能全部丢弃，要重新执行正确分支的指令。 这些现代处理器的特性，也会对程序性能有影响。 指令的并行执行上面提到的 sum2 函数，它循环部分的汇编代码如下(Clang 12.0 使用 O1 优化)： 12345.LBB1_4: # =&gt;This Inner Loop Header: Depth=1 add ecx, dword ptr [rdi + 4*rsi] add rsi, 1 cmp rax, rsi jne .LBB1_4 这一段汇编代码中，实际上并不只有 add、 add、 cmp 和 jne 四个操作，比如还涉及从内存中加载数据的操作( dword ptr [rdi + 4*rsi] )。在加载数据之后，比较关键的一个点是，两个 add 指令是可以同时运行的。 这是因为两个 add 指令直接并不存在数据依赖。第二个 add 和 cmp 指令就不能同时进行，因为 cmp 使用了 rsi 寄存器的值，必须要等第二个 add 指令完成之后，cmp 计算的值才是正确的。 第一个 add 指令和第二个 add 指令虽然也都用到了 rsi 寄存器，但是第一个 add 指令用到的 rsi 寄存器，发生在加载数据的时候。真正进行 add 计算时，已经不再使用 rsi 寄存器的值了。 BUT! 如果我理解没问题的话，我这里就有个疑惑了：人可以分析出来这些，但是 CPU 怎么知道这些指令没有数据上的依赖呢？ 循环展开这是我觉得最有意思的部分，循环展开优化是我以前就了解过的编译器优化技术，这本书让我知道了循环展开优化里的各种细节。 k x 1 循环展开前文提到的 sum2 函数的循环要执行 n 次加法和 n 次判断(判断 i 和 length 的大小)。循环展开优化，将每次循环做 1 次加法改成做 k 次加法。这样优化最终还是要做 n 次加法，但是循环的次数以及判断的次数都减少了。(减少了 cmp 指令和 jmp 指令的执行) 这种循环展开称为 k x 1 循环展开，一次循环计算 k 个元素而累计值存到 1 个变量中。 比如当 k = 2 时，函数 sum2 可以展开成： 12345678910111213141516void sum2(int* array, int length, int* result){ int tmp = 0; int i; // 1 次循环加 2 个元素 for(i = 0; i &lt; length - 1; i += 2) { tmp = (tmp + array[i]) + array[i + 1]; } // 把剩余的元素都加上 for(; i &lt; length; ++i) { tmp = tmp + array[i]; } *result = tmp;} k x k 循环展开k x 1 次循环展开的计算结果都存到 1 个变量中，这导致第 t 次运算都要等第 t - 1 次运算结束后才能进行。如果有多个结果变量，那么这 k 次运算就可以并行执行。 12345678910111213141516171819void sum2(int* array, int length, int* result){ int tmp1 = 0; int tmp2 = 0; int i; // 1 次循环加 2 个元素 for(i = 0; i &lt; length - 1; i += 2) { // 现在，这两个加法运算没有关联了，可以并行执行 tmp1 = tmp1 + array[i]; tmp2 = tmp2 + array[i + 1]; } // 把剩余的元素都加上 for(; i &lt; length; ++i) { tmp1 = tmp1 + array[i]; } *result = tmp1 + tmp2;} 最后，循环展开的代码不需要自己写，编译器优化会自动完成的。","link":"/2021/05/18/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E4%B9%8B%E4%BC%98%E5%8C%96%E7%A8%8B%E5%BA%8F%E6%80%A7%E8%83%BD-%E7%AC%AC%E4%BA%94%E7%AB%A0-%E7%AC%94%E8%AE%B0/"},{"title":"[翻译]控制台、终端和Shell的区别是什么？","text":"控制台、终端和Shell的区别是什么？ 原文链接：https://www.hanselman.com/blog/WhatsTheDifferenceBetweenAConsoleATerminalAndAShell.aspx 我见过许多类似的问题，但是这些问题他们本身说明了对一些重要术语的误解。 为什么我们要通过 Windows Terminal 使用 PowerShell？ 我不需要通过 WSL 来使用 bash，我使用 Cygwin 我可以将 Conemu 和 PowerShell 一起使用吗或者我需要使用 Windows Terminal吗？ 让我们从词汇表开始辨析这些词语。 终端(Terminal)终端(Terminal)来自终止(Terminate)一词，这表示它是终止的一端或通讯过程的“终止端”。我们经常听到“哑终端”(dumb terminal)这个词，它指的是一个基于文本的环境，你身边的电脑只是接收文本输入和显示文本，而真正在执行工作的是另一端的大型机。 电传打字机(TTY, teletypewriter)是第一种终端。在你面前的是一种文字打字机而不是屏幕。当你在打字机上打字，你会在一张纸上看到你所打出的文本，并且文本会输入到计算机中。当计算机做出回应，你会看到打字机自动在同一张纸上打字。 当我们从软件意义上提及终端，我们指的是终端或电传打字机的文字软件版本。Windows Terminal就是这种。它非常擅长显示文字输出。它可以接收输入并传递它。但是终端并不聪明。它实际上不处理你的输入，它不会查看你的文件或进行思考。 控制台(Console)在 20 世纪中期人们会有一种叫做控制台或者控制台机柜的家具放在客厅。在计算机中，控制台是一种集成了屏幕和键盘的控制台或机柜。但它实际上是一个终端。技术上说，控制台是设备而终端现在是控制台中的软件程序。 在软件世界里，终端和控制台在所有方面都是同义词。 SHELL终端会将用户的输入发送给 Shell 程序。Shell 程序生成输出并传递回终端让其显示。下面是一些 Shell 程序： bash, fish, zsh, ksh, sh, tsch PowerShell, pwsh cmd, yori, 4dos, command.com 现在，你有了这些终端，是一个更有意义的要点。你对 Shell 的选择不应该也不能决定你对终端软件的选择。 题外话：WSL 和 WSL2 (适用于 Linux 的 windows 子系统,the Windows Subsystem for Linux) 是运行于 Windows 10 的完整的本地 Linux(或许多 Linux)。它们是完整而且真实的。WSL2 附带了一个真实的 Linux 内核并且运行在 Windows 10 上。Cygwin 不是一个 Linux。Cygwin 是 Windows 上一个包含了 GNU 和 开源工具的大集合，它们提供的功能类似于 Linux。但 Cygwin 不是 Linux，它是一个模拟器。是针对 Win32 编译的 GNU 实用程序。它非常好，但对你来说知道它们之间的区别也很重要。Cygwin 可以让你运行你的 bash shell 脚本，但是它不能运行 Apache、Docker 或其它真正的 ELF 二进制文件和 Linux 应用程序。 你选择的 Windows 控制台吗？Windows 附带了许多 Shell。这是我正在运行的一些。(图)注意到“chrome”或它们周围的边框和标题了吗？这些 shell 都由一个你从未听过的传统 windows 控制台托管，它叫做 conhost.exe。你可以转到命令提示符，键入 powershell，cmd 或 ubuntu，任意数量的 shell 都能运行。Conhost 完成输入和输出的工作。 现在，请忘记 conhost 的存在，因为它很烂，它已经过时了。 伪控制台、伪终端、PTY、伪TTY(CconPTY)（不是很懂这一段） Pseudo Terminals are terminal emulators or software interfaces that emulate terminals. They pretend to be terminals like the ones above. *Nix systems have long had a pseudo-terminal (PTY) infrastructure and now Windows as a pseudoconsole (ConPTY) as well. Window’s new ConPTY interface is the future of consoles and terminals on Windows. If you choose a 3rd party (non-built-in) console applications for Windows, make sure it supports ConPTY and it’ll be a better experience than some of the older consoles that use screen scraping or other hacks. 回到你对 Windows 控制台的选择记住在 Windows 上你可以使用很多 shell。如果你不喜欢 conhost.exe （你不应该这样），有大量你可以使用的第三方控制台。 Hyper ConEmu cmder Console2 ConsoleZ Terminus FluentTerminal ZOC MobaXterm Babun (dead) 4NT/jpSoftware (not free) Putty MinTTY Windows Terminal (free in Microsoft Store) XTermjs - a Typescript component that lets you integrate terminals into your apps VSCode includes a Terminal Visual Studio 2019 Preview includes a Terminal 所有这些终端都支持上面提到的所有 shell。因为一个 shell 不是一个终端。选择让你开心的一个。我在 Windows Terminal 使用 PowerShell Core 和 WSL2。 希望这篇文章有助于你弄清楚这些事情。","link":"/2020/07/18/%E7%BF%BB%E8%AF%91-%E6%8E%A7%E5%88%B6%E5%8F%B0%E3%80%81%E7%BB%88%E7%AB%AF%E5%92%8CShell%E7%9A%84%E5%8C%BA%E5%88%AB%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F/"},{"title":"船舶目标检测:使用Darknet训练yolo模型的过程记录","text":"船舶目标检测:使用Darknet训练yolo模型的过程记录 编译darknet其实早就了解过yolo，但是一直没时间（也可以说没动力，没分配时间）去试一下。放假了突然就想试一下目标检测。 谷歌查到了yolo作者的网站，讲的很详细，跟着做就完事了，非常简单。 只可惜我第一步就卡住了。 根据网站的描述，第一步是下载 darknet 的源码并执行 make 编译。但我用的是Windows系统，作者给的 darknet repo 似乎没提供 Windows 上编译的过程。 于是我又去查Windows下如何编译darknet，最后找到了 AlexeyAB/darknet，提供了在Windows和Linux的编译方法。 不过 AlexeyAB/darknet 的文档让我有一点点疑惑。它提供了使用 vcpkg 编译 darknet 的方法，但是它的步骤似乎多了很多多余的步骤： 123456789PS Code\\&gt; git clone https://github.com/microsoft/vcpkgPS Code\\&gt; cd vcpkgPS Code\\vcpkg&gt; $env:VCPKG_ROOT=$PWDPS Code\\vcpkg&gt; .\\bootstrap-vcpkg.batPS Code\\vcpkg&gt; .\\vcpkg install darknet[full]:x64-windows #replace with darknet[opencv-base,cuda,cudnn]:x64-windows for a quicker install of dependenciesPS Code\\vcpkg&gt; cd ..PS Code\\&gt; git clone https://github.com/AlexeyAB/darknetPS Code\\&gt; cd darknetPS Code\\darknet&gt; powershell -ExecutionPolicy Bypass -File .\\build.ps1 实际上，在 .\\vcpkg install darknet[full]:x64-windows 这一步就把 darknet 编译出来了。编译出来的 darknet.exe 在 vcpkg\\installed\\x64-windows\\tools\\darknet 里。 我花了很多时间在后面的那些指令上，因为最后一步的 powershell 脚本我执行的时候总是提示找不到 CUDA 编译器。 把编译的 powershell 脚本和 CMakeLists.txt 看了又看，改了又改，都没解决问题。 所以我只好倒回到 vcpkg 的步骤，检查 installed 文件夹，查看是不是哪些依赖没装好。 就这么巧合地发现 darknet.exe 躺在 tools 文件夹里。 我用的指令是作者推荐的 vcpkg install darknet[opencv-base,cuda,cudnn]:x64-windows。但是编译出来的 darknet 居然提示没有 opencv，不能直接显示预测图片，只能把预测结果保存到硬盘再查看。 vcpkg 编译的结果不满意，我只能再编译一次。 在找错的时候，我分析出这个 powershell 脚本就做了两件事： 通过 VCPKG_ROOT 环境变量找到 vcpkg.exe，然后使用 vcpkg 编译依赖，并且把编译结果放到 darknet 源码的根目录（而不是 vcpkg 的 installed 文件夹）。 执行 cmake，其中 CMakeLists.txt 就在 darknet 源码的根目录。 所以我决定绕过这个 powershell 脚本，直接用 CMake-GUI 来编译。 这个过程的步骤很多，但都是 CMake 的一些基本操作。 很顺利地成功了，没有什么找不到 CUDA 编译器的错误。 题外话：安装完 CUDA 后，我的 Visual Studio 2019 变得非常卡！一直在等待什么扩展的加载！看了下扩展菜单，多了个 Nsight 的菜单。我想把这个扩展禁用了，但是 VS 的扩展管理器里却找不到这个扩展。查了 VS 的社区论坛，似乎是 Nsight 的一个 BUG，但是没人提供解决方法，只是说和 VS 没关系。在 StackOverflow 里也遇到了同样的问题，一模一样，问题已经存在一个月了，但是没有任何答案。然后我就想到控制面板把整个 Nsight 给删掉试试看，发现了一项 Nsight Integration 很可疑。试着卸载它，发现问题就这样解决了。贡献了一个 StackOverflow 回答。 尝试训练自己的模型体验模型还是不够过瘾的，我更想试着训练出自己的模型。 我体验的模型是 PASCAL VOC 数据集的模型，都是人啊猫狗啊之类的常见对象。因为已经有了，所以这些对象我都没兴趣去训练了。 我最终决定去检测船舶，一个是这和我的专业有点关系，另一个是我找到了现成的数据集，不用自己标注了（重点）。 训练需要做的准备AlexeyAB/darknet 的 README 文件说的非常详细，一步一步地指导应该修改什么文件。 这里我做个简单的总结： 修改 yolov4-custom.cfg 文件, 让它符合你的需要（这一步会设置目标检测分类的数量和神经网络的大小等参数） 准备好训练用的数据集，包括图片和标注文件，图片和标注文件都放在同一个文件夹里。标注文件的文件名和图片的文件名一样，只是后缀是txt。标注文件用一个矩形描述对象所在的位置。 准备 train.txt 里面是图片的路径，一行一个。(相对于 darknet.exe 的相对路径) 准备 valid.txt 里面是图片的路径，同 train.txt，这里的图片用于验证。(不是必须) 准备 obj.names 文件，内容是分类的名字，一行一个。 准备 obj.data 文件，内容包括分类的数量、train.txt和valid.txt的路径、obj.names的路径和模型备份的目录路径。 训练的数据集训练用的数据集来自于论文 “Seaships: A large-scale precisely annotated dataset for ship detection” [1], 下载地址：SeqShips(7000).zip)。 包含六个分类：orecarrier, bulk cargo carrier, general cargo ship, container ship, fishing boat, and passenger ship。 数据集里的图片长这样： 都是来自航道监控的一些图片，很模糊。而且论文里说数据集有三万多张图，但是我只从作者的网站里下载到了 7000 张图片的数据集。 标注的格式转换数据集用的标注格式是 PASCAL VOL 的格式，就是一个图片对应一个XML文件。XML文件包含图片的大小、目标的分类和目标所在的矩形区域(左上角的点(Xmin,Ymin)和右下角的点(Xmax,Ymax)，即xmin,ymin,xmax,ymax共四个值)。 但是使用 darknet 进行训练，就要用 darknet 的标注格式。darknet的标注格式是一张图片对应一个txt文件，txt文件一行就是一个检测目标： 1&lt;object-class&gt; &lt;x&gt; &lt;y&gt; &lt;width&gt; &lt;height&gt; 所以要进行格式上的转换。 实际上，yolo作者的网站也是用darknet训练 PASCAL VOL 数据集，也提到了这个转换。而且yolo作者提供了这个转换的python程序。 稍微修改一下这个python程序，就能进行转换了。 训练模型按照 AlexeyAB/darknet 的文档，大概要训练 9000 iteration 会有比较好的结果。但实际上我训练了 300 iteration 就开始测试了。 300 迭代的结果就是，什么结果都没有，没有检测的框框。太心急了！ 500 迭代我又去测试，这次终于能检测到一些船舶了。但是个别数据集的图片还是没有结果。 评估模型完好程度的指标除了迭代次数，还有就是 darknet 的输出。 输出的内容里有一个指标是 IoU，它的含义是 检测的框框和标注的框框面积的交集 与 检测的框框和标注的框框面积的并集 的比值。 指标 IoU 的值介于 0~1，它越高，说明检测的结果与标注的结果越接近，一般来说 0.7 以上就是良好。 结合 AlexeyAB/darknet 文档中的图片能更好地理解 IoU，我就不浪费读者的时间了。 我的机器是一台办公笔记本，显卡是 MX150，训练速度非常慢，500 迭代大概花了三四个小时。 后来我又换 GTX 1660s 的台式机来训练，同样是三四个小时，能够达到 1300 迭代。 我的笔记本感觉要牺牲了，训练期间GPU保持在93℃。而且因为是第一次训练，经验不足，重来了几次，所以实际训练时间大概有五六个小时，这期间笔记本一直处于高温的状态，没让它休息。感觉电池鼓包更严重了，触控板都突出来了。 预测结果展示下面两张是训练数据集的预测结果，效果还比较理想。 下面这三张图片都是网上另外找的，不在训练数据集里： 船舶的位置确实是准确找出来了，但是分类几乎都是错的。这可能是因为迭代次数太少了，或者可能是训练数据集的图片太模糊了，船舶的特征不够明显。又或者，训练用的船都是内河船，测试用的船都是海船，外形差别有点大。 另外，这个模型对于竖着的船，很容易就检测不出来了。这可能是因为训练的数据集里的船都是横着的。 还有就是对于占图篇幅很大的船（离镜头很近），即使船舶是完整的，模型也容易识别不出来。这可能是因为数据集里的船都是离镜头很远的船，在图片里很小，训练出来的模型就不够自信了？ 总结挺好玩的，训练模型很吃配置，耗时间。 整个训练过程实际上最关键的一步是找到标注好的数据集，我自己是没有能力标注出那么多的图片的，很好地体会了 “人工智能时代，信息数据就是资源” 这句话。 参考文献 [1] Shao, Zhenfeng, et al. “Seaships: A large-scale precisely annotated dataset for ship detection.” IEEE transactions on multimedia 20.10 (2018): 2593-2604.","link":"/2021/02/13/%E8%88%B9%E8%88%B6%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B-%E4%BD%BF%E7%94%A8Darknet%E8%AE%AD%E7%BB%83yolo%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%BF%87%E7%A8%8B%E8%AE%B0%E5%BD%95/"},{"title":"超星学习通IM协议分析","text":"超星学习通IM协议分析。本文仅供学习交流。 超星学习通的课程签到任务，会第一时间以一条消息的形式发送到课程群聊中。如果能监听课程群聊的消息，就能在第一时间得到最新的签到任务。 当前的学习通自动签到程序，都采用轮询课程任务页面的方式获得课程签到任务。轮询的缺点很明显，频率过高会被反爬虫措施拦截，频率过低很容易错过签到。而监听课程群聊消息的方式，不需要轮询，效率高，灵敏度高，甚至可以做到“秒签到”的效果。（博主的一个实现：https://github.com/cyanray/cx-auto-sign） 接下来简单分析一下超星学习通的IM协议。 从 Android 端进行分析是比较复杂的，尤其是高版本的 Android 系统，因为证书信任的问题，抓包变得非常困难。 在超星学习通的网页端找了找，很幸运找到了 Web 版本的IM客户端：https://im.chaoxing.com/webim/me 有网页版本的话，工作就轻松多了。按下 F12，打开开发人员工具慢慢分析。 注意到这个页面有个 WebSocket 连接。(如图)在有新消息到达时，这个 WebSocket 连接都会有相应的数据包到达。而且新消息的内容越长，到达的数据包尺寸越大。 所以可以猜测超星学习通的IM协议是基于 WebSocket 协议的。 先不急分析数据包的具体含义，我先去看了看这个 Websocket 的发起程序。发现调用堆栈中最开头有个函数叫 loginByToken。这说明超星的IM协议存在登录部分，而且可以通过一种 Token 登录。 继续分析 loginByToken 函数所在的文件 im-base.js。可以发现这个文件注释齐全，代码规范，逆向分析er大喜。 可以发现里面还有一个 login 函数，参数是用户名和密码，这说明这个IM协议可能还可以直接用账号密码登录。（虽然没什么用） loginByToken 函数的定义如下： 1234567891011121314151617181920/** * token登录 * * @param username * @param token */var evenName, evenToken;function loginByToken(username, token) { evenName = username; evenToken = token; var options = { apiUrl : WebIM.config.apiURL, user : String(username), accessToken : String(token), appKey : WebIM.config.appkey }; conn.open(options); callBack(); init();} 从这个函数可以了解到要建立这个 WebSocket 连接需要的一些参数。 打个断点，刷新页面，就能看到这些参数的具体内容。搜索之后发现，这些参数基本都能在网页源代码里找到。 继续分析，实际发起 WebScoket 连接的文件是 websdk3.1.4.js。从这个文件的 url (https://im.chaoxing.com/res/plugin/HuanXinIm/sdk/websdk3.1.4.js) 发现关键词 HuanXinIm。百度之后发现是环信IM。原来超星学习通的IM服务是环信IM提供的。 然而环信IM没有提供 dotnet sdk。因此只能继续逆向分析出协议，自己实现了。 返回去分析 WebSocket 的数据包，有个别包以“==”结尾，猜测是 base64 编码。找个解码工具解码看看内容。 几乎是明文的。 图中圈起来的内容分别是：AppKey，uid，固定字符串，环信IM的ID，登录用的Token。 篇幅有限，更多的细节就不再分析了。","link":"/2020/11/16/%E8%B6%85%E6%98%9F%E5%AD%A6%E4%B9%A0%E9%80%9AIM%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90/"},{"title":"花","text":"花","link":"/2021/10/11/%E8%8A%B1/"},{"title":"运动手环的使用体验","text":"我想买个运动手环来检测、记录我的睡眠情况。但是小米手环5已经出了很久了，想着买新不买旧，一直在等小米手环6的发布。结果小米手环6的厚下巴在“跑马屏”下显得十分不和谐，再加上很多人评价说睡眠监测的结果不准确，因此我最终买了荣耀手环6。 屏幕和表盘先看看外观图。 很多人评价小米手环的窄屏幕才是手环的样子，荣耀手环的宽屏幕已经接近于手表了。但是我作为一个普通用户，并不想管手环和手表的准确定义，我只考虑用起来的实际体验。 荣耀手环的大屏幕真的很有优势，能显示的内容很多。在这个价值￥6的表盘下，常用的数据几乎同时显示了出来。 为什么我要强调这个表盘的价格呢？因为荣耀的表盘市场里免费的表盘真的好少，收费表盘的居多。相比之下，小米手环的免费表盘似乎丰富得多。（云体验，从别人的截图感受到的） 睡眠检测 睡眠检测其实是可以检测到各个睡眠周期的，也就是快速眼动、浅睡眠和深睡眠这三个睡眠周期，截图里没有体现出来。 我没法验证睡眠周期的检测准不准，但是入睡时间的检测我感觉还是准的。 比如截图里有 3 条零星小睡的记录，第一条记录是因为我感冒了，觉得很困，我上课趴着睡觉给检测到了。 这条记录被手环记录下来，我还是蛮震惊的。因为我听说手环检测睡眠的原理是检测手臂的运动，运动的幅度小就认为是睡着了。然而我趴着睡的时候，其实并不稳当，因为我旁边的同学一直在拍桌子，我也一直在晃。 第二条和第三条记录是我逃课回寝室睡的，中途醒来了一次，也被检测到了，分成了两条记录。 运动检测自动运动检测需要在手环设置里开启，默认是不开启的。开启之后，如果手环检测到你在运动，会弹出提示询问你是否真的在运动。确认之后，就会记录这一次运动。 这里有一个比较人性化的设计。我一开始是不知道还有个确认运动的环节的，我跑步中途才发现手环有这个提示。我本以为确认之前的跑步数据会丢失。没想到的是，手环没有丢掉确认之前的运动数据，我从开始跑步到确认运动的数据都还留着（从里程数能看出来）。 其他买来手环的前几天，每天起床的第一件事就是看晚上的睡眠质量如何，但是很快就懒得看了。我的睡眠习惯和运动习惯也没因为它变得更好。毕竟手环只是记录，要改变习惯还得看我自己。","link":"/2021/04/20/%E8%BF%90%E5%8A%A8%E6%89%8B%E7%8E%AF%E7%9A%84%E4%BD%BF%E7%94%A8%E4%BD%93%E9%AA%8C/"},{"title":"随着音乐跳动的电平灯","text":"随着音乐跳动的电平灯 Your user agent does not support the HTML5 Video element. 淘宝买套件做的，并不懂原理。做这个完全是电烙铁玩了个爽。看到最终的效果虽然什么都不懂也很开心。","link":"/2020/03/28/%E9%9A%8F%E7%9D%80%E9%9F%B3%E4%B9%90%E8%B7%B3%E5%8A%A8%E7%9A%84%E7%94%B5%E5%B9%B3%E7%81%AF/"},{"title":"运用快速幂算法求解递推式的第N项","text":"将递推式转化为矩阵式，并使用矩阵快速幂算法求解矩阵幂运算，从而解得原递推式的第N项值。 算法题目这是一道来自蓝桥杯的题目。问题描述已知递推式： \\begin{aligned} F(n,1) &= F(n-1,2) + 2F(n-3,1) + 5 \\\\\\\\ F(n,2) &= F(n-1,1) + 3F(n-3,1) + 2F(n-3,2) + 3 \\end{aligned}初始值为：\\( F(1,1) = 2 \\) , \\( F(1,2) = 3 \\) , \\( F(2,1) = 1 \\) , \\( F(2,2) = 4 \\) , \\( F(3,1) = 6 \\) , \\( F(3,2) = 5 \\)。输入 \\( N \\)，输出 \\( F(n,1) \\) 和 \\( F(n,2) \\) ，由于答案可能很大，你只需要输出答案除以 99999999 的余数。输入格式输入第一行包括一个整数 \\( N \\)。输出格式输出两行，第一行为 \\( F(n,1) \\) 除以 99999999 的余数，第二行为 \\( F(n,2) \\) 除以 99999999 的余数。样例输入4样例输出1421数据规模和约定\\( 1 \\leqslant N \\leqslant 10^{18} \\) 问题分析&emsp;&emsp;这个题目数据量很大，如果是简单地递归，肯定会栈溢出或者超时。即使把递归改成循环，也只能避免栈溢出，难逃超时的命运。&emsp;&emsp;递推式主要涉及加法运算，必须从头到尾把每一项都计算出来才可以得到答案，很难再做出优化。将递推式改为矩阵式，则涉及到矩阵的幂运算，而幂运算可以用 快速幂算法 优化，只需做 log(N) 次乘法运算就可以得到答案。 斐波那契数列的矩阵式&emsp;&emsp;我没有找到这个题目矩阵式推导的详细过程，所以只能自己琢磨。我知道一个很经典的递推式子，即斐波那契数列的递推式。研究怎么推导斐波那契数列的矩阵式，也许就能知道怎么推导这个蓝桥杯题目中的递推式的矩阵式。&emsp;&emsp;以下是我整理的斐波那契数列矩阵式的推导过程。 已知斐波那契数列的递推式 F_n = F_{n-1} + F_{n-2} \\quad n \\geqslant 2 \\tag{1} \\label{1}初始值为 F_0 = 0, \\quad F_1 = 1设有矩阵 \\( M \\)，使得下式成立 \\begin{bmatrix} F_n \\\\\\\\ F_{n-1} \\end{bmatrix} = M \\begin{bmatrix} F_{n-1} \\\\\\\\ F_{n-2} \\end{bmatrix} \\tag{2} \\label{2}不妨设矩阵 \\( M \\)为 M = \\begin{bmatrix} A&B \\\\\\\\ C&D \\end{bmatrix}则由公式 \\( \\eqref{2} \\) 可得 \\begin{aligned} F_n &= AF_{n-1} + BF_{n-2} \\\\\\\\ F_{n-1} &= CF_{n-1} + DF{n-2} \\end{aligned}显然，\\( C=1,D=0 \\)。由公式 \\( \\eqref{1} \\) 可知 \\( A = B = 1 \\)。所以矩阵 \\( M\\) 为 M = \\begin{bmatrix} 1&1 \\\\\\\\ 1&0 \\end{bmatrix}于是公式 \\( \\eqref{2} \\) 可以写为 \\begin{bmatrix} F_n \\\\\\\\ F_{n-1} \\end{bmatrix} = \\begin{bmatrix} 1&1 \\\\\\\\ 1&0 \\end{bmatrix} \\begin{bmatrix} F_{n-1} \\\\\\\\ F_{n-2} \\end{bmatrix}将 \\( F{n-1},F{n-2} \\) 部分也替换为矩阵式，则有 \\begin{bmatrix} F_n \\\\\\\\ F_{n-1} \\end{bmatrix} = \\begin{bmatrix} 1&1 \\\\\\\\ 1&0 \\end{bmatrix} ^2 \\begin{bmatrix} F_{n-2} \\\\\\\\ F_{n-3} \\end{bmatrix}进一步可以得到斐波那契数列的矩阵式 \\begin{bmatrix} F_n \\\\\\\\ F_{n-1} \\end{bmatrix} = \\begin{bmatrix} 1&1 \\\\\\\\ 1&0 \\end{bmatrix} ^{n} \\begin{bmatrix} F_1 \\\\\\\\ F_0 \\end{bmatrix}\\ = \\begin{bmatrix} 1&1 \\\\\\\\ 1&0 \\end{bmatrix} ^{n} \\begin{bmatrix} 1 \\\\\\\\ 0 \\end{bmatrix} \\tag{3} \\label{3}快速幂算法&emsp;&emsp;使用矩阵式来计算斐波那契数列的第 \\( n \\) 项，关键在于计算矩阵 \\( M \\) 的 \\( n \\) 次方。&emsp;&emsp;最简单地方法是连续做 \\( n-1 \\) 次乘法。考虑到这里其实是对矩阵进行幂运算，所以可以使用一种叫 快速幂 的算法来加速运算，只需要做 log(N) 次乘法运算就能得到结果。 &emsp;&emsp;快速幂算法的思想是，把指数部分用 二进制 表示，分割出更小的任务。&emsp;&emsp;举个例子(这里直接使用了 OJ-Wiki.org 中的例子) 3^{13} = 3^{(1101)_2} = 3^{(2^3 \\cdot 1 + 2^2 \\cdot 1 + 2^1 \\cdot 0 + 2^0 \\cdot 1)} = 3^8 \\cdot 3^4 \\cdot 3^1 \\tag{1} \\label{11}&emsp;&emsp;因为 \\( n \\) 有 \\( \\lfloor \\log_2 n \\rfloor + 1 \\) 个二进制位，因此当知道了 \\( a^1,a^2,a^4,a^8,\\cdots,a^{2 \\lfloor \\log_2 n \\rfloor} \\)后，就可以只计算 \\( \\Theta(\\log n) \\) 次乘法得到 \\( a^n \\)。 &emsp;&emsp;由等式 \\( \\eqref{11} \\) 可知，要计算 \\( 3^{13} \\)，只需要将指数对应二进制位为 \\( 1 \\) 的整系数幂乘起来就可以了。 &emsp;&emsp;循环求整数快速幂的代码实现123456789101112long long binpow(long long a, long long b) { long long res = 1; while (b &gt; 0) { // 如果当前二进制位为1，把系数幂乘进答案 if (b &amp; 1) res = res * a; // 求a^n a = a * a; // 整体右移，则最低位为下一个二进制位 b &gt;&gt;= 1; } return res;}&emsp;&emsp;对于矩阵的快速幂算法，只需要把 long long 替换为自己的矩阵类，把整数乘法替换为矩阵乘法，把 res 的初始值替换为单位矩阵就可以了。&emsp;&emsp;未完全实现的矩阵快速幂：1234567891011121314151617// 矩阵类为简单实现，都为 maxn X maxn 的方阵const int maxn = 8;// 矩阵快速幂Matrix quickPow(Matrix M, int e){ // 初始化ans为单位矩阵，eye()返回一个单位矩阵 Matrix ans = eye(),base = M; // 快速幂运算 while (e &gt; 0) { // MatrixMul 是对两个矩阵做乘法运算的函数 if (e &amp; 1) ans = MatrixMul(ans, base); base = MatrixMul(base, base); e &gt;&gt;= 1; } return ans;} &emsp;&emsp;有了矩阵快速幂算法，那么使用矩阵式来计算斐波那契数列的第 N 项已经不是问题了。 题目的矩阵式推导&emsp;&emsp;回到最开始的题目。题目中的递推式比斐波那契数列的递推式复杂的多，但是推导它的矩阵式并没有难多少。同样地，假设存在矩阵 \\( M \\)，使得下式成立 \\begin{bmatrix} F(n,1) \\\\\\\\ F(n,2) \\\\\\\\ F(n-1,1) \\\\\\\\ F(n-1,2) \\\\\\\\ F(n-2,1) \\\\\\\\ F(n-2,2) \\\\\\\\ 5 \\\\\\\\ 3 \\\\\\\\ \\end{bmatrix} = M \\begin{bmatrix} F(n-1,1) \\\\\\\\ F(n-1,2) \\\\\\\\ F(n-2,1) \\\\\\\\ F(n-2,2) \\\\\\\\ F(n-3,1) \\\\\\\\ F(n-3,2) \\\\\\\\ 5 \\\\\\\\ 3 \\\\\\\\ \\end{bmatrix} \\tag{1} \\label{21}(注意：因为原 递推式 的右边存在 \\( F(n-1,1),F(n-1,2),F(n-3,1),F(n-3,2),5,3 \\) ，所以矩阵式的右边也会出现它们，将矩阵式右边的下标统统加 1，就得到了矩阵式的左边。) 设 \\( M \\) 为 M = \\begin{bmatrix} a_{11} & a_{12} & \\cdots\\ & a_{18} \\\\\\\\ a_{21} & a_{22} & \\cdots\\ & a_{28} \\\\\\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\\\\\ a_{81} & a_{82} & \\cdots\\ & a_{88} \\\\\\\\ \\end{bmatrix}由等式 \\( \\eqref{21} \\) 可得一系列关系式，再结合递推式，可得矩阵 \\( M \\)为 M = \\begin{bmatrix} 0&1&0&0&2&0&1&0 \\\\\\\\ 1&0&0&0&3&2&0&1 \\\\\\\\ 1&0&0&0&0&0&0&0 \\\\\\\\ 0&1&0&0&0&0&0&0 \\\\\\\\ 0&0&1&0&0&0&0&0 \\\\\\\\ 0&0&0&1&0&0&0&0 \\\\\\\\ 0&0&0&0&0&0&1&0 \\\\\\\\ 0&0&0&0&0&0&0&1 \\\\\\\\ \\end{bmatrix}……(懒得写推导过程了，和斐波那契数列真的几乎一样) 附上这一题的解题代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105#include &lt;bits/stdc++.h&gt;using namespace std;#define int int64_tconst int mod = 99999999ll;const int maxn = 8;struct Matrix{ int M[maxn][maxn] = { 0 };};// 普通矩阵乘法Matrix MatrixMul(Matrix A, Matrix B){ Matrix tM; for (int i = 0; i &lt; maxn; i++) for (int j = 0; j &lt; maxn; j++) { for (int k = 0; k &lt; maxn; k++) { tM.M[i][j] += ( (A.M[i][k])%mod * (B.M[k][j])%mod )%mod; } tM.M[i][j] %= mod; } return tM;}// 矩阵快速幂Matrix quickPow(Matrix M, int e){ Matrix ans,base = M; // 初始化ans为单位矩阵 for (int i = 0; i &lt; maxn; i++) { for (int j = 0; j &lt; maxn; j++) { if (i == j) ans.M[i][j] = 1; } } while (e) { if (e &amp; 1) ans = MatrixMul(ans, base); base = MatrixMul(base, base); e &gt;&gt;= 1; } return ans;}signed main(){ int T[maxn][maxn] = { {0,1,0,0,2,0,1,0}, {1,0,0,0,3,2,0,1}, {1,0,0,0,0,0,0,0}, {0,1,0,0,0,0,0,0}, {0,0,1,0,0,0,0,0}, {0,0,0,1,0,0,0,0}, {0,0,0,0,0,0,1,0}, {0,0,0,0,0,0,0,1} }; int P[maxn] = { 6,5,1,4,2,3,5,3 }; int S1 = 2, S2 = 1, S3 = 6; // F(x,1) 用 int V1 = 3, V2 = 4, V3 = 5; // F(x,2) 用 Matrix M, ans; memcpy(&amp;M.M, T, sizeof(M.M)); int N; cin &gt;&gt; N; if (N == 1) { cout &lt;&lt; S1 &lt;&lt; endl &lt;&lt; V1 &lt;&lt; endl; return 0; } if (N == 2) { cout &lt;&lt; S2 &lt;&lt; endl &lt;&lt; V2 &lt;&lt; endl; return 0; } if (N == 3) { cout &lt;&lt; S3 &lt;&lt; endl &lt;&lt; V3 &lt;&lt; endl; return 0; } ans = quickPow(M, N - 3); // 矩阵式从n&gt;=4开始 int Fn1 = 0, Fn2 = 0; for (int i = 0; i &lt; maxn; i++) { Fn1 += (ans.M[0][i]%mod * P[i]%mod)%mod; Fn2 += (ans.M[1][i]%mod * P[i]%mod)%mod; } cout &lt;&lt; Fn1%mod &lt;&lt; endl; cout &lt;&lt; Fn2%mod &lt;&lt; endl; return 0;} 参考文献[1] 快速幂 - OI Wiki. https://oi-wiki.org/math/quick-pow/","link":"/2020/01/30/%E8%BF%90%E7%94%A8%E5%BF%AB%E9%80%9F%E5%B9%82%E7%AE%97%E6%B3%95%E6%B1%82%E8%A7%A3%E9%80%92%E6%8E%A8%E5%BC%8F%E7%9A%84%E7%AC%ACN%E9%A1%B9/"},{"title":"青果教务系统APP网络协议加密算法分析","text":"本文仅供学习交流，严禁用于非法用途，请于24小时内遗忘。 抓包分析接上一篇文章成功逆向该 App 之后，开始分析其网络协议部分。这个 App 的网络部分非常有趣，数据请求是基于 HTTP 协议的，但是所有的数据查询请求的 URL 都是同一个。不仅如此，从这个 POST 请求的数据部分可以看出，请求的参数都被一种算法加密过了。 几乎所有请求都只有这四个参数，而且都发给了同一个 URL。很显然，真正的查询参数都被加密藏在这些参数里了。从命名来看，参数 token 应该是用来识别区分用户的，不过请求中也包含了 cookie ，而且 cookie 的内容和 token 不一样，所以还不好下结论，万一是用 cookie 来区分用户的呢。参数 param 和 param2 应该就是真正的查询参数了，可惜是被加密的密文，而且还看不出是什么加密算法。参数 appinfo 的内容是这个程序的版本号。 反编译分析从反编译出来的代码中搜索 URL，找出和 HTTP 请求有关的代码。我是从登录的请求开始分析的，因为登录的前后有很多很多的流程，分析这些流程有助于梳理程序的逻辑。 这个 App 是经过混淆处理的，给分析增加了很多的难度。分析的过程我就不写了，其实就是阅读代码，因为很多变量名称、函数名称都没了，所以需要自己寻找各个变量、函数的含义，最终找到和加密有关的函数。 下面这个函数是构建请求参数的函数： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public static Map&lt;String, String&gt; m11985a( Map&lt;String, String&gt; map, // 原始参数字典 boolean z, // 未知 flag 猜测：是否已登录 Context context) { // ? String str; String a = Version.m1233a(context); // 返回 yt6n78 猜测是密钥 String str2 = &quot;&quot;; for (Map.Entry next : map.entrySet()) { String trim = ((String) next.getKey()).trim(); if (next.getValue() == null) { str = &quot;&quot;; } else { str = (String) next.getValue(); } LogUtil.m11834a(str.length() + &quot;&quot;); str2 = str2 + &quot;&amp;&quot; + trim + &quot;=&quot; + str; } // 如果z==true，就加上 sfid 和 uuid 参数 if (z) { str2 = (str2 + &quot;&amp;sfid=&quot; + InterfaceTools.f17467a.userid) + &quot;&amp;uuid=&quot; + InterfaceTools.f17467a.uuid; } // 去除开头的 &amp; 字符 if (str2.indexOf(&quot;&amp;&quot;) == 0) { str2 = str2.substring(1); } // 构建加密后的字典 HashMap hashMap = new HashMap(); try { MyLog.m11863a(&quot;as_str=&quot;, str2); // param 来自这里 hashMap.put(&quot;param&quot;, m11979a(str2, a)); // param2 来自这里 hashMap.put(&quot;param2&quot;, m11996f(str2)); if (z) { hashMap.put(&quot;token&quot;, InterfaceTools.f17467a.token); hashMap.put(&quot;appinfo&quot;, Version.m1234b(context)); } else { hashMap.put(&quot;token&quot;, &quot;00000&quot;); hashMap.put(&quot;appinfo&quot;, Version.m1234b(context)); } return hashMap; } catch (Exception unused) { hashMap.put(&quot;param&quot;, &quot;error&quot;); hashMap.put(&quot;param2&quot;, &quot;error&quot;); if (z) { hashMap.put(&quot;token&quot;, &quot;error&quot;); hashMap.put(&quot;appinfo&quot;, Version.m1234b(context)); } return hashMap; }} 其中最关键的是这两行： 1234// param 来自这里hashMap.put(&quot;param&quot;, m11979a(str2, a)); // param2 来自这里hashMap.put(&quot;param2&quot;, m11996f(str2)); 参数 param 是由 m11979a 这个函数生成的，所以进一步去分析这个函数。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public static String m11979a(String str, String str2) { if (str != null) { String str3 = &quot;&quot;; if (!str3.equals(str) &amp;&amp; str2 != null &amp;&amp; !str3.equals(str2)) { int length = str2.length(); int length2 = str.length(); double d = (double) length2; int ceil = (int) Math.ceil((1.0d * d) / ((double) length)); int ceil2 = (((int) Math.ceil((((d * 3.0d) * 6.0d) / 9.0d) / 6.0d)) * 6) % length; int i = 0; String str4 = str3; for (int i2 = 0; i2 &lt; ceil; i2++) { for (int i3 = 1; i3 &lt;= length; i3++) { int i4 = (i2 * length) + i3; String substring = str.substring(i4 - 1, i4); String substring2 = str2.substring(i3 - 1, i3); String str5 = &quot;000&quot; + String.valueOf( Integer.valueOf(m11997g(substring)).intValue() + Integer.valueOf(m11997g(substring2)).intValue() + ceil2); str4 = str4 + str5.substring(str5.length() - 3, str5.length()); if (i4 == length2) { break; } } } while (i &lt; str4.length()) { int i5 = i + 9; String substring3 = str4.substring(i, i5 &gt;= str4.length() ? str4.length() : i5); String str6 = &quot;000000&quot; + m11977a(Long.valueOf(substring3).longValue()); str3 = str3 + str6.substring(str6.length() - 6, str6.length()); i = i5; } return str3; } } return str;}// 每个字符用逗号隔开public static String m11997g(String str) { StringBuffer stringBuffer = new StringBuffer(); char[] charArray = str.toCharArray(); for (int i = 0; i &lt; charArray.length; i++) { if (i != charArray.length - 1) { stringBuffer.append(charArray[i]); stringBuffer.append(&quot;,&quot;); } else { stringBuffer.append(charArray[i]); } } return stringBuffer.toString();}// 将整数 j 用36进制表示private static String m11977a(long j) { m11986a(); if (j &lt; 0) { return &quot;-&quot; + m11977a(Math.abs(j)); } String str = &quot;&quot;; do { // f17428a 的值是：0123456789abcdefghijklmnopqrstuvwxyz String ch = f17428a.get(Integer.valueOf((int) (j % 36))).toString(); if (&quot;&quot;.equals(str)) { str = ch; } else { str = ch + str; } j /= 36; } while (j &gt; 0); return str;} 实践证明，函数 m11979a 确实是用来计算参数 param 的，但是这段反编译出来的代码其实是有问题的，不能直接用。 问题出在这一段： 12345String str5 = &quot;000&quot; + String.valueOf( Integer.valueOf(m11997g(substring)).intValue() + Integer.valueOf(m11997g(substring2)).intValue() + ceil2); 函数 m11997g 的作用是用逗号将字符串的每一个字符分开，比如m11997g(&quot;ABC&quot;)的结果是&quot;A,B,C&quot;，是一个字符串。而反编译出来的代码却对一个非数字字符串使用Integer.valueOf()，这是不符合逻辑的。如果 substring 和 substring2 是形如&quot;123543&quot;这样的数字字符串，那还是说得通的。但是 substring 和 substring2 的内容并不总是数字，大多数情况下是英文字符，很显然无法将英文解析成数字。 分析这一段的时候，简直怀疑人生，以为自己看漏了什么代码。后来实在没办法，其他代码里也找不到新的线索，我就猜测这两行是取 substring 和 substring2 第一个字符的 ASCII 码。按照这个思路重新实现这段代码，居然成功获得了加密的字符串。 以下是使用 C# 重新实现后的 param1 的计算算法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354static string charTable = &quot;0123456789abcdefghijklmnopqrstuvwxyz&quot;;private static string m11977a(long j){ if (j &lt; 0) { return &quot;-&quot; + m11977a(Math.Abs(j)); } var result = new StringBuilder(); do { string ch = charTable[(int)(j % 36)].ToString(); result.Insert(0, ch); j /= 36; } while (j &gt; 0); return result.ToString();}public static string CalcParam1(string str, string str2){ if (string.IsNullOrEmpty(str) || string.IsNullOrEmpty(str2)) return str; int length1 = str.Length; int length2 = str2.Length; int ceil = (int)Math.Ceiling((1.0d * length1) / ((double)length2)); int ceil2 = ((int)Math.Ceiling(length1 * 3.0d * 6.0d / 9.0d / 6.0d)) * 6 % length2; string str4 = string.Empty; for (int i2 = 0; i2 &lt; ceil; i2++) { for (int i3 = 1; i3 &lt;= length2; i3++) { int i4 = (i2 * length2) + i3; string substring = str.Substring(i4 - 1, 1); string substring2 = str2.Substring(i3 - 1, 1); string str5 = &quot;000&quot; + (substring[0] + substring2[0] + ceil2).ToString(); str4 = str4 + str5.Substring(str5.Length - 3); if (i4 == length1) { break; } } } var result = new StringBuilder(); int i = 0; while (i &lt; str4.Length) { int i5 = i + 9; int len = Math.Min(str4.Length, i5) - i; string substring3 = str4.Substring(i, len); string val = m11977a(Convert.ToInt64(substring3)); string str6 = $&quot;000000{val}&quot;; result.Append(str6.Substring(str6.Length - 6)); i = i5; } return result.ToString();} 关于计算 param2 的函数，我没有仔细地研究，因为它在请求中似乎没有作用，我保持 param2 不变发送不同的请求依然能得到正确的回应。 结论反编译出来的代码未必是正确的，还是得猜一下代码。","link":"/2020/08/21/%E9%9D%92%E6%9E%9C%E6%95%99%E5%8A%A1%E7%B3%BB%E7%BB%9FAPP%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/"},{"title":"默认构造函数的构造行为","text":"编译器在什么时候会创造默认构造函数？会如何创造构造函数？（《深度探索C++对象模型》读书笔记） 默认构造函数 (Default Constructor)在《Effective C++》这本书有提到，C++编译器会在没有声明定义任何构造函数的情况下为 class 生成一个构造函数。在《深度探索C++对象模型》这本书里，对编译器何时生成构造函数做了更详细的讨论。(有很多词语这本书的译者都没有翻译，我觉得这个做法挺好，避免了歧义和不必要的解释。这篇笔记也仿照这种方法，一些词不做翻译，混入大量英文。) 默认构造函数可以认为有两种，一种是 trivial（浅薄而无能，没什么用的） constructor ，一种是 nontrivial constructor。如果一个类的成员全都是内建类型（built-in type），也就是没有任何成员对象，那么产生的 default constructor 就是 trivial constructor。因为由编译器产生的 default constructor 是不会自动初始化内建类型的成员的，所以这个由编译器产生的构造函数其实什么都没做。 而 nontrivial constructor 会在编译器需要的时候被编译器产生出来。对于下面这一段代码，Foo 没有构造函数，程序也需要 bar’s members 都被清零，但是编译器不会为 Foo 生成默认构造函数。因为这里的需要，指的是编译器的需要，而不是程序员的需要。程序员的需要，应该由程序员来保证，这里应该让 class Foo 的作者负责。 123456789class Foo { public: int val; Foo *pnext; };void foo_bar(){ // 程序要求 bar's members 都被清零 Foo bar; if (bar.val || bar.pnext) // do something} 有 4 种情况会产生 nontrivial constructor： 类中有一个或多个成员对象（即Member Class Object），并且它们都有 Default Constructor 派生自某个基类，并且该基类带有 Default Constructor 该类带有 Virtual Function 该类虚继承于基类(A Class with Virtual Base Class) 第 1 种情况和第 2 种情况强调了成员对象或基类都要有 Default Constructor，如果没有，是无法通过编译的。（不展开，需要理解）当然，成员对象或基类的 Default Constructor，并没有限制必须是用户声明的（user-declared），也可以是编译器生成的。 “带有 Default Constructor” 的 Member Class Object如果 class 中有一个 member object，并且没有写任何构造函数，那么出于初始化这个 member object 的需要，编译器会生成一个 Default Constructor来初始化这个 member object。此时编译器生成的 Default Constructor 显然不是 trivial constructor，因为它确实做了一些工作，即初始化 member object。 1234567class Foo { public: Foo(); };class Bar { public: Foo foo; char *str; }void foo_bar{ Bar bar; // Bar::foo 是一个 member object，需要在此处被初始化} 对于上面这个例子，编译器生成的 Default Constructor 可能看起来是这样的： 1234inline Bar::Bar(){ foo.Foo::Foo();} 生成的 Default Constructor 完成了对 foo 的初始化需要。当然，没有对 str 进行初始化，因为初始化 str 不是编译器的需要。如果程序对初始化 str 有需要，那么应该请程序员来初始化 str。 题外话：上面这一段代码中出现的 inline，不是为了什么优化。如果有多个翻译单元，编译器可能会为每个翻译单元都合成一个 Default Constructor，链接器就没法完成链接了。（不知道现代C++编译器会怎么处理，这是书上的说法） 程序确实对初始化 str 有需要，于是程序员写了如下默认构造函数： 1Bar::Bar() { str = 0; } 现在程序的需要满足了，但是编译器的需要却没有满足。编译器还需要初始化 member object foo。由于现在已经有一个构造函数了，编译器没法再生成第二个。在这种情况下，编译器的行为是：对现有的每一个构造函数进行扩张，在其中安插一些代码，使得 user code 被执行前，完成对 member object 的初始化。 延续上一个例子，扩张后的 constructor 可能像这样： 12345Bar::Bar() { foo.Foo::Foo(); // 编译器扩张的代码 str = 0; // user code} 上面只讨论了一个 member object 的情况。如果有多个 member objects，编译器的行为是差不多的，编译器会按照声明顺序对每一个 member object 完成初始化。 “带有 Default Constructor” 的 Base Class编译器的行为与 “带有 Default Constructor” 的 Member Class Object 类似。编译器会创造或扩张 Constructor，从而满足对 Base Class 的初始化需求。 “带有一个 Virtual Function”的 Class如果有 virtual function，编译器会创建一个虚表(virtual function table)，用于存放 class 的 virtual funtions 地址。 此外，编译器会给 class object 额外加入一个 pointer member 指向虚表。 这个时候由编译器产生的 Default Constructor 也是 nontrivial constructor，因为需要对虚表和额外加入的 pointer member 进行初始化。 “带有一个 Virtual Base Class”的 Class和 “带有一个 Virtual Function”的 Class 的情况差不多，编译器为了实现运行时多态，会加入一些东西，并需要对加入的东西完成初始化。 // 未完待续…","link":"/2020/07/19/%E9%BB%98%E8%AE%A4%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0%E7%9A%84%E6%9E%84%E9%80%A0%E8%A1%8C%E4%B8%BA/"},{"title":"青果教务系统安卓APP(喜鹊儿)逆向分析","text":"本文仅供学习交流，请勿用于违法用途。 博主第一次尝试 APK 逆向，以下分析内容针对 v2.6.109 版本的APP。 基本分析首先是基本操作，使用 apktool 解压得到 classes.dex，然后使用 dex2jar 将 classes.dex 转化为 jar 文件，再使用 jd-gui 打开 jar 文件，查看反编译出来的代码。反编译结果如下图所示。 看到代码的第一反应是惊讶与疑惑，这代码也太少太简单了吧！我以为是反编译的结果不对，又使用 jadx-gui 打开这个 dex 文件。结果如下图所示。 可以看出两个软件反编译的结果是一样的，也就是反编译的结果是没有问题的。使用文本搜索搜索了下一些文本，但是都找不到。很显然，这个 APP 真正的代码并没有被反编译出来。那么真正的代码都藏在了哪里呢？ 查阅了一些有关 APK 加固的文章，一种识别 APK 被加固的方式是查看反编译出来的源代码的包名。比如有 tencent 字样，那么多半是腾讯的加固。这个 APP 反编译出来的源代码里确实有 alibaba 的字样，但是这个只是 fastjson 库的包名。结合网上的逆向资料来看，这也不像 alibaba 加固后的样子。 这个时候，我猜测这是一种自制的加固方式。浏览反编译出来的代码，里面的”AESEncrypt“、”ApplicationProxy“、”RefInvoke“ 和 ”SecurityUtils“ 让我更相信这个 APP 被加固了。 于是我开始仔细阅读里面的源代码，不久我就找到了一个很可能是突破口的函数。这是一个叫做 ”readDexFromApk“ 的函数，它的定义如下： 12345678910111213141516171819202122public byte[] readDexFromApk() throws IOException { ByteArrayOutputStream dexByteArrayOutputSteam = new ByteArrayOutputStream(); System.out.println(getApplicationInfo().sourceDir); ZipInputStream localZipInputStream = new ZipInputStream(new BufferedInputStream(new FileInputStream(getApplicationInfo().sourceDir))); while (true) { ZipEntry localZipEntry = localZipInputStream.getNextEntry(); if (localZipEntry == null) { localZipInputStream.close(); localZipInputStream.close(); return dexByteArrayOutputSteam.toByteArray(); } else if (localZipEntry.getName().equals(&quot;classes.dex&quot;)) { byte[] arrayOfByte = new byte[1024]; while (true) { int i = localZipInputStream.read(arrayOfByte); if (i == -1) { break; } dexByteArrayOutputSteam.write(arrayOfByte, 0, i); } } }} 这段代码没有被混淆过，可读性很好。这段代码的大意是解压自己这个 apk 文件，逐个分析 apk 里面的文件，如果有名为 classes.dex 的文件，那么就读取这个 dex 文件的所有内容，最后返回读取到的内容。 这个函数被一个叫 multiThread 的函数调用。它的代码如下： 这个函数很长，建议读者先往下读我对它的拆解分析，然后再回头阅读这个函数的代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354private void multiThread(String primaryDexDir) { try { byte[] data = readDexFromApk(); int shellDexLen = data.length; byte[] dexFileCommentLenByte = new byte[4]; System.arraycopy(data, shellDexLen - 4, dexFileCommentLenByte, 0, 4); int dexFileCommentLen = new DataInputStream(new ByteArrayInputStream(dexFileCommentLenByte)).readInt(); byte[] dexFileCommentByte = new byte[dexFileCommentLen]; System.arraycopy(data, (shellDexLen - 4) - dexFileCommentLen, dexFileCommentByte, 0, dexFileCommentLen); String dexFileComment = new String(dexFileCommentByte); LogUtils.m3d(&quot;dex comment:&quot; + dexFileComment); ArrayList&lt;DexFile&gt; dexFileArrayList = (ArrayList) JSON.parseArray(dexFileComment, DexFile.class); int currentReadEndIndex = (shellDexLen - 4) - dexFileCommentLen; ExecutorService pool = Executors.newFixedThreadPool(dexFileArrayList.size()); ArrayList arrayList = new ArrayList(); List&lt;String&gt; dexnamelist = new ArrayList&lt;&gt;(); for (int i = dexFileArrayList.size() - 1; i &gt;= 0; i--) { DexFile dexFile = dexFileArrayList.get(i); byte[] primaryDexData = new byte[dexFile.getDexLength()]; System.arraycopy(data, currentReadEndIndex - dexFile.getDexLength(), primaryDexData, 0, dexFile.getDexLength()); arrayList.add(pool.submit(new MyCallable(i, primaryDexData, this))); dexnamelist.add(dexFile.getDexName()); currentReadEndIndex -= dexFile.getDexLength(); } int i2 = arrayList.size() - 1; while (i2 &gt;= 0) { try { byte[] primaryDexData2 = (byte[]) ((Future) arrayList.get(i2)).get(60, TimeUnit.SECONDS); System.out.println(&quot; primaryDexData encCD size=&quot; + primaryDexData2.length); File file = new File(primaryDexDir, dexnamelist.get(i2)); if (!file.exists()) { file.createNewFile(); } FileOutputStream fileOutputStream = new FileOutputStream(file); fileOutputStream.write(primaryDexData2); fileOutputStream.close(); i2--; } catch (InterruptedException e) { e.printStackTrace(); File odex = getDir(&quot;payload_odex&quot;, 0); getDir(&quot;payload_dex&quot;, 0).delete(); odex.delete(); return; } catch (ExecutionException e2) { e2.printStackTrace(); File odex2 = getDir(&quot;payload_odex&quot;, 0); getDir(&quot;payload_dex&quot;, 0).delete(); odex2.delete(); return; } } } catch (Exception e3) { }} 这段代码首先调用 readDexFromApk 读取 APP 自己的 Dex 文件，把数据存入变量 data 中。然后读取了 Dex 文件最末尾的 4 个字节，以 int 类型解读这 4 个字节，存入到变量 dexFileCommentLen 中。 123456789// 读取 Dex 文件byte[] data = readDexFromApk();// Dex 文件的总长int shellDexLen = data.length;byte[] dexFileCommentLenByte = new byte[4];// 读取 Dex 文件最末尾的 4 个字节System.arraycopy(data, shellDexLen - 4, dexFileCommentLenByte0, 4);// 以 int 类型解读这 4 个字节int dexFileCommentLen = new DataInputStream(new ByteArrayInputStream(dexFileCommentLenByte)).readInt(); 结合变量名不难猜测，这个 int 变量描述的是一个 ”comment“ 的长度，而且是 ”dex file comment“。很显然，这个 App 的 dex 文件里另有乾坤，接下来多半是读取这个 ”dex file comment“，并且进行分析。 紧接着上面的这几行代码的大概含义是：从刚刚读取 4 个字节的位置继续向前读取 dexFileCommentLen 那么多个字节，并把这些字节数据以文本的形式解读，存入到 String 型变量 dexFileComment 中。最后用 JSON 库解析读取到的内容。 123456789byte[] dexFileCommentByte = new byte[dexFileCommentLen];// 往前继续读取 dexFileCommentLen 个字节的内容System.arraycopy(data, (shellDexLen - 4) - dexFileCommentLen , dexFileCommentByte, 0, dexFileCommentLen);// 以文本的形式解读读取到的内容，存入到 string 变量中String dexFileComment = new String(dexFileCommentByte);// 从类名猜测，这一句是在记录日志LogUtils.m3d(&quot;dex comment:&quot; + dexFileComment);// 用 JSON 库解析这段文本ArrayList&lt;DexFile&gt; dexFileArrayList = (ArrayList) JSOparseArray(dexFileComment, DexFile.class); 读完上面的代码，看来我的思路是对的。这个 dexFileComment 不仅是文本，而且还是 JSON 格式的文本。接下来我已经迫不及待想要验证这段代码的真实性。 一开始我使用的是 VSCode + hexdump 插件来阅读 dex 文件，但是这个 dex 文件实在是太大了，受限于插件，根本读不到末尾的内容。于是我又使用 linux 里的 hexdump 工具查看。 在 wsl 中执行： 1hexdump -C classes.dex &gt; hexdump.txt 最终得到的 hexdump.txt 足足有 100MB 那么大！我直接翻到末尾，内容如下： 可以看到，这个 App 的 dex 文件的末尾确实有一段 JSON 文本。最后四个字节的内容对应十进制 96，和 JSON 文本的长度一致。这说明上面的代码是真实有效的，确实是这次逆向的突破口。 顺着这个思路继续来解读这段 JSON 文本。根据这段 JSON 文本，可以了解到在哪个地方藏着两个 dex 文件，名字分别是 classes.dex 和 classes2.dex，同时给出了这两个文件的长度。 回到上面提到的 multiThread 这个函数的代码。JSON 库解析这段 JSON 文本后，得到了一个 DexFile 对象的数组。其中 DexFile 类的定义如下： 12345public class DexFile { private int dexLength; private String dexName; /* 省略了不重要的代码 */} DexFile 类中的两个字段和看到的 JSON 文本里包含的字段是一致的。 multiThread 函数接下来会从读取完 dexFileComment 的位置继续往前读取内容，读取的长度来自于 DexFile 的 dexLength 字段： 12345678for (int i = dexFileArrayList.size() - 1; i &gt;= 0; i--) { DexFile dexFile = dexFileArrayList.get(i); byte[] primaryDexData = new byte[dexFile.getDexLength()]; System.arraycopy(data, currentReadEndIndex - dexFile.getDexLength(), primaryDexData, 0, dexFile.getDexLength()); arrayList.add(pool.submit(new MyCallable(i, primaryDexData, this))); dexnamelist.add(dexFile.getDexName()); currentReadEndIndex -= dexFile.getDexLength();} 看来那两个藏起来的 dex 文件就藏在这个 App 的 dex 文件末尾。这两个隐藏起来的 dex 文件的数据，扔到了线程池里进行处理。这里的线程池很显然对应了这个函数名称 multiThread。原来这个函数的 “多线程” 指的是多线程处理被隐藏的 dex 文件数据。 我没有学习过 java 语言，但是我猜测任务交给线程池之后应该会执行 MyCallable 这个类的 call 方法。 123456789private class MyCallable implements Callable { /* 省略了不重要的代码 */ public Object call() throws Exception { long startTime = System.nanoTime(); byte[] primaryDexData = Base64.decode(new String(SecurityUtils.AESDecrypt(AESEncrypt.decode(this.innerapp, Base64.decode(Constant.AES_PRIVATE_KEY, 2), Constant.AES_IV, Constant.AES_TYPE, this.innerDexData), &quot;UTF-8&quot;), 2); System.out.println(&quot;程序运行时间： &quot; + this.num + &quot;--&quot; + (System.nanoTime() - startTime) + &quot;ns&quot;); return primaryDexData; }} 我这么猜测不是毫无道理的，因为我认为被隐藏起来的 dex 很可能不会明文保存，不然开头看到的 AESEncrypt 类是干嘛用的？ 这个 call 函数里正好用到了 AESEncrypt 类和 SecurityUtils 类。可以看出，这段代码确实是对刚刚读取的隐藏 dex 文件的数据进行解密。 上面这段代码中涉及的 Constan 类的内容如下： 12345public class Constant { public static final String AES_IV = &quot;1234567898765432&quot;; public static final String AES_PRIVATE_KEY = &quot;m/EEDbJozOx74V16O9VNgmcjCrhDfT/sMdENbl/MOiY=&quot;; public static final String AES_TYPE = &quot;AES/ECB/PKCS5Padding&quot;;} 我猜测这里的内容指的是加密类型和密钥一类的参数。进一步可以猜测，被隐藏的 dex 文件是被 AES 算法加密的。 但是让我很疑惑的是，这段代码用到了两个 AES 解密的函数：“SecurityUtils.AESDecrypt” 和 “AESEncrypt.decode”，他们的定义如下： 1234567public static byte[] AESDecrypt(String privateKey, String iv, String AES_TYPE, byte[] data) { new IvParameterSpec(iv.getBytes()); SecretKeySpec key = new SecretKeySpec(privateKey.getBytes(), &quot;AES&quot;); Cipher cipher = Cipher.getInstance(AES_TYPE); cipher.init(2, key); return cipher.doFinal(data);} 1234567891011public class AESEncrypt { public static native int checkSignature(Object obj); public static native String decode(Object obj, byte[] bArr); public static native String encode(Object obj, String str); static { System.loadLibrary(&quot;JNIEncrypt&quot;); }} 暂且不管这两个函数的代码是什么意思。（实际上我并不了解 AES 算法，也读不懂这两个函数的代码）从这两个函数签名就可以分析到的是 SecurityUtils.AESDecrypt 需要的参数比 AESEncrypt.decode 的参数多了两个。 查阅资料了解到 AES 算法加解密是需要初始向量（即iv）和填充类型（PKCS5Padding）等参数的。 我实在无法理解为什么会有两个 AES 加解密的函数，我想程序员应该是非常懒而且非常讨厌重复的，在同一个程序里使用两个 AES 加解密类，实在不符合常理。 根据我的坏运气体质，写程序验证多半会解密失败。到时候要定位错误，同时涉及到两个 AES 解密，调试成本会很高。 因此我没有去验证这一段代码是不是真正的解密代码。 柳暗花明我继续阅读其他的代码，重点挑选和 AES 有关的函数，很快发现了新的突破口： 12345678910public byte[] decryAES(byte[] data) { byte[] baseDEC = null; try { baseDEC = Base64.decode(AESEncrypt.decode(this, data), 2); System.out.println(&quot; encCD size=&quot; + baseDEC.length); return baseDEC; } catch (Exception e) { return baseDEC; }} 这个函数只调用了 AESEncrypt.decode 进行解密，要写程序验证，即使解密出现失败，我也有信心调试出错误原因。于是我查了下这个函数的引用，它被 splitPrimaryDexFromShellDex 函数所调用： 1234567891011121314151617181920212223242526public void splitPrimaryDexFromShellDex(byte[] data, String primaryDexDir) { int shellDexLen = data.length; byte[] dexFileCommentLenByte = new byte[4]; System.arraycopy(data, shellDexLen - 4, dexFileCommentLenByte, 0, 4); int dexFileCommentLen = new DataInputStream(new ByteArrayInputStream(dexFileCommentLenByte)).readInt(); byte[] dexFileCommentByte = new byte[dexFileCommentLen]; System.arraycopy(data, (shellDexLen - 4) - dexFileCommentLen, dexFileCommentByte, 0, dexFileCommentLen); String dexFileComment = new String(dexFileCommentByte); LogUtils.m3d(&quot;dex comment:&quot; + dexFileComment); ArrayList&lt;DexFile&gt; dexFileArrayList = (ArrayList) JSON.parseArray(dexFileComment, DexFile.class); int currentReadEndIndex = (shellDexLen - 4) - dexFileCommentLen; for (int i = dexFileArrayList.size() - 1; i &gt;= 0; i--) { DexFile dexFile = dexFileArrayList.get(i); byte[] primaryDexData = new byte[dexFile.getDexLength()]; System.arraycopy(data, currentReadEndIndex - dexFile.getDexLength(), primaryDexData, 0, dexFile.getDexLength()); byte[] primaryDexData2 = decryAES(primaryDexData); File file = new File(primaryDexDir, dexFile.getDexName()); if (!file.exists()) { file.createNewFile(); } FileOutputStream localFileOutputStream = new FileOutputStream(file); localFileOutputStream.write(primaryDexData2); localFileOutputStream.close(); currentReadEndIndex -= dexFile.getDexLength(); }} 这个函数执行的流程和 multiThread 函数大致相同，也是读取隐藏的 dex 文件数据，然后对各个隐藏 dex 文件数据调用decryAES函数进行解密，解密后的数据保存到磁盘中。 相比于刚刚 call 函数里的解密方式，更容易去验证这个函数的解密方式是否正确。 解密的核心函数是 AESEncrypt.decode，这个函数的内容不在 java 层而在 native 层。看这个函数的定义就知道，带着“native”关键词，并且来自“JNIEncrypt”库。 调试 native 库就要用到工具 IDA 了。使用 IDA 打开 x86 目录下的 libJNIEncrypt.so 文件，如下图所示，找到 decode 函数后按下 F5 反编译为 c 语言代码。 从代码中的 AES_128_ECB_PKCS5Padding_Decrypt 函数可以了解到很多很多信息。AES 解密所需要的信息这里基本上都包含了。但是我很疑惑为什么这里解密没有用到初始向量（iv）。要知道 java 层的 AES 解密以及 Constants 类都有初始向量 iv 的定义。 查阅资料后发现，原来 AES 算法在 ECB 模式下，初始向量不是必要的参数。 但是 java 层的也是 ECB 模式！为什么它还是用到了初始向量呢？我没有去进一步了解，往后看吧，我直接成功了。（剧透警告） 分析一下我只看懂的三行代码： 123456// v6 感觉是密钥v6 = getKey();// 使用密钥进行解密v7 = AES_128_ECB_PKCS5Padding_Decrypt(v4, v5, v6);// 返回解密后的数据return charToJstring(a1, v7); 于是我去看了看 getKey 函数，我想这里能够知道密钥是怎么来的： 这次我能看懂的代码只剩下 2 行了： 1234// 对 v3 执行 strlen ？v3 不是 char 变量吗？v0 = strlen(&amp;v3);// b64_decode 应该是 base64 解码v2 = b64_decode(&amp;v3, v0); 从C语言的语法来理解，v3 应该是 char 变量，是不应该对它使用 strlen 的，但是这里偏偏就对它使用了strlen。 无奈我是第一次使用 IDA，所以我只能认为不能用常规的C语言语法来理解这段代码。我猜测 v3 到 v26 那些变量，实际上是同一个字符串的内容，它们在内存中的位置是连续的。 我又注意到 v25 和 v26 的字符一样，结合 base64 编码的特性，我猜测这两个字符很可能就是两个等号。翻了翻 ASCII 码表，dec 61对应的字符确实是等号，我的想法是对的。 最终，我得到了下面这些数据： 123&quot;77 84 73 122 78 68 85 52 79 84 89 51 77 71 82 108 90 109 70 105 89 119 61 61&quot;&quot;MTIzNDU4OTY3MGRlZmFiYw==&quot;&quot;1234589670defabc&quot; 虽然我是第一次进行 App 逆向，但是我见过别人的逆向文章，别人逆向出来的密钥，有很多都是 123456 这样的简单密钥。我也逆向出了个“1234589670defabc”，因此我逆向得到的也是密钥。（哈哈哈哈，别不信，我是对的） 接下来我用 C# 写了个程序，去验证我的猜想。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364using Newtonsoft.Json;using Newtonsoft.Json.Linq;using System;using System.Collections.Generic;using System.IO;using System.Security.Cryptography;using System.Text;namespace kgo{ class Program { static void Main(string[] args) { byte[] dexData = File.ReadAllBytes(&quot;D:\\\\classes.dex&quot;); int Len = dexData.Length; byte[] commentLenByte = new byte[4]; Array.Copy(dexData, Len - 4, commentLenByte, 0, 4); Array.Reverse(commentLenByte); int commentLen = BitConverter.ToInt32(commentLenByte); Console.WriteLine($&quot;注释长度: {commentLen}&quot;); byte[] commentByte = new byte[commentLen]; Array.Copy(dexData, Len - 4 - commentLen, commentByte, 0, commentLen); string comment = Encoding.UTF8.GetString(commentByte); Console.WriteLine($&quot;注释内容：{comment}&quot;); List&lt;DexFile&gt; dexFiles = new List&lt;DexFile&gt;(); dexFiles = JsonConvert.DeserializeObject&lt;List&lt;DexFile&gt;&gt;(comment); int tLen = Len - 4 - commentLen; for(int i = dexFiles.Count - 1; i &gt;=0; i--) { var dexFile = dexFiles[i]; Console.WriteLine($&quot;检测到 dex 文件: {dexFile.Name}, 总长度: {dexFile.Length}&quot;); tLen -= dexFile.Length; byte[] dexFileData = new byte[dexFile.Length]; Array.Copy(dexData, tLen, dexFileData, 0, dexFile.Length); byte[] de = Decrypt(dexFileData, Convert.FromBase64String(&quot;MTIzNDU4OTY3MGRlZmFiYw==&quot;)); de = Convert.FromBase64String(Encoding.ASCII.GetString(de)); File.WriteAllBytes($&quot;D:\\\\decode_{dexFile.Name}&quot;, de); } } public static byte[] Decrypt(byte[] input, byte[] key) { var aesAlg = new AesManaged { KeySize = 128, Key = key, BlockSize = 128, Mode = CipherMode.ECB, Padding = PaddingMode.PKCS7, IV = new byte[] { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }; ICryptoTransform encryptor = aesAlg.CreateDecryptor(aesAlg.Key, aesAlg.IV); return encryptor.TransformFinalBlock(input, 0, input.Length); } } public class DexFile { [JsonProperty(&quot;dexLength&quot;)] public int Length { get; set; } [JsonProperty(&quot;dexName&quot;)] public string Name { get; set; } }} 运行结果如图所示： 逆向成功用 dex2jar 转换一下解密得到的两个 dex 文件，提示都有错误！但是应该不是很大的错误，因为我还是得到了两个 jar 文件。 有很多个错误，但是都是同一个错误：java.lang.RuntimeException: can not merge I and Z。查资料后发现，这是 java 无法把 int类型 转化为 Boolean类型，所以在严格的类型检查下报错了。 使用 jd-gui 成功打开这两个 jar 文件： 搜一下字符串，成功搜索到期待的字符串。","link":"/2020/08/20/%E9%9D%92%E6%9E%9C%E6%95%99%E5%8A%A1%E7%B3%BB%E7%BB%9F%E5%AE%89%E5%8D%93APP-%E5%96%9C%E9%B9%8A%E5%84%BF-%E9%80%86%E5%90%91%E5%88%86%E6%9E%90/"}],"tags":[{"name":"c++","slug":"c","link":"/tags/c/"},{"name":"opencv","slug":"opencv","link":"/tags/opencv/"},{"name":"C++","slug":"C","link":"/tags/C/"},{"name":"c#","slug":"c","link":"/tags/c/"},{"name":"concept","slug":"concept","link":"/tags/concept/"},{"name":"SFINAE","slug":"SFINAE","link":"/tags/SFINAE/"},{"name":"并发","slug":"并发","link":"/tags/%E5%B9%B6%E5%8F%91/"},{"name":"学习笔记","slug":"学习笔记","link":"/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"CMake","slug":"CMake","link":"/tags/CMake/"},{"name":"摄影作品","slug":"摄影作品","link":"/tags/%E6%91%84%E5%BD%B1%E4%BD%9C%E5%93%81/"},{"name":"数学建模","slug":"数学建模","link":"/tags/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"},{"name":"AutoCAD","slug":"AutoCAD","link":"/tags/AutoCAD/"},{"name":"CSharp","slug":"CSharp","link":"/tags/CSharp/"},{"name":"Matlab","slug":"Matlab","link":"/tags/Matlab/"},{"name":"ls-dyna","slug":"ls-dyna","link":"/tags/ls-dyna/"},{"name":"数学","slug":"数学","link":"/tags/%E6%95%B0%E5%AD%A6/"},{"name":"MATLAB","slug":"MATLAB","link":"/tags/MATLAB/"},{"name":"无聊了","slug":"无聊了","link":"/tags/%E6%97%A0%E8%81%8A%E4%BA%86/"},{"name":"C#","slug":"C","link":"/tags/C/"},{"name":"其他","slug":"其他","link":"/tags/%E5%85%B6%E4%BB%96/"},{"name":"读书笔记","slug":"读书笔记","link":"/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"目标检测","slug":"目标检测","link":"/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"},{"name":"yolo","slug":"yolo","link":"/tags/yolo/"},{"name":"船舶","slug":"船舶","link":"/tags/%E8%88%B9%E8%88%B6/"},{"name":"算法","slug":"算法","link":"/tags/%E7%AE%97%E6%B3%95/"}],"categories":[]}